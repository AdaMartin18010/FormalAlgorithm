---
title: 1.11 æµ‹åº¦è®ºåŸºç¡€ / Measure Theory Foundation
version: 1.0
status: maintained
last_updated: 2025-01-11
owner: åŸºç¡€ç†è®ºå·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)
> **é¡¹ç›®å¯¼èˆªä¸å¯¹æ ‡**ï¼š[é¡¹ç›®æ‰©å±•ä¸æŒç»­æ¨è¿›ä»»åŠ¡ç¼–æ’](../é¡¹ç›®æ‰©å±•ä¸æŒç»­æ¨è¿›ä»»åŠ¡ç¼–æ’.md)ã€[å›½é™…è¯¾ç¨‹å¯¹æ ‡è¡¨](../å›½é™…è¯¾ç¨‹å¯¹æ ‡è¡¨.md)

## 1.11 æµ‹åº¦è®ºåŸºç¡€ / Measure Theory Foundation

### æ‘˜è¦ / Executive Summary

- å»ºç«‹æµ‹åº¦è®ºçš„åŸºç¡€ç†è®ºï¼Œç»Ÿä¸€Ïƒ-ä»£æ•°ã€æµ‹åº¦ã€å¯æµ‹å‡½æ•°ç­‰æ ¸å¿ƒæ¦‚å¿µã€‚
- å»ºç«‹æµ‹åº¦è®ºåœ¨æ¦‚ç‡è®ºå’Œåˆ†æä¸­çš„åŸºç¡€åœ°ä½ã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- Ïƒ-ä»£æ•°ã€æµ‹åº¦ã€å¯æµ‹å‡½æ•°ã€ç§¯åˆ†ã€å‹’è´æ ¼æµ‹åº¦ã€æ¦‚ç‡æµ‹åº¦ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology & Notation

- Ïƒ-ä»£æ•°ï¼ˆÏƒ-Algebraï¼‰ï¼šæ»¡è¶³ç‰¹å®šæ¡ä»¶çš„é›†åˆæ—ã€‚
- æµ‹åº¦ï¼ˆMeasureï¼‰ï¼šä»Ïƒ-ä»£æ•°åˆ°éè´Ÿå®æ•°çš„æ˜ å°„ã€‚
- å¯æµ‹å‡½æ•°ï¼ˆMeasurable Functionï¼‰ï¼šä¿æŒå¯æµ‹æ€§çš„å‡½æ•°ã€‚
- ç§¯åˆ†ï¼ˆIntegralï¼‰ï¼šå¯æµ‹å‡½æ•°çš„ç§¯åˆ†ã€‚
- è®°å·çº¦å®šï¼š`Î£` è¡¨ç¤ºÏƒ-ä»£æ•°ï¼Œ`Î¼` è¡¨ç¤ºæµ‹åº¦ï¼Œ`f` è¡¨ç¤ºå¯æµ‹å‡½æ•°ï¼Œ`âˆ«` è¡¨ç¤ºç§¯åˆ†ã€‚

### äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References

- æ¦‚ç‡ä¸ç»Ÿè®¡åŸºç¡€ï¼šå‚è§ `01-åŸºç¡€ç†è®º/07-æ¦‚ç‡ä¸ç»Ÿè®¡åŸºç¡€.md`ã€‚
- æ•°å­¦åŸºç¡€ï¼šå‚è§ `01-åŸºç¡€ç†è®º/02-æ•°å­¦åŸºç¡€.md`ã€‚
- å‡½æ•°è®ºåŸºç¡€ï¼šå‚è§ `01-åŸºç¡€ç†è®º/04-å‡½æ•°è®ºåŸºç¡€.md`ã€‚

### å¿«é€Ÿå¯¼èˆª / Quick Links

- åŸºæœ¬æ¦‚å¿µ
- Ïƒ-ä»£æ•°
- æµ‹åº¦ä¸ç§¯åˆ†

## ç›®å½• (Table of Contents)

- [1.11 æµ‹åº¦è®ºåŸºç¡€ / Measure Theory Foundation](#111-æµ‹åº¦è®ºåŸºç¡€--measure-theory-foundation)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology \& Notation](#æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ--terminology--notation)
  - [äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References](#äº¤å‰å¼•ç”¨å¯¼èˆª--cross-references)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½• (Table of Contents)](#ç›®å½•-table-of-contents)
- [åŸºæœ¬æ¦‚å¿µ / Basic Concepts](#åŸºæœ¬æ¦‚å¿µ--basic-concepts)
  - [Ïƒ-ä»£æ•° / Ïƒ-Algebra](#Ïƒ-ä»£æ•°--Ïƒ-algebra)
  - [æµ‹åº¦ / Measure](#æµ‹åº¦--measure)
  - [å¯æµ‹å‡½æ•° / Measurable Functions](#å¯æµ‹å‡½æ•°--measurable-functions)
- [æµ‹åº¦è®ºåœ¨ç®—æ³•ä¸­çš„åº”ç”¨ / Applications of Measure Theory in Algorithms](#æµ‹åº¦è®ºåœ¨ç®—æ³•ä¸­çš„åº”ç”¨--applications-of-measure-theory-in-algorithms)
  - [æ¦‚ç‡ç®—æ³• / Probabilistic Algorithms](#æ¦‚ç‡ç®—æ³•--probabilistic-algorithms)
  - [ç§¯åˆ†ç†è®º / Integration Theory](#ç§¯åˆ†ç†è®º--integration-theory)
- [æµ‹åº¦è®ºçš„é«˜çº§ä¸»é¢˜ / Advanced Topics in Measure Theory](#æµ‹åº¦è®ºçš„é«˜çº§ä¸»é¢˜--advanced-topics-in-measure-theory)
  - [ç»å¯¹è¿ç»­æ€§å’Œå¥‡å¼‚æµ‹åº¦ / Absolute Continuity and Singular Measures](#ç»å¯¹è¿ç»­æ€§å’Œå¥‡å¼‚æµ‹åº¦--absolute-continuity-and-singular-measures)
  - [æ”¶æ•›å®šç† / Convergence Theorems](#æ”¶æ•›å®šç†--convergence-theorems)
- [å®ç°ç¤ºä¾‹ / Implementation Examples](#å®ç°ç¤ºä¾‹--implementation-examples)
  - [æ¦‚ç‡åˆ†å¸ƒ / Probability Distributions](#æ¦‚ç‡åˆ†å¸ƒ--probability-distributions)
- [å‚è€ƒæ–‡çŒ® / References](#å‚è€ƒæ–‡çŒ®--references)

## åŸºæœ¬æ¦‚å¿µ / Basic Concepts

### Ïƒ-ä»£æ•° / Ïƒ-Algebra

**å®šä¹‰ 1.1** (Ïƒ-ä»£æ•°) / **Definition 1.1** (Ïƒ-Algebra)
è®¾ $X$ ä¸ºé›†åˆï¼Œ$\mathcal{F}$ ä¸º $X$ çš„å­é›†æ—ï¼Œå¦‚æœ $\mathcal{F}$ æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š
Let $X$ be a set and $\mathcal{F}$ be a family of subsets of $X$. $\mathcal{F}$ is a **Ïƒ-algebra** if it satisfies:

1. **åŒ…å«å…¨é›†** / **Contains Universe**: $X \in \mathcal{F}$
2. **è¡¥é›†å°é—­** / **Closed under Complements**: è‹¥ $A \in \mathcal{F}$ï¼Œåˆ™ $A^c \in \mathcal{F}$
3. **å¯æ•°å¹¶å°é—­** / **Closed under Countable Unions**: è‹¥ $\{A_n\}_{n=1}^{\infty} \subseteq \mathcal{F}$ï¼Œåˆ™ $\bigcup_{n=1}^{\infty} A_n \in \mathcal{F}$

åˆ™ç§° $\mathcal{F}$ ä¸º $X$ ä¸Šçš„**Ïƒ-ä»£æ•°**ã€‚
Then $\mathcal{F}$ is called a **Ïƒ-algebra** on $X$.

**å®šç† 1.1** (Ïƒ-ä»£æ•°çš„åŸºæœ¬æ€§è´¨) / **Theorem 1.1** (Basic Properties of Ïƒ-Algebras)
è®¾ $\mathcal{F}$ ä¸º $X$ ä¸Šçš„Ïƒ-ä»£æ•°ï¼Œåˆ™ï¼š
Let $\mathcal{F}$ be a Ïƒ-algebra on $X$, then:

1. $\emptyset \in \mathcal{F}$
2. è‹¥ $A, B \in \mathcal{F}$ï¼Œåˆ™ $A \cap B \in \mathcal{F}$
3. è‹¥ $\{A_n\}_{n=1}^{\infty} \subseteq \mathcal{F}$ï¼Œåˆ™ $\bigcap_{n=1}^{\infty} A_n \in \mathcal{F}$

### æµ‹åº¦ / Measure

**å®šä¹‰ 1.2** (æµ‹åº¦) / **Definition 1.2** (Measure)
è®¾ $(X, \mathcal{F})$ ä¸ºå¯æµ‹ç©ºé—´ï¼Œå‡½æ•° $\mu: \mathcal{F} \to [0, \infty]$ ç§°ä¸º**æµ‹åº¦**ï¼Œå¦‚æœï¼š
Let $(X, \mathcal{F})$ be a measurable space. A function $\mu: \mathcal{F} \to [0, \infty]$ is called a **measure** if:

1. **éè´Ÿæ€§** / **Non-negativity**: $\mu(A) \geq 0$ å¯¹æ‰€æœ‰ $A \in \mathcal{F}$
2. **ç©ºé›†ä¸ºé›¶** / **Empty Set**: $\mu(\emptyset) = 0$
3. **å¯æ•°å¯åŠ æ€§** / **Countable Additivity**: è‹¥ $\{A_n\}_{n=1}^{\infty} \subseteq \mathcal{F}$ ä¸ºäº’ä¸ç›¸äº¤çš„é›†åˆæ—ï¼Œåˆ™ï¼š
   $$\mu\left(\bigcup_{n=1}^{\infty} A_n\right) = \sum_{n=1}^{\infty} \mu(A_n)$$

**å®šç† 1.2** (æµ‹åº¦çš„åŸºæœ¬æ€§è´¨) / **Theorem 1.2** (Basic Properties of Measures)
è®¾ $\mu$ ä¸ºæµ‹åº¦ï¼Œåˆ™ï¼š
Let $\mu$ be a measure, then:

1. **å•è°ƒæ€§** / **Monotonicity**: è‹¥ $A \subseteq B$ï¼Œåˆ™ $\mu(A) \leq \mu(B)$
2. **æ¬¡å¯åŠ æ€§** / **Subadditivity**: $\mu\left(\bigcup_{n=1}^{\infty} A_n\right) \leq \sum_{n=1}^{\infty} \mu(A_n)$
3. **è¿ç»­æ€§** / **Continuity**: è‹¥ $A_n \uparrow A$ï¼Œåˆ™ $\mu(A_n) \uparrow \mu(A)$

### å¯æµ‹å‡½æ•° / Measurable Functions

**å®šä¹‰ 1.3** (å¯æµ‹å‡½æ•°) / **Definition 1.3** (Measurable Function)
è®¾ $(X, \mathcal{F})$ å’Œ $(Y, \mathcal{G})$ ä¸ºå¯æµ‹ç©ºé—´ï¼Œå‡½æ•° $f: X \to Y$ ç§°ä¸º**å¯æµ‹å‡½æ•°**ï¼Œå¦‚æœï¼š
Let $(X, \mathcal{F})$ and $(Y, \mathcal{G})$ be measurable spaces. A function $f: X \to Y$ is called **measurable** if:

$$f^{-1}(G) \in \mathcal{F} \text{ for all } G \in \mathcal{G}$$

**å®šç† 1.3** (å¯æµ‹å‡½æ•°çš„æ€§è´¨) / **Theorem 1.3** (Properties of Measurable Functions)
è®¾ $f, g: X \to \mathbb{R}$ ä¸ºå¯æµ‹å‡½æ•°ï¼Œåˆ™ï¼š
Let $f, g: X \to \mathbb{R}$ be measurable functions, then:

1. $f + g$ å¯æµ‹ / $f + g$ is measurable
2. $f \cdot g$ å¯æµ‹ / $f \cdot g$ is measurable
3. $\max(f, g)$ å’Œ $\min(f, g)$ å¯æµ‹ / $\max(f, g)$ and $\min(f, g)$ are measurable

## æµ‹åº¦è®ºåœ¨ç®—æ³•ä¸­çš„åº”ç”¨ / Applications of Measure Theory in Algorithms

### æ¦‚ç‡ç®—æ³• / Probabilistic Algorithms

**å®šä¹‰ 2.1** (æ¦‚ç‡ç©ºé—´) / **Definition 2.1** (Probability Space)
ä¸€ä¸ª**æ¦‚ç‡ç©ºé—´**æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ $(\Omega, \mathcal{F}, P)$ï¼Œå…¶ä¸­ï¼š
A **probability space** is a triple $(\Omega, \mathcal{F}, P)$ where:

1. $\Omega$ ä¸ºæ ·æœ¬ç©ºé—´ / $\Omega$ is the sample space
2. $\mathcal{F}$ ä¸ºäº‹ä»¶Ïƒ-ä»£æ•° / $\mathcal{F}$ is the event Ïƒ-algebra
3. $P$ ä¸ºæ¦‚ç‡æµ‹åº¦ï¼Œæ»¡è¶³ $P(\Omega) = 1$ / $P$ is the probability measure with $P(\Omega) = 1$

**å®ç°ç¤ºä¾‹** / **Implementation Example**

```rust
use std::collections::HashMap;
use rand::Rng;

// æ¦‚ç‡ç©ºé—´ / Probability Space
struct ProbabilitySpace {
    events: HashMap<String, f64>,
}

impl ProbabilitySpace {
    fn new() -> Self {
        ProbabilitySpace {
            events: HashMap::new(),
        }
    }

    fn add_event(&mut self, event: String, probability: f64) {
        self.events.insert(event, probability);
    }

    fn get_probability(&self, event: &str) -> f64 {
        *self.events.get(event).unwrap_or(&0.0)
    }

    fn total_probability(&self) -> f64 {
        self.events.values().sum()
    }
}

// éšæœºå˜é‡ / Random Variable
struct RandomVariable {
    values: Vec<f64>,
    probabilities: Vec<f64>,
}

impl RandomVariable {
    fn new(values: Vec<f64>, probabilities: Vec<f64>) -> Self {
        assert_eq!(values.len(), probabilities.len());
        RandomVariable { values, probabilities }
    }

    fn expectation(&self) -> f64 {
        self.values.iter()
            .zip(self.probabilities.iter())
            .map(|(x, p)| x * p)
            .sum()
    }

    fn variance(&self) -> f64 {
        let mean = self.expectation();
        self.values.iter()
            .zip(self.probabilities.iter())
            .map(|(x, p)| (x - mean).powi(2) * p)
            .sum()
    }

    fn sample(&self) -> f64 {
        let mut rng = rand::thread_rng();
        let u: f64 = rng.gen();
        let mut cumulative = 0.0;

        for (value, prob) in self.values.iter().zip(self.probabilities.iter()) {
            cumulative += prob;
            if u <= cumulative {
                return *value;
            }
        }

        self.values.last().unwrap_or(&0.0)
    }
}

// è’™ç‰¹å¡æ´›ç®—æ³• / Monte Carlo Algorithm
struct MonteCarlo {
    iterations: usize,
}

impl MonteCarlo {
    fn new(iterations: usize) -> Self {
        MonteCarlo { iterations }
    }

    fn estimate_pi(&self) -> f64 {
        let mut rng = rand::thread_rng();
        let mut inside_circle = 0;

        for _ in 0..self.iterations {
            let x: f64 = rng.gen_range(-1.0..1.0);
            let y: f64 = rng.gen_range(-1.0..1.0);

            if x * x + y * y <= 1.0 {
                inside_circle += 1;
            }
        }

        4.0 * inside_circle as f64 / self.iterations as f64
    }

    fn estimate_integral<F>(&self, f: F, a: f64, b: f64) -> f64
    where
        F: Fn(f64) -> f64,
    {
        let mut rng = rand::thread_rng();
        let mut sum = 0.0;

        for _ in 0..self.iterations {
            let x: f64 = rng.gen_range(a..b);
            sum += f(x);
        }

        (b - a) * sum / self.iterations as f64
    }
}

fn main() {
    // æ¦‚ç‡ç©ºé—´ä½¿ç”¨ç¤ºä¾‹ / Probability space usage example
    let mut ps = ProbabilitySpace::new();
    ps.add_event("heads".to_string(), 0.5);
    ps.add_event("tails".to_string(), 0.5);

    println!("Probability of heads: {}", ps.get_probability("heads"));
    println!("Total probability: {}", ps.total_probability());

    // éšæœºå˜é‡ä½¿ç”¨ç¤ºä¾‹ / Random variable usage example
    let rv = RandomVariable::new(
        vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0],
        vec![1.0/6.0; 6],
    );

    println!("Expectation: {}", rv.expectation());
    println!("Variance: {}", rv.variance());
    println!("Sample: {}", rv.sample());

    // è’™ç‰¹å¡æ´›ç®—æ³•ä½¿ç”¨ç¤ºä¾‹ / Monte Carlo algorithm usage example
    let mc = MonteCarlo::new(1000000);
    println!("Estimated Ï€: {}", mc.estimate_pi());

    let integral = mc.estimate_integral(|x| x * x, 0.0, 1.0);
    println!("Estimated integral of xÂ² from 0 to 1: {}", integral);
}
```

### ç§¯åˆ†ç†è®º / Integration Theory

**å®šä¹‰ 2.2** (å‹’è´æ ¼ç§¯åˆ†) / **Definition 2.2** (Lebesgue Integral)
è®¾ $(X, \mathcal{F}, \mu)$ ä¸ºæµ‹åº¦ç©ºé—´ï¼Œ$f: X \to [0, \infty]$ ä¸ºéè´Ÿå¯æµ‹å‡½æ•°ï¼Œåˆ™**å‹’è´æ ¼ç§¯åˆ†**å®šä¹‰ä¸ºï¼š
Let $(X, \mathcal{F}, \mu)$ be a measure space and $f: X \to [0, \infty]$ be a non-negative measurable function. The **Lebesgue integral** is defined as:

$$\int_X f \, d\mu = \sup \left\{ \sum_{i=1}^{n} a_i \mu(A_i) \mid 0 \leq \sum_{i=1}^{n} a_i \chi_{A_i} \leq f \right\}$$

**å®šç† 2.1** (å•è°ƒæ”¶æ•›å®šç†) / **Theorem 2.1** (Monotone Convergence Theorem)
è®¾ $\{f_n\}$ ä¸ºéè´Ÿå¯æµ‹å‡½æ•°çš„é€’å¢åºåˆ—ï¼Œ$f = \lim_{n \to \infty} f_n$ï¼Œåˆ™ï¼š
Let $\{f_n\}$ be an increasing sequence of non-negative measurable functions and $f = \lim_{n \to \infty} f_n$, then:

$$\int_X f \, d\mu = \lim_{n \to \infty} \int_X f_n \, d\mu$$

**å®ç°ç¤ºä¾‹** / **Implementation Example**

```rust
// æ•°å€¼ç§¯åˆ† / Numerical Integration
trait Integrable {
    fn evaluate(&self, x: f64) -> f64;
}

struct Function<F> {
    f: F,
}

impl<F> Function<F>
where
    F: Fn(f64) -> f64,
{
    fn new(f: F) -> Self {
        Function { f }
    }
}

impl<F> Integrable for Function<F>
where
    F: Fn(f64) -> f64,
{
    fn evaluate(&self, x: f64) -> f64 {
        (self.f)(x)
    }
}

// æ¢¯å½¢æ³•åˆ™ / Trapezoidal Rule
struct TrapezoidalRule {
    n: usize,
}

impl TrapezoidalRule {
    fn new(n: usize) -> Self {
        TrapezoidalRule { n }
    }

    fn integrate<I: Integrable>(&self, f: &I, a: f64, b: f64) -> f64 {
        let h = (b - a) / self.n as f64;
        let mut sum = 0.5 * (f.evaluate(a) + f.evaluate(b));

        for i in 1..self.n {
            let x = a + i as f64 * h;
            sum += f.evaluate(x);
        }

        h * sum
    }
}

// è¾›æ™®æ£®æ³•åˆ™ / Simpson's Rule
struct SimpsonsRule {
    n: usize,
}

impl SimpsonsRule {
    fn new(n: usize) -> Self {
        SimpsonsRule { n }
    }

    fn integrate<I: Integrable>(&self, f: &I, a: f64, b: f64) -> f64 {
        let h = (b - a) / self.n as f64;
        let mut sum = f.evaluate(a) + f.evaluate(b);

        for i in 1..self.n {
            let x = a + i as f64 * h;
            if i % 2 == 0 {
                sum += 2.0 * f.evaluate(x);
            } else {
                sum += 4.0 * f.evaluate(x);
            }
        }

        h * sum / 3.0
    }
}

// è‡ªé€‚åº”ç§¯åˆ† / Adaptive Integration
struct AdaptiveIntegrator {
    tolerance: f64,
    max_iterations: usize,
}

impl AdaptiveIntegrator {
    fn new(tolerance: f64, max_iterations: usize) -> Self {
        AdaptiveIntegrator {
            tolerance,
            max_iterations,
        }
    }

    fn integrate<I: Integrable>(&self, f: &I, a: f64, b: f64) -> f64 {
        self.adaptive_step(f, a, b, 0)
    }

    fn adaptive_step<I: Integrable>(&self, f: &I, a: f64, b: f64, depth: usize) -> f64 {
        if depth >= self.max_iterations {
            return self.simple_integrate(f, a, b);
        }

        let mid = (a + b) / 2.0;
        let left = self.simple_integrate(f, a, mid);
        let right = self.simple_integrate(f, mid, b);
        let total = self.simple_integrate(f, a, b);

        if (left + right - total).abs() < self.tolerance {
            left + right
        } else {
            self.adaptive_step(f, a, mid, depth + 1) +
            self.adaptive_step(f, mid, b, depth + 1)
        }
    }

    fn simple_integrate<I: Integrable>(&self, f: &I, a: f64, b: f64) -> f64 {
        let h = b - a;
        let fa = f.evaluate(a);
        let fb = f.evaluate(b);
        h * (fa + fb) / 2.0
    }
}

fn main() {
    // å‡½æ•°ç§¯åˆ†ç¤ºä¾‹ / Function integration example
    let f = Function::new(|x| x * x);

    // æ¢¯å½¢æ³•åˆ™ / Trapezoidal rule
    let trapezoidal = TrapezoidalRule::new(1000);
    let result1 = trapezoidal.integrate(&f, 0.0, 1.0);
    println!("Trapezoidal rule: {}", result1);

    // è¾›æ™®æ£®æ³•åˆ™ / Simpson's rule
    let simpson = SimpsonsRule::new(1000);
    let result2 = simpson.integrate(&f, 0.0, 1.0);
    println!("Simpson's rule: {}", result2);

    // è‡ªé€‚åº”ç§¯åˆ† / Adaptive integration
    let adaptive = AdaptiveIntegrator::new(1e-6, 10);
    let result3 = adaptive.integrate(&f, 0.0, 1.0);
    println!("Adaptive integration: {}", result3);

    // ç†è®ºå€¼ / Theoretical value
    println!("Theoretical value: {}", 1.0 / 3.0);
}
```

## æµ‹åº¦è®ºçš„é«˜çº§ä¸»é¢˜ / Advanced Topics in Measure Theory

### ç»å¯¹è¿ç»­æ€§å’Œå¥‡å¼‚æµ‹åº¦ / Absolute Continuity and Singular Measures

**å®šä¹‰ 3.1** (ç»å¯¹è¿ç»­) / **Definition 3.1** (Absolute Continuity)
è®¾ $\mu$ å’Œ $\nu$ ä¸ºæµ‹åº¦ç©ºé—´ $(X, \mathcal{F})$ ä¸Šçš„æµ‹åº¦ï¼Œå¦‚æœå¯¹ä»»æ„ $A \in \mathcal{F}$ï¼Œ$\mu(A) = 0$ è•´å« $\nu(A) = 0$ï¼Œåˆ™ç§° $\nu$ å…³äº $\mu$ **ç»å¯¹è¿ç»­**ï¼Œè®°ä½œ $\nu \ll \mu$ã€‚
Let $\mu$ and $\nu$ be measures on $(X, \mathcal{F})$. If for any $A \in \mathcal{F}$, $\mu(A) = 0$ implies $\nu(A) = 0$, then $\nu$ is **absolutely continuous** with respect to $\mu$, denoted by $\nu \ll \mu$.

**å®šç† 3.1** (æ‹‰ä¸œ-å°¼ç§‘è¿ªå§†å®šç†) / **Theorem 3.1** (Radon-Nikodym Theorem)
è®¾ $\mu$ ä¸ºÏƒ-æœ‰é™æµ‹åº¦ï¼Œ$\nu$ å…³äº $\mu$ ç»å¯¹è¿ç»­ï¼Œåˆ™å­˜åœ¨éè´Ÿå¯æµ‹å‡½æ•° $f$ ä½¿å¾—ï¼š
Let $\mu$ be Ïƒ-finite and $\nu \ll \mu$. Then there exists a non-negative measurable function $f$ such that:

$$\nu(A) = \int_A f \, d\mu \text{ for all } A \in \mathcal{F}$$

### æ”¶æ•›å®šç† / Convergence Theorems

**å®šç† 3.2** (æ§åˆ¶æ”¶æ•›å®šç†) / **Theorem 3.2** (Dominated Convergence Theorem)
è®¾ $\{f_n\}$ ä¸ºå¯æµ‹å‡½æ•°åºåˆ—ï¼Œ$f_n \to f$ å‡ ä¹å¤„å¤„ï¼Œä¸”å­˜åœ¨å¯ç§¯å‡½æ•° $g$ ä½¿å¾— $|f_n| \leq g$ å‡ ä¹å¤„å¤„ï¼Œåˆ™ï¼š
Let $\{f_n\}$ be a sequence of measurable functions with $f_n \to f$ almost everywhere, and there exists an integrable function $g$ such that $|f_n| \leq g$ almost everywhere, then:

$$\lim_{n \to \infty} \int_X f_n \, d\mu = \int_X f \, d\mu$$

**å®ç°ç¤ºä¾‹** / **Implementation Example**

```rust
// æµ‹åº¦æ”¶æ•› / Measure Convergence
struct MeasureConvergence {
    tolerance: f64,
}

impl MeasureConvergence {
    fn new(tolerance: f64) -> Self {
        MeasureConvergence { tolerance }
    }

    fn check_convergence(&self, sequence: &[f64]) -> bool {
        if sequence.len() < 2 {
            return true;
        }

        for i in 1..sequence.len() {
            if (sequence[i] - sequence[i-1]).abs() > self.tolerance {
                return false;
            }
        }
        true
    }

    fn limit(&self, sequence: &[f64]) -> Option<f64> {
        if self.check_convergence(sequence) {
            sequence.last().copied()
        } else {
            None
        }
    }
}

// å‡½æ•°åºåˆ— / Function Sequence
struct FunctionSequence<F> {
    functions: Vec<F>,
}

impl<F> FunctionSequence<F>
where
    F: Fn(f64) -> f64,
{
    fn new() -> Self {
        FunctionSequence {
            functions: Vec::new(),
        }
    }

    fn add_function(&mut self, f: F) {
        self.functions.push(f);
    }

    fn evaluate_at(&self, x: f64) -> Vec<f64> {
        self.functions.iter().map(|f| f(x)).collect()
    }

    fn check_pointwise_convergence(&self, x: f64, limit: f64, tolerance: f64) -> bool {
        let values = self.evaluate_at(x);
        values.iter().all(|&v| (v - limit).abs() < tolerance)
    }
}

fn main() {
    // æµ‹åº¦æ”¶æ•›ç¤ºä¾‹ / Measure convergence example
    let convergence = MeasureConvergence::new(1e-6);
    let sequence = vec![1.0, 1.1, 1.11, 1.111, 1.1111];

    println!("Sequence converges: {}", convergence.check_convergence(&sequence));
    if let Some(limit) = convergence.limit(&sequence) {
        println!("Limit: {}", limit);
    }

    // å‡½æ•°åºåˆ—ç¤ºä¾‹ / Function sequence example
    let mut fs = FunctionSequence::new();
    fs.add_function(|x| x);
    fs.add_function(|x| x + 0.1);
    fs.add_function(|x| x + 0.11);
    fs.add_function(|x| x + 0.111);

    let x = 1.0;
    let values = fs.evaluate_at(x);
    println!("Function values at x={}: {:?}", x, values);

    let converges = fs.check_pointwise_convergence(x, 1.111, 1e-3);
    println!("Pointwise convergence at x={}: {}", x, converges);
}
```

## å®ç°ç¤ºä¾‹ / Implementation Examples

### æ¦‚ç‡åˆ†å¸ƒ / Probability Distributions

```rust
// æ¦‚ç‡åˆ†å¸ƒç‰¹è´¨ / Probability Distribution Trait
trait ProbabilityDistribution {
    fn pdf(&self, x: f64) -> f64;
    fn cdf(&self, x: f64) -> f64;
    fn mean(&self) -> f64;
    fn variance(&self) -> f64;
    fn sample(&self) -> f64;
}

// æ­£æ€åˆ†å¸ƒ / Normal Distribution
struct NormalDistribution {
    mean: f64,
    std_dev: f64,
}

impl NormalDistribution {
    fn new(mean: f64, std_dev: f64) -> Self {
        NormalDistribution { mean, std_dev }
    }

    fn standard_normal() -> Self {
        NormalDistribution::new(0.0, 1.0)
    }
}

impl ProbabilityDistribution for NormalDistribution {
    fn pdf(&self, x: f64) -> f64 {
        let z = (x - self.mean) / self.std_dev;
        (1.0 / (self.std_dev * (2.0 * std::f64::consts::PI).sqrt())) *
        (-0.5 * z * z).exp()
    }

    fn cdf(&self, x: f64) -> f64 {
        let z = (x - self.mean) / self.std_dev;
        0.5 * (1.0 + erf(z / 2.0_f64.sqrt()))
    }

    fn mean(&self) -> f64 {
        self.mean
    }

    fn variance(&self) -> f64 {
        self.std_dev * self.std_dev
    }

    fn sample(&self) -> f64 {
        let mut rng = rand::thread_rng();
        let u1: f64 = rng.gen();
        let u2: f64 = rng.gen();

        // Box-Mullerå˜æ¢ / Box-Muller transform
        let z0 = (-2.0 * u1.ln()).sqrt() * (2.0 * std::f64::consts::PI * u2).cos();
        self.mean + self.std_dev * z0
    }
}

// è¯¯å·®å‡½æ•° / Error Function
fn erf(x: f64) -> f64 {
    let a1 =  0.254829592;
    let a2 = -0.284496736;
    let a3 =  1.421413741;
    let a4 = -1.453152027;
    let a5 =  1.061405429;
    let p  =  0.3275911;

    let sign = if x < 0.0 { -1.0 } else { 1.0 };
    let x = x.abs();

    let t = 1.0 / (1.0 + p * x);
    let y = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * (-x * x).exp();

    sign * y
}

// æŒ‡æ•°åˆ†å¸ƒ / Exponential Distribution
struct ExponentialDistribution {
    lambda: f64,
}

impl ExponentialDistribution {
    fn new(lambda: f64) -> Self {
        ExponentialDistribution { lambda }
    }
}

impl ProbabilityDistribution for ExponentialDistribution {
    fn pdf(&self, x: f64) -> f64 {
        if x >= 0.0 {
            self.lambda * (-self.lambda * x).exp()
        } else {
            0.0
        }
    }

    fn cdf(&self, x: f64) -> f64 {
        if x >= 0.0 {
            1.0 - (-self.lambda * x).exp()
        } else {
            0.0
        }
    }

    fn mean(&self) -> f64 {
        1.0 / self.lambda
    }

    fn variance(&self) -> f64 {
        1.0 / (self.lambda * self.lambda)
    }

    fn sample(&self) -> f64 {
        let mut rng = rand::thread_rng();
        let u: f64 = rng.gen();
        -u.ln() / self.lambda
    }
}

fn main() {
    // æ­£æ€åˆ†å¸ƒç¤ºä¾‹ / Normal distribution example
    let normal = NormalDistribution::new(0.0, 1.0);
    println!("Normal PDF at 0: {}", normal.pdf(0.0));
    println!("Normal CDF at 0: {}", normal.cdf(0.0));
    println!("Normal mean: {}", normal.mean());
    println!("Normal variance: {}", normal.variance());
    println!("Normal sample: {}", normal.sample());

    // æŒ‡æ•°åˆ†å¸ƒç¤ºä¾‹ / Exponential distribution example
    let exponential = ExponentialDistribution::new(1.0);
    println!("Exponential PDF at 1: {}", exponential.pdf(1.0));
    println!("Exponential CDF at 1: {}", exponential.cdf(1.0));
    println!("Exponential mean: {}", exponential.mean());
    println!("Exponential variance: {}", exponential.variance());
    println!("Exponential sample: {}", exponential.sample());
}
```

## å‚è€ƒæ–‡çŒ® / References

æœ¬æ–‡æ¡£åŸºäºå·²å‘è¡¨çš„å­¦æœ¯æ–‡çŒ®å’Œå…¬å¼€èµ„æ–™ç¼–å†™ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦å‚è€ƒæ–‡çŒ®ï¼š

**æµ‹åº¦è®ºåŸºç¡€ / Measure Theory Foundations**:

1. [Rudin1987] Rudin, W. (1987). *Real and Complex Analysis* (3rd Edition). McGraw-Hill. ISBN: 978-0070542341.
   - é«˜ç­‰åˆ†æçš„æƒå¨æ•™æï¼Œæµ‹åº¦è®ºå’Œç§¯åˆ†ç†è®ºçš„æ ‡å‡†å‚è€ƒï¼Œæ¶µç›–Ïƒ-ä»£æ•°ã€Lebesgueæµ‹åº¦å’Œæ”¶æ•›å®šç†ã€‚

2. [Folland1999] Folland, G. B. (1999). *Real Analysis: Modern Techniques and Their Applications* (2nd Edition). Wiley. ISBN: 978-0471317166.
   - ç°ä»£æµ‹åº¦è®ºå’Œç§¯åˆ†ç†è®ºæ•™æï¼Œè¯¦ç»†ä»‹ç»æµ‹åº¦ç©ºé—´ã€å¯æµ‹å‡½æ•°å’ŒRadon-Nikodymå®šç†ã€‚

3. [Royden2010] Royden, H. L., & Fitzpatrick, P. (2010). *Real Analysis* (4th Edition). Pearson. ISBN: 978-0131437470.
   - å®åˆ†æçš„æ ‡å‡†æ•™æï¼Œæ¸…æ™°ä»‹ç»æµ‹åº¦è®ºå’ŒLebesgueç§¯åˆ†ï¼Œé€‚åˆæœ¬ç§‘é«˜å¹´çº§å’Œç ”ç©¶ç”Ÿã€‚

**æ¦‚ç‡æµ‹åº¦ç†è®º / Probability Measure Theory**:

1. [Billingsley2012] Billingsley, P. (2012). *Probability and Measure* (Anniversary Edition). Wiley. ISBN: 978-1118122372.
   - ä¸¥æ ¼çš„æ¦‚ç‡è®ºæ•™æï¼ŒåŸºäºæµ‹åº¦è®ºæ–¹æ³•ï¼Œè¯¦ç»†ä»‹ç»æ¦‚ç‡ç©ºé—´å’Œéšæœºå˜é‡ã€‚

2. [Williams1991] Williams, D. (1991). *Probability with Martingales*. Cambridge University Press. ISBN: 978-0521406055.
   - ç°ä»£æ¦‚ç‡è®ºæ•™æï¼Œå¼ºè°ƒæµ‹åº¦è®ºåŸºç¡€å’Œé…ç†è®ºã€‚

**ç§¯åˆ†ç†è®º / Integration Theory**:

1. [Rudin1976] Rudin, W. (1976). *Principles of Mathematical Analysis* (3rd Edition). McGraw-Hill. ISBN: 978-0070542358.
   - ç»å…¸çš„å®åˆ†ææ•™æï¼Œä»‹ç»Riemannç§¯åˆ†å’Œä¸€è‡´æ”¶æ•›ã€‚

2. [Apostol1974] Apostol, T. M. (1974). *Mathematical Analysis* (2nd Edition). Addison-Wesley. ISBN: 978-0201002881.
   - ç»å…¸çš„æ•°å­¦åˆ†ææ•™æï¼Œè¯¦ç»†ä»‹ç»ç§¯åˆ†ç†è®ºå’Œæ”¶æ•›å®šç†ã€‚

**ç®—æ³•åº”ç”¨ / Algorithm Applications**:

1. [Motwani1995] Motwani, R., & Raghavan, P. (1995). *Randomized Algorithms*. Cambridge University Press. ISBN: 978-0521474658.
   - éšæœºç®—æ³•çš„ç»å…¸æ•™æï¼Œä»‹ç»æ¦‚ç‡æµ‹åº¦åœ¨ç®—æ³•åˆ†æä¸­çš„åº”ç”¨ã€‚

2. [MitzenmacherUpfal2005] Mitzenmacher, M., & Upfal, E. (2005). *Probability and Computing: Randomized Algorithms and Probabilistic Analysis*. Cambridge University Press. ISBN: 978-0521835404.
   - æ¦‚ç‡ä¸è®¡ç®—çš„ç»¼åˆæ•™æï¼Œæµ‹åº¦è®ºåœ¨æ¦‚ç‡ç®—æ³•ä¸­çš„åº”ç”¨ã€‚

**å»¶ä¼¸é˜…è¯» / Further Reading**:

1. [Ash2000] Ash, R. B. (2000). *Probability and Measure Theory* (2nd Edition). Academic Press.
   - æ¦‚ç‡è®ºå’Œæµ‹åº¦è®ºçš„ç»¼åˆæ•™æã€‚

2. [Tao2011] Tao, T. (2011). *An Introduction to Measure Theory*. American Mathematical Society.
   - æµ‹åº¦è®ºçš„ç°ä»£å¯¼å¼•ï¼Œæ¸…æ™°æ˜“æ‡‚ã€‚

**å¼•ç”¨è§„èŒƒè¯´æ˜ / Citation Guidelines**:

æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®å¼•ç”¨è§„èŒƒï¼ˆè§ `docs/å¼•ç”¨è§„èŒƒä¸æ•°æ®åº“.md`ï¼‰ã€‚æ‰€æœ‰å¼•ç”¨æ¡ç›®åœ¨ `docs/references_database.yaml` ä¸­æœ‰å®Œæ•´è®°å½•ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.1
**æœ€åæ›´æ–° / Last Updated**: 2025-10-11
**çŠ¶æ€ / Status**: å·²æ·»åŠ å­¦æœ¯å¼•ç”¨ / Academic citations added

---

*æœ¬æ–‡æ¡£æä¾›äº†æµ‹åº¦è®ºçš„åŸºç¡€ç†è®ºåŠå…¶åœ¨ç®—æ³•ä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬Ïƒ-ä»£æ•°ã€æµ‹åº¦ã€å¯æµ‹å‡½æ•°ã€ç§¯åˆ†ç­‰æ ¸å¿ƒæ¦‚å¿µï¼Œä»¥åŠå®ƒä»¬åœ¨æ¦‚ç‡ç®—æ³•ã€æ•°å€¼ç§¯åˆ†ã€æ¦‚ç‡åˆ†å¸ƒç­‰ç®—æ³•ä¸­çš„å…·ä½“åº”ç”¨ã€‚*
