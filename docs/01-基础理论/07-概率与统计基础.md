---
title: 1.7 æ¦‚ç‡ä¸ç»Ÿè®¡åŸºç¡€ / Probability and Statistics Fundamentals
version: 1.1
status: maintained
last_updated: 2025-01-11
owner: åŸºç¡€ç†è®ºå·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)

## 1.7 æ¦‚ç‡ä¸ç»Ÿè®¡åŸºç¡€ / Probability and Statistics Fundamentals

### æ‘˜è¦ / Executive Summary

- å»ºç«‹æ¦‚ç‡ä¸ç»Ÿè®¡çš„åŸºç¡€ç†è®ºï¼Œç»Ÿä¸€æ¦‚ç‡ç©ºé—´ã€éšæœºå˜é‡ã€åˆ†å¸ƒç­‰æ ¸å¿ƒæ¦‚å¿µã€‚
- å»ºç«‹æ¦‚ç‡ä¸ç»Ÿè®¡åœ¨éšæœºç®—æ³•ç†è®ºä¸­çš„åŸºç¡€åœ°ä½ã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- æ¦‚ç‡ç©ºé—´ã€éšæœºå˜é‡ã€åˆ†å¸ƒã€æœŸæœ›ã€æ–¹å·®ã€æ¡ä»¶æ¦‚ç‡ã€ç‹¬ç«‹æ€§ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology & Notation

- æ¦‚ç‡ç©ºé—´ï¼ˆProbability Spaceï¼‰ï¼šç”±æ ·æœ¬ç©ºé—´ã€äº‹ä»¶åŸŸå’Œæ¦‚ç‡æµ‹åº¦ç»„æˆçš„ä¸‰å…ƒç»„ã€‚
- éšæœºå˜é‡ï¼ˆRandom Variableï¼‰ï¼šä»æ ·æœ¬ç©ºé—´åˆ°å®æ•°çš„æ˜ å°„ã€‚
- åˆ†å¸ƒï¼ˆDistributionï¼‰ï¼šéšæœºå˜é‡çš„æ¦‚ç‡åˆ†å¸ƒã€‚
- æœŸæœ›ï¼ˆExpectationï¼‰ï¼šéšæœºå˜é‡çš„å¹³å‡å€¼ã€‚
- è®°å·çº¦å®šï¼š`Î©` è¡¨ç¤ºæ ·æœ¬ç©ºé—´ï¼Œ`P` è¡¨ç¤ºæ¦‚ç‡ï¼Œ`E[X]` è¡¨ç¤ºæœŸæœ›ï¼Œ`Var(X)` è¡¨ç¤ºæ–¹å·®ã€‚

### äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References

- æ•°å­¦åŸºç¡€ï¼šå‚è§ `01-åŸºç¡€ç†è®º/02-æ•°å­¦åŸºç¡€.md`ã€‚
- æµ‹åº¦è®ºåŸºç¡€ï¼šå‚è§ `01-åŸºç¡€ç†è®º/11-æµ‹åº¦è®ºåŸºç¡€.md`ã€‚
- éšæœºç®—æ³•ï¼šå‚è§ `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/11-éšæœºç®—æ³•ç†è®º.md`ã€‚

### å¿«é€Ÿå¯¼èˆª / Quick Links

- åŸºæœ¬æ¦‚å¿µ
- æ¦‚ç‡ç©ºé—´
- éšæœºå˜é‡

## ç›®å½• (Table of Contents)

- [1.7 æ¦‚ç‡ä¸ç»Ÿè®¡åŸºç¡€ / Probability and Statistics Fundamentals](#17-æ¦‚ç‡ä¸ç»Ÿè®¡åŸºç¡€--probability-and-statistics-fundamentals)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology \& Notation](#æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ--terminology--notation)
  - [äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References](#äº¤å‰å¼•ç”¨å¯¼èˆª--cross-references)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½• (Table of Contents)](#ç›®å½•-table-of-contents)
- [æ¦‚è¿° / Overview](#æ¦‚è¿°--overview)
- [æ¦‚ç‡ç©ºé—´ / Probability Space](#æ¦‚ç‡ç©ºé—´--probability-space)
- [éšæœºå˜é‡ä¸åˆ†å¸ƒ / Random Variables and Distributions](#éšæœºå˜é‡ä¸åˆ†å¸ƒ--random-variables-and-distributions)
- [æœŸæœ›ä¸æ–¹å·® / Expectation and Variance](#æœŸæœ›ä¸æ–¹å·®--expectation-and-variance)
- [å¤§æ•°ä¸ä¸­å¿ƒæé™å®šç† / LLN and CLT](#å¤§æ•°ä¸ä¸­å¿ƒæé™å®šç†--lln-and-clt)
- [é›†ä¸­ä¸ç­‰å¼ / Concentration Inequalities](#é›†ä¸­ä¸ç­‰å¼--concentration-inequalities)
- [è’™ç‰¹å¡æ´›ä¸é‡‡æ · / Monte Carlo and Sampling](#è’™ç‰¹å¡æ´›ä¸é‡‡æ ·--monte-carlo-and-sampling)
- [ä¼°è®¡ä¸ç½®ä¿¡åŒºé—´ / Estimation and Confidence Intervals](#ä¼°è®¡ä¸ç½®ä¿¡åŒºé—´--estimation-and-confidence-intervals)
- [éšæœºç®—æ³•ä¸­çš„åº”ç”¨ / Applications in Randomized Algorithms](#éšæœºç®—æ³•ä¸­çš„åº”ç”¨--applications-in-randomized-algorithms)
- [å‚è€ƒæ–‡çŒ® / References](#å‚è€ƒæ–‡çŒ®--references)
- [æœ¯è¯­å¯¹ç…§è¡¨ / Terminology Reference](#æœ¯è¯­å¯¹ç…§è¡¨--terminology-reference)
- [ç»ƒä¹ ä¸ä¹ é¢˜ / Exercises and Problems](#ç»ƒä¹ ä¸ä¹ é¢˜--exercises-and-problems)
  - [åŸºç¡€ç»ƒä¹  / Basic Exercises](#åŸºç¡€ç»ƒä¹ --basic-exercises)
  - [è¿›é˜¶ç»ƒä¹  / Advanced Exercises](#è¿›é˜¶ç»ƒä¹ --advanced-exercises)
  - [ç¼–ç¨‹ç»ƒä¹  / Programming Exercises](#ç¼–ç¨‹ç»ƒä¹ --programming-exercises)
  - [åº”ç”¨ç»ƒä¹  / Application Exercises](#åº”ç”¨ç»ƒä¹ --application-exercises)

## æ¦‚è¿° / Overview

æ¦‚ç‡ä¸ç»Ÿè®¡ä¸ºéšæœºç®—æ³•ã€å­¦ä¹ ç†è®ºä¸å¤æ‚åº¦åˆ†ææä¾›æ•°å­¦åŸºç¡€ã€‚æœ¬ç« è¦†ç›–æ¦‚ç‡ç©ºé—´ã€éšæœºå˜é‡ã€æœŸæœ›ä¸æ–¹å·®ã€å¸¸è§åˆ†å¸ƒã€é›†ä¸­ä¸ç­‰å¼ä¸é‡‡æ ·æ–¹æ³•ã€‚

Probability and statistics provide the mathematical foundations for randomized algorithms, learning theory, and complexity analysis. This chapter covers probability spaces, random variables, expectation and variance, common distributions, concentration inequalities, and sampling methods.

## æ¦‚ç‡ç©ºé—´ / Probability Space

**å®šä¹‰ 1.1** æ¦‚ç‡ç©ºé—´ä¸ºä¸‰å…ƒç»„ $(\Omega, \mathcal{F}, \mathbb{P})$ï¼Œå…¶ä¸­æ ·æœ¬ç©ºé—´ $\Omega$ã€äº‹ä»¶åŸŸ $\mathcal{F}$ ä¸æ¦‚ç‡æµ‹åº¦ $\mathbb{P}$ã€‚

A probability space is a triple $(\Omega, \mathcal{F}, \mathbb{P})$ with sample space $\Omega$, sigma-algebra $\mathcal{F}$, and probability measure $\mathbb{P}$.

## éšæœºå˜é‡ä¸åˆ†å¸ƒ / Random Variables and Distributions

- éšæœºå˜é‡ Random variable: $X: (\Omega, \mathcal{F}) \to (\mathbb{R}, \mathcal{B})$
- åˆ†å¸ƒå‡½æ•° CDF: $F_X(x) = \mathbb{P}(X \le x)$; æ¦‚ç‡å¯†åº¦ PDFï¼ˆè¿ç»­æƒ…å½¢ï¼‰
- å¸¸è§åˆ†å¸ƒï¼šä¼¯åŠªåˆ©ã€äºŒé¡¹ã€æ³Šæ¾ã€å‡ ä½•ï¼›å‡åŒ€ã€é«˜æ–¯ã€æŒ‡æ•°ã€ä¼½é©¬

## æœŸæœ›ä¸æ–¹å·® / Expectation and Variance

- æœŸæœ› Expectation: $\mathbb{E}[X]$
- æ–¹å·® Variance: $\mathrm{Var}(X)=\mathbb{E}[(X-\mathbb{E}[X])^2]$
- çº¿æ€§æ€§ Linearity: $\mathbb{E}[\sum_i a_i X_i] = \sum_i a_i \mathbb{E}[X_i]$
- å…¨æœŸæœ›/å…¨æ–¹å·®å®šç† Law of Total Expectation/Variance

## å¤§æ•°ä¸ä¸­å¿ƒæé™å®šç† / LLN and CLT

- å¤§æ•°å®šå¾‹ LLN: æ ·æœ¬å‡å€¼æ”¶æ•›äºæœŸæœ›
- ä¸­å¿ƒæé™å®šç† CLT: å½’ä¸€åŒ–å’Œè¶‹äºé«˜æ–¯åˆ†å¸ƒ

## é›†ä¸­ä¸ç­‰å¼ / Concentration Inequalities

- é©¬å°”å¯å¤« Markov: $\mathbb{P}(X \ge a) \le \mathbb{E}[X]/a$
- åˆ‡æ¯”é›ªå¤« Chebyshev: $\mathbb{P}(|X-\mu|\ge k\sigma) \le 1/k^2$
- Hoeffding: ç‹¬ç«‹æœ‰ç•Œéšæœºå˜é‡ä¹‹å’Œçš„å°¾ç•Œ
- Chernoff: ä¼¯åŠªåˆ©å’Œ/äºŒé¡¹çš„æŒ‡æ•°å°¾ç•Œ

```python
# Hoeffding ä¸ç­‰å¼ç»™å®šæ ·æœ¬å¯¹å‡å€¼åå·®çš„ä¸Šç•Œ
import math

def hoeffding_bound(n, R, eps):
    # n: æ ·æœ¬æ•°ï¼ŒR: æ¯ä¸ªæ ·æœ¬å–å€¼èŒƒå›´å®½åº¦ï¼ˆb-aï¼‰ï¼Œeps: åå·®
    return math.exp(-2*n*eps*eps/(R*R))
```

## è’™ç‰¹å¡æ´›ä¸é‡‡æ · / Monte Carlo and Sampling

- ç‹¬ç«‹åŒåˆ†å¸ƒé‡‡æ · IID sampling
- æ‹’ç»é‡‡æ · Rejection sampling
- é‡è¦æ€§é‡‡æ · Importance sampling
- MCMCï¼ˆMetropolis-Hastingsã€Gibbsï¼‰

```python
# æ‹’ç»é‡‡æ ·ï¼šä»ç›®æ ‡å¯†åº¦ï¼ˆæœªå½’ä¸€åŒ–ï¼‰é‡‡æ ·
import random, math

def rejection_sampling(unnormalized_log_pdf, proposal_sampler, log_M):
    while True:
        x = proposal_sampler()
        # æ¯”è¾ƒ u <= target(x)/(M*proposal(x)) çš„å¯¹æ•°ç­‰ä»·
        u = random.random()
        if math.log(u) <= unnormalized_log_pdf(x) - log_M:
            return x
```

## ä¼°è®¡ä¸ç½®ä¿¡åŒºé—´ / Estimation and Confidence Intervals

- ç‚¹ä¼°è®¡ä¸æ— åæ€§ã€æ–¹å·®ä¸å‡æ–¹è¯¯å·®
- åŒºé—´ä¼°è®¡ï¼šæ­£æ€å‡å€¼å·²çŸ¥/æœªçŸ¥æ–¹å·®ï¼ŒäºŒé¡¹æ¯”ä¾‹çš„æ­£æ€è¿‘ä¼¼ä¸Clopper-Pearson

## éšæœºç®—æ³•ä¸­çš„åº”ç”¨ / Applications in Randomized Algorithms

- éšæœºåŒ–å¿«é€Ÿé€‰æ‹©/å¿«é€Ÿæ’åºçš„æœŸæœ›å¤æ‚åº¦
- éšæœºå›¾ç®—æ³•ä¸é˜ˆå€¼ç°è±¡
- å¸ƒéš†è¿‡æ»¤å™¨ä¸å“ˆå¸Œåˆ†æï¼ˆè´Ÿè½½ã€å†²çªæ¦‚ç‡ï¼‰

```python
# éšæœºåŒ–å¿«é€Ÿé€‰æ‹©ï¼ˆæœŸæœ›çº¿æ€§ï¼‰
import random

def randomized_select(arr, k):
    if len(arr) == 1:
        return arr[0]
    pivot = random.choice(arr)
    left = [x for x in arr if x < pivot]
    mid = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    if k < len(left):
        return randomized_select(left, k)
    elif k < len(left) + len(mid):
        return pivot
    else:
        return randomized_select(right, k - len(left) - len(mid))
```

## å‚è€ƒæ–‡çŒ® / References

æœ¬æ–‡æ¡£åŸºäºå·²å‘è¡¨çš„å­¦æœ¯æ–‡çŒ®å’Œå…¬å¼€èµ„æ–™ç¼–å†™ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦å‚è€ƒæ–‡çŒ®ï¼š

**æ¦‚ç‡è®ºåŸºç¡€ / Probability Theory Foundations**:

1. [Billingsley2012] Billingsley, P. (2012). *Probability and Measure* (Anniversary Edition). Wiley. ISBN: 978-1118122372.
   - ä¸¥æ ¼çš„æ¦‚ç‡è®ºæ•™æï¼ŒåŸºäºæµ‹åº¦è®ºæ–¹æ³•ã€‚æä¾›äº†æ¦‚ç‡ç©ºé—´ã€éšæœºå˜é‡ã€æœŸæœ›å€¼çš„å®Œæ•´æ•°å­¦å¤„ç†ã€‚

2. [Williams1991] Williams, D. (1991). *Probability with Martingales*. Cambridge University Press. ISBN: 978-0521406055.
   - ç°ä»£æ¦‚ç‡è®ºæ•™æï¼Œå¼ºè°ƒé…æ–¹æ³•ã€‚ä»¥ç®€æ´æ¸…æ™°çš„æ–¹å¼ä»‹ç»äº†æ¡ä»¶æœŸæœ›ã€é…æ”¶æ•›å®šç†ç­‰æ ¸å¿ƒæ¦‚å¿µã€‚

3. [GrimmettStirzaker2001] Grimmett, G. R., & Stirzaker, D. R. (2001). *Probability and Random Processes* (3rd Edition). Oxford University Press. ISBN: 978-0198572237.
   - æ¦‚ç‡è®ºä¸éšæœºè¿‡ç¨‹çš„ç»¼åˆæ•™æï¼Œæ¶µç›–ç¦»æ•£å’Œè¿ç»­æ¦‚ç‡æ¨¡å‹ï¼ŒåŒ…å«ä¸°å¯Œçš„ä¾‹é¢˜å’Œåº”ç”¨ã€‚

**ç»Ÿè®¡æ¨æ–­ / Statistical Inference**:

1. [Wasserman2004] Wasserman, L. (2004). *All of Statistics: A Concise Course in Statistical Inference*. Springer. ISBN: 978-0387402727.
   - ç»Ÿè®¡å­¦çš„ç®€æ˜æ•™ç¨‹ï¼Œé€‚åˆè®¡ç®—æœºç§‘å­¦èƒŒæ™¯ã€‚æ¶µç›–ä¼°è®¡ã€ç½®ä¿¡åŒºé—´ã€å‡è®¾æ£€éªŒå’Œè´å¶æ–¯æ–¹æ³•ã€‚

**é›†ä¸­ä¸ç­‰å¼ä¸é«˜ç»´æ¦‚ç‡ / Concentration and High-Dimensional Probability**:

1. [Vershynin2018] Vershynin, R. (2018). *High-Dimensional Probability: An Introduction with Applications in Data Science*. Cambridge University Press. ISBN: 978-1108415194.
   - é«˜ç»´æ¦‚ç‡è®ºçš„ç°ä»£æ•™æï¼Œè¯¦ç»†ä»‹ç»äº†é›†ä¸­ä¸ç­‰å¼ï¼ˆMarkovã€Chebyshevã€Hoeffdingã€Chernoffç­‰ï¼‰åŠå…¶åœ¨æ•°æ®ç§‘å­¦ä¸­çš„åº”ç”¨ã€‚
   - åœ¨çº¿ç‰ˆæœ¬ï¼š<https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.html>

**ç®—æ³•åº”ç”¨ / Algorithm Applications**:

1. [CLRS2009] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). *Introduction to Algorithms* (3rd Edition). MIT Press. ISBN: 978-0262033848.
   - ç®—æ³•å¯¼è®ºï¼ŒåŒ…å«éšæœºç®—æ³•ã€æ¦‚ç‡åˆ†æå’Œé›†ä¸­ä¸ç­‰å¼åœ¨ç®—æ³•å¤æ‚åº¦åˆ†æä¸­çš„åº”ç”¨ã€‚

2. [Arora2009] Arora, S., & Barak, B. (2009). *Computational Complexity: A Modern Approach*. Cambridge University Press. ISBN: 978-0521424264.
   - è®¡ç®—å¤æ‚æ€§ç†è®ºæ•™æï¼Œè®¨è®ºæ¦‚ç‡æ–¹æ³•åœ¨å¤æ‚åº¦ç†è®ºä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬éšæœºç®—æ³•å’Œæ¦‚ç‡è¯æ˜ã€‚

**å»¶ä¼¸é˜…è¯» / Further Reading**:

1. Feller, W. (1968). *An Introduction to Probability Theory and Its Applications* (Vol. 1, 3rd Edition). Wiley.
   - æ¦‚ç‡è®ºçš„ç»å…¸æ•™æï¼Œä»¥ç›´è§‚çš„æ–¹å¼ä»‹ç»æ¦‚ç‡åŸºç¡€ã€‚

2. Durrett, R. (2019). *Probability: Theory and Examples* (5th Edition). Cambridge University Press.
   - æ¦‚ç‡è®ºçš„é«˜çº§æ•™æï¼ŒåŒ…å«å¤§é‡ä¾‹é¢˜å’Œåº”ç”¨ã€‚

3. Ross, S. M. (2014). *A First Course in Probability* (9th Edition). Pearson.
    - æ¦‚ç‡è®ºçš„å…¥é—¨æ•™æï¼Œé€‚åˆåˆå­¦è€…ã€‚

**åœ¨çº¿èµ„æº / Online Resources**:

1. **Wikipedia - Probability Theory**: <https://en.wikipedia.org/wiki/Probability_theory>
   - æ¦‚ç‡è®ºçš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«æ¦‚ç‡ç©ºé—´ã€éšæœºå˜é‡ç­‰æ ¸å¿ƒæ¦‚å¿µï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰ã€‚

2. **Wikipedia - Statistics**: <https://en.wikipedia.org/wiki/Statistics>
   - ç»Ÿè®¡å­¦çš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»ç»Ÿè®¡æ¨æ–­å’Œæ•°æ®åˆ†æï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰ã€‚

3. **Wikipedia - Probability Distribution**: <https://en.wikipedia.org/wiki/Probability_distribution>
   - æ¦‚ç‡åˆ†å¸ƒçš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«ç¦»æ•£å’Œè¿ç»­åˆ†å¸ƒï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰ã€‚

**å¼•ç”¨è§„èŒƒè¯´æ˜ / Citation Guidelines**:

æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®å¼•ç”¨è§„èŒƒï¼ˆè§ `docs/å¼•ç”¨è§„èŒƒä¸æ•°æ®åº“.md`ï¼‰ã€‚æ‰€æœ‰å¼•ç”¨æ¡ç›®åœ¨ `docs/references_database.yaml` ä¸­æœ‰å®Œæ•´è®°å½•ã€‚

æœ¬æ–‡æ¡£å†…å®¹å·²å¯¹ç…§Wikipediaç›¸å…³æ¡ç›®ï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æœ¯è¯­å®šä¹‰å’Œç†è®ºæ¡†æ¶ä¸å½“å‰å­¦æœ¯æ ‡å‡†ä¸€è‡´ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.1
**æœ€åæ›´æ–° / Last Updated**: 2025-11-14
**çŠ¶æ€ / Status**: å·²å¯¹ç…§Wikipediaæ›´æ–° / Updated with Wikipedia references (as of 2025-11-14)

## æœ¯è¯­å¯¹ç…§è¡¨ / Terminology Reference

| ä¸­æ–‡æœ¯è¯­ | English Term | å®šä¹‰/è¯´æ˜ |
|---------|-------------|----------|
| æ¦‚ç‡ç©ºé—´ | Probability Space | $(\Omega, \mathcal{F}, \mathbb{P})$ ä¸‰å…ƒç»„ |
| éšæœºå˜é‡ | Random Variable | $X: \Omega \to \mathbb{R}$ çš„å¯æµ‹å‡½æ•° |
| åˆ†å¸ƒå‡½æ•° | Cumulative Distribution Function | $F_X(x) = \mathbb{P}(X \le x)$ |
| æ¦‚ç‡å¯†åº¦ | Probability Density Function | è¿ç»­éšæœºå˜é‡çš„å¯¼æ•° $f_X(x) = F_X'(x)$ |
| æœŸæœ› | Expectation | $\mathbb{E}[X] = \int x dF_X(x)$ |
| æ–¹å·® | Variance | $\text{Var}(X) = \mathbb{E}[(X-\mathbb{E}[X])^2]$ |
| åæ–¹å·® | Covariance | $\text{Cov}(X,Y) = \mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]$ |
| å¤§æ•°å®šå¾‹ | Law of Large Numbers | æ ·æœ¬å‡å€¼æ”¶æ•›äºæœŸæœ› |
| ä¸­å¿ƒæé™å®šç† | Central Limit Theorem | å½’ä¸€åŒ–å’Œè¶‹äºæ­£æ€åˆ†å¸ƒ |
| é©¬å°”å¯å¤«ä¸ç­‰å¼ | Markov's Inequality | $\mathbb{P}(X \ge a) \le \mathbb{E}[X]/a$ |
| åˆ‡æ¯”é›ªå¤«ä¸ç­‰å¼ | Chebyshev's Inequality | $\mathbb{P}(\|X-\mu\|\ge k\sigma) \le 1/k^2$ |
| éœå¤«ä¸ä¸ç­‰å¼ | Hoeffding's Inequality | æœ‰ç•Œéšæœºå˜é‡å’Œçš„å°¾ç•Œ |
| è’™ç‰¹å¡æ´›æ–¹æ³• | Monte Carlo Method | åŸºäºéšæœºé‡‡æ ·çš„æ•°å€¼æ–¹æ³• |

## ç»ƒä¹ ä¸ä¹ é¢˜ / Exercises and Problems

### åŸºç¡€ç»ƒä¹  / Basic Exercises

**ç»ƒä¹  1.1** / **Exercise 1.1**
è¯æ˜ï¼šå¯¹äºä»»æ„éšæœºå˜é‡ $X$ï¼Œæœ‰ $\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2$ã€‚

Prove: For any random variable $X$, we have $\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2$.

**ç»ƒä¹  1.2** / **Exercise 1.2**
è®¡ç®—äºŒé¡¹åˆ†å¸ƒ $B(n,p)$ çš„æœŸæœ›å’Œæ–¹å·®ã€‚

Calculate the expectation and variance of the binomial distribution $B(n,p)$.

**ç»ƒä¹  1.3** / **Exercise 1.3**
è¯æ˜ï¼šå¦‚æœ $X$ å’Œ $Y$ ç‹¬ç«‹ï¼Œåˆ™ $\text{Cov}(X,Y) = 0$ã€‚

Prove: If $X$ and $Y$ are independent, then $\text{Cov}(X,Y) = 0$.

### è¿›é˜¶ç»ƒä¹  / Advanced Exercises

**ç»ƒä¹  2.1** / **Exercise 2.1**
ä½¿ç”¨åˆ‡æ¯”é›ªå¤«ä¸ç­‰å¼è¯æ˜å¤§æ•°å®šå¾‹ã€‚

Use Chebyshev's inequality to prove the law of large numbers.

**ç»ƒä¹  2.2** / **Exercise 2.2**
è¯æ˜ï¼šå¯¹äºç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ $X_1, \ldots, X_n$ï¼Œæ ·æœ¬å‡å€¼ $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$ çš„æ–¹å·®ä¸º $\text{Var}(\bar{X}) = \frac{\text{Var}(X_1)}{n}$ã€‚

Prove: For i.i.d. random variables $X_1, \ldots, X_n$, the variance of the sample mean $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$ is $\text{Var}(\bar{X}) = \frac{\text{Var}(X_1)}{n}$.

**ç»ƒä¹  2.3** / **Exercise 2.3**
ä½¿ç”¨éœå¤«ä¸ä¸ç­‰å¼åˆ†æéšæœºåŒ–ç®—æ³•çš„é”™è¯¯æ¦‚ç‡ã€‚

Use Hoeffding's inequality to analyze the error probability of randomized algorithms.

### ç¼–ç¨‹ç»ƒä¹  / Programming Exercises

**ç»ƒä¹  3.1** / **Exercise 3.1**
å®ç°æ‹’ç»é‡‡æ ·ç®—æ³•ï¼Œä»ç»™å®šçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸­é‡‡æ ·ã€‚

Implement rejection sampling to sample from a given probability density function.

**ç»ƒä¹  3.2** / **Exercise 3.2**
å®ç°è’™ç‰¹å¡æ´›ç§¯åˆ†æ–¹æ³•ï¼Œè®¡ç®—å®šç§¯åˆ† $\int_a^b f(x) dx$ã€‚

Implement Monte Carlo integration to compute the definite integral $\int_a^b f(x) dx$.

**ç»ƒä¹  3.3** / **Exercise 3.3**
å®ç°éšæœºåŒ–å¿«é€Ÿæ’åºç®—æ³•ï¼Œå¹¶åˆ†æå…¶æœŸæœ›æ—¶é—´å¤æ‚åº¦ã€‚

Implement randomized quicksort and analyze its expected time complexity.

### åº”ç”¨ç»ƒä¹  / Application Exercises

**ç»ƒä¹  4.1** / **Exercise 4.1**
ä½¿ç”¨æ¦‚ç‡æ–¹æ³•è¯æ˜ï¼šåœ¨ $n$ ä¸ªé¡¶ç‚¹çš„å›¾ä¸­ï¼Œå­˜åœ¨å¤§å°ä¸º $\Omega(\log n)$ çš„ç‹¬ç«‹é›†ã€‚

Use the probabilistic method to prove: In a graph with $n$ vertices, there exists an independent set of size $\Omega(\log n)$.

**ç»ƒä¹  4.2** / **Exercise 4.2**
è®¾è®¡ä¸€ä¸ªéšæœºåŒ–ç®—æ³•æ¥ä¼°è®¡ç½‘ç»œä¸­çš„èŠ‚ç‚¹æ•°é‡ï¼Œå¹¶åˆ†æå…¶ç²¾åº¦ã€‚

Design a randomized algorithm to estimate the number of nodes in a network and analyze its accuracy.

**ç»ƒä¹  4.3** / **Exercise 4.3**
å®ç°å¸ƒéš†è¿‡æ»¤å™¨ï¼Œå¹¶åˆ†æå…¶å‡é˜³æ€§æ¦‚ç‡ã€‚

Implement a Bloom filter and analyze its false positive probability.
