# 神经网络计算模型 / Neural Network Computational Models

## 概述 / Overview

神经网络计算模型是受生物神经系统启发的计算范式，通过互连的人工神经元网络来处理信息。这些模型具有学习、适应和泛化的能力，是机器学习和人工智能的重要基础，广泛应用于模式识别、函数逼近、数据分析等领域。

Neural network computational models are computational paradigms inspired by biological nervous systems, processing information through networks of interconnected artificial neurons. These models possess capabilities for learning, adaptation, and generalization, serving as important foundations for machine learning and artificial intelligence, with wide applications in pattern recognition, function approximation, and data analysis.

## 基本概念 / Basic Concepts

### 人工神经元 / Artificial Neuron

**定义 1.1** (人工神经元 / Artificial Neuron)
一个人工神经元是一个计算单元，它接收多个输入信号，通过加权求和并应用激活函数来产生输出。数学上表示为：
y = f(∑(wᵢxᵢ) + b)

**Definition 1.1** (Artificial Neuron)
An artificial neuron is a computational unit that receives multiple input signals, produces output through weighted summation and application of an activation function. Mathematically represented as:
y = f(∑(wᵢxᵢ) + b)

### 神经网络的组成要素 / Components of Neural Networks

1. **神经元** / Neurons
   - 网络的基本计算单元
   - 具有权重、偏置和激活函数

2. **连接** / Connections
   - 神经元之间的信息传递路径
   - 具有权重参数

3. **层次结构** / Layer Structure
   - 输入层、隐藏层、输出层
   - 前馈或循环连接

4. **学习算法** / Learning Algorithms
   - 权重更新机制
   - 监督、无监督或强化学习

## 基础神经网络实现 / Basic Neural Network Implementation

### 感知机模型 / Perceptron Model

```rust
// 感知机实现
// Perceptron implementation

use rand::Rng;

#[derive(Clone, Debug)]
pub struct Perceptron {
    weights: Vec<f64>,
    bias: f64,
    learning_rate: f64,
}

impl Perceptron {
    pub fn new(input_size: usize, learning_rate: f64) -> Self {
        let mut rng = rand::thread_rng();
        let weights = (0..input_size)
            .map(|_| rng.gen_range(-1.0..1.0))
            .collect();
        
        Self {
            weights,
            bias: rng.gen_range(-1.0..1.0),
            learning_rate,
        }
    }
    
    pub fn predict(&self, inputs: &[f64]) -> f64 {
        assert_eq!(inputs.len(), self.weights.len());
        
        let weighted_sum: f64 = inputs
            .iter()
            .zip(self.weights.iter())
            .map(|(x, w)| x * w)
            .sum::<f64>() + self.bias;
        
        self.step_function(weighted_sum)
    }
    
    pub fn predict_continuous(&self, inputs: &[f64]) -> f64 {
        assert_eq!(inputs.len(), self.weights.len());
        
        let weighted_sum: f64 = inputs
            .iter()
            .zip(self.weights.iter())
            .map(|(x, w)| x * w)
            .sum::<f64>() + self.bias;
        
        self.sigmoid(weighted_sum)
    }
    
    fn step_function(&self, x: f64) -> f64 {
        if x >= 0.0 { 1.0 } else { 0.0 }
    }
    
    fn sigmoid(&self, x: f64) -> f64 {
        1.0 / (1.0 + (-x).exp())
    }
    
    pub fn train(&mut self, inputs: &[f64], target: f64) -> f64 {
        let prediction = self.predict(inputs);
        let error = target - prediction;
        
        // 权重更新
        for i in 0..self.weights.len() {
            self.weights[i] += self.learning_rate * error * inputs[i];
        }
        self.bias += self.learning_rate * error;
        
        error.abs()
    }
    
    pub fn train_epoch(&mut self, training_data: &[(Vec<f64>, f64)]) -> f64 {
        let mut total_error = 0.0;
        
        for (inputs, target) in training_data {
            total_error += self.train(inputs, *target);
        }
        
        total_error / training_data.len() as f64
    }
    
    pub fn get_weights(&self) -> &[f64] {
        &self.weights
    }
    
    pub fn get_bias(&self) -> f64 {
        self.bias
    }
}

// 感知机训练示例
pub fn perceptron_example() {
    // 训练感知机学习AND逻辑门
    let mut perceptron = Perceptron::new(2, 0.1);
    
    let training_data = vec![
        (vec![0.0, 0.0], 0.0),
        (vec![0.0, 1.0], 0.0),
        (vec![1.0, 0.0], 0.0),
        (vec![1.0, 1.0], 1.0),
    ];
    
    println!("训练AND逻辑门:");
    for epoch in 0..100 {
        let error = perceptron.train_epoch(&training_data);
        if epoch % 20 == 0 {
            println!("Epoch {}: Error = {:.4}", epoch, error);
        }
        
        if error < 0.01 {
            break;
        }
    }
    
    println!("最终权重: {:?}", perceptron.get_weights());
    println!("最终偏置: {:.4}", perceptron.get_bias());
    
    // 测试
    println!("测试结果:");
    for (inputs, expected) in &training_data {
        let prediction = perceptron.predict(inputs);
        println!("{:?} -> {:.1} (期望: {:.1})", inputs, prediction, expected);
    }
}
```

### 多层感知机 / Multi-Layer Perceptron

```rust
// 多层感知机实现
// Multi-layer perceptron implementation

#[derive(Clone, Debug)]
pub struct Layer {
    weights: Vec<Vec<f64>>,  // weights[neuron][input]
    biases: Vec<f64>,
    activations: Vec<f64>,
    inputs: Vec<f64>,
}

impl Layer {
    pub fn new(input_size: usize, output_size: usize) -> Self {
        let mut rng = rand::thread_rng();
        
        let weights = (0..output_size)
            .map(|_| {
                (0..input_size)
                    .map(|_| rng.gen_range(-1.0..1.0))
                    .collect()
            })
            .collect();
        
        let biases = (0..output_size)
            .map(|_| rng.gen_range(-1.0..1.0))
            .collect();
        
        Self {
            weights,
            biases,
            activations: vec![0.0; output_size],
            inputs: vec![0.0; input_size],
        }
    }
    
    pub fn forward(&mut self, inputs: &[f64]) -> Vec<f64> {
        assert_eq!(inputs.len(), self.weights[0].len());
        
        self.inputs = inputs.to_vec();
        
        for i in 0..self.weights.len() {
            let weighted_sum: f64 = inputs
                .iter()
                .zip(self.weights[i].iter())
                .map(|(x, w)| x * w)
                .sum::<f64>() + self.biases[i];
            
            self.activations[i] = self.sigmoid(weighted_sum);
        }
        
        self.activations.clone()
    }
    
    fn sigmoid(&self, x: f64) -> f64 {
        1.0 / (1.0 + (-x).exp())
    }
    
    fn sigmoid_derivative(&self, x: f64) -> f64 {
        let s = self.sigmoid(x);
        s * (1.0 - s)
    }
    
    pub fn get_activations(&self) -> &[f64] {
        &self.activations
    }
    
    pub fn get_weights(&self) -> &[Vec<f64>] {
        &self.weights
    }
    
    pub fn get_biases(&self) -> &[f64] {
        &self.biases
    }
}

#[derive(Clone, Debug)]
pub struct MultilayerPerceptron {
    layers: Vec<Layer>,
    learning_rate: f64,
}

impl MultilayerPerceptron {
    pub fn new(layer_sizes: &[usize], learning_rate: f64) -> Self {
        assert!(layer_sizes.len() >= 2, "至少需要输入层和输出层");
        
        let mut layers = Vec::new();
        
        for i in 0..layer_sizes.len() - 1 {
            layers.push(Layer::new(layer_sizes[i], layer_sizes[i + 1]));
        }
        
        Self {
            layers,
            learning_rate,
        }
    }
    
    pub fn forward(&mut self, inputs: &[f64]) -> Vec<f64> {
        let mut current_inputs = inputs.to_vec();
        
        for layer in &mut self.layers {
            current_inputs = layer.forward(&current_inputs);
        }
        
        current_inputs
    }
    
    pub fn train(&mut self, inputs: &[f64], targets: &[f64]) -> f64 {
        // 前向传播
        let outputs = self.forward(inputs);
        
        // 计算输出误差
        let output_errors: Vec<f64> = outputs
            .iter()
            .zip(targets.iter())
            .map(|(output, target)| target - output)
            .collect();
        
        // 反向传播
        self.backward(&output_errors);
        
        // 计算总误差
        output_errors.iter().map(|e| e * e).sum::<f64>() / 2.0
    }
    
    fn backward(&mut self, output_errors: &[f64]) {
        let num_layers = self.layers.len();
        let mut errors = output_errors.to_vec();
        
        // 从输出层向前逐层反向传播
        for layer_idx in (0..num_layers).rev() {
            let layer = &mut self.layers[layer_idx];
            let mut next_errors = vec![0.0; layer.inputs.len()];
            
            // 更新权重和偏置
            for neuron_idx in 0..layer.weights.len() {
                let activation = layer.activations[neuron_idx];
                let delta = errors[neuron_idx] * activation * (1.0 - activation);
                
                // 更新权重
                for weight_idx in 0..layer.weights[neuron_idx].len() {
                    let input_value = layer.inputs[weight_idx];
                    layer.weights[neuron_idx][weight_idx] += 
                        self.learning_rate * delta * input_value;
                    
                    // 计算传播到前一层的误差
                    next_errors[weight_idx] += delta * layer.weights[neuron_idx][weight_idx];
                }
                
                // 更新偏置
                layer.biases[neuron_idx] += self.learning_rate * delta;
            }
            
            errors = next_errors;
        }
    }
    
    pub fn train_epoch(&mut self, training_data: &[(Vec<f64>, Vec<f64>)]) -> f64 {
        let mut total_error = 0.0;
        
        for (inputs, targets) in training_data {
            total_error += self.train(inputs, targets);
        }
        
        total_error / training_data.len() as f64
    }
    
    pub fn predict(&mut self, inputs: &[f64]) -> Vec<f64> {
        self.forward(inputs)
    }
}

// XOR问题示例
pub fn xor_example() {
    let mut mlp = MultilayerPerceptron::new(&[2, 4, 1], 0.5);
    
    let training_data = vec![
        (vec![0.0, 0.0], vec![0.0]),
        (vec![0.0, 1.0], vec![1.0]),
        (vec![1.0, 0.0], vec![1.0]),
        (vec![1.0, 1.0], vec![0.0]),
    ];
    
    println!("训练XOR问题:");
    for epoch in 0..1000 {
        let error = mlp.train_epoch(&training_data);
        if epoch % 200 == 0 {
            println!("Epoch {}: Error = {:.6}", epoch, error);
        }
        
        if error < 0.001 {
            break;
        }
    }
    
    println!("测试结果:");
    for (inputs, expected) in &training_data {
        let prediction = mlp.predict(inputs);
        println!("{:?} -> {:.3} (期望: {:.1})", inputs, prediction[0], expected[0]);
    }
}
```

## 深度学习模型 / Deep Learning Models

### 卷积神经网络 / Convolutional Neural Networks

```rust
// 卷积神经网络实现
// Convolutional Neural Network implementation

#[derive(Clone, Debug)]
pub struct ConvolutionLayer {
    kernels: Vec<Vec<Vec<f64>>>,  // kernels[filter][row][col]
    biases: Vec<f64>,
    stride: usize,
    padding: usize,
    input_channels: usize,
    output_channels: usize,
    kernel_size: usize,
}

impl ConvolutionLayer {
    pub fn new(
        input_channels: usize,
        output_channels: usize,
        kernel_size: usize,
        stride: usize,
        padding: usize,
    ) -> Self {
        let mut rng = rand::thread_rng();
        
        let kernels = (0..output_channels)
            .map(|_| {
                (0..kernel_size)
                    .map(|_| {
                        (0..kernel_size)
                            .map(|_| rng.gen_range(-0.1..0.1))
                            .collect()
                    })
                    .collect()
            })
            .collect();
        
        let biases = (0..output_channels)
            .map(|_| rng.gen_range(-0.1..0.1))
            .collect();
        
        Self {
            kernels,
            biases,
            stride,
            padding,
            input_channels,
            output_channels,
            kernel_size,
        }
    }
    
    pub fn forward(&self, input: &[Vec<f64>]) -> Vec<Vec<f64>> {
        let input_height = input.len();
        let input_width = input[0].len();
        
        let output_height = (input_height + 2 * self.padding - self.kernel_size) / self.stride + 1;
        let output_width = (input_width + 2 * self.padding - self.kernel_size) / self.stride + 1;
        
        let mut output = vec![vec![0.0; output_width]; output_height];
        
        for filter_idx in 0..self.output_channels {
            for out_row in 0..output_height {
                for out_col in 0..output_width {
                    let mut sum = 0.0;
                    
                    for kernel_row in 0..self.kernel_size {
                        for kernel_col in 0..self.kernel_size {
                            let in_row = out_row * self.stride + kernel_row;
                            let in_col = out_col * self.stride + kernel_col;
                            
                            if in_row < input_height && in_col < input_width {
                                sum += input[in_row][in_col] * 
                                       self.kernels[filter_idx][kernel_row][kernel_col];
                            }
                        }
                    }
                    
                    output[out_row][out_col] = self.relu(sum + self.biases[filter_idx]);
                }
            }
        }
        
        output
    }
    
    fn relu(&self, x: f64) -> f64 {
        f64::max(0.0, x)
    }
}

#[derive(Clone, Debug)]
pub struct PoolingLayer {
    pool_size: usize,
    stride: usize,
    pooling_type: PoolingType,
}

#[derive(Clone, Debug, PartialEq)]
pub enum PoolingType {
    Max,
    Average,
}

impl PoolingLayer {
    pub fn new(pool_size: usize, stride: usize, pooling_type: PoolingType) -> Self {
        Self {
            pool_size,
            stride,
            pooling_type,
        }
    }
    
    pub fn forward(&self, input: &[Vec<f64>]) -> Vec<Vec<f64>> {
        let input_height = input.len();
        let input_width = input[0].len();
        
        let output_height = (input_height - self.pool_size) / self.stride + 1;
        let output_width = (input_width - self.pool_size) / self.stride + 1;
        
        let mut output = vec![vec![0.0; output_width]; output_height];
        
        for out_row in 0..output_height {
            for out_col in 0..output_width {
                let start_row = out_row * self.stride;
                let start_col = out_col * self.stride;
                
                let mut pool_values = Vec::new();
                for pool_row in 0..self.pool_size {
                    for pool_col in 0..self.pool_size {
                        let in_row = start_row + pool_row;
                        let in_col = start_col + pool_col;
                        
                        if in_row < input_height && in_col < input_width {
                            pool_values.push(input[in_row][in_col]);
                        }
                    }
                }
                
                output[out_row][out_col] = match self.pooling_type {
                    PoolingType::Max => {
                        pool_values.into_iter().fold(f64::NEG_INFINITY, f64::max)
                    }
                    PoolingType::Average => {
                        pool_values.iter().sum::<f64>() / pool_values.len() as f64
                    }
                };
            }
        }
        
        output
    }
}

#[derive(Clone, Debug)]
pub struct ConvolutionalNN {
    conv_layers: Vec<ConvolutionLayer>,
    pool_layers: Vec<PoolingLayer>,
    fc_layers: Vec<Layer>,
    learning_rate: f64,
}

impl ConvolutionalNN {
    pub fn new(learning_rate: f64) -> Self {
        Self {
            conv_layers: Vec::new(),
            pool_layers: Vec::new(),
            fc_layers: Vec::new(),
            learning_rate,
        }
    }
    
    pub fn add_conv_layer(&mut self, layer: ConvolutionLayer) {
        self.conv_layers.push(layer);
    }
    
    pub fn add_pool_layer(&mut self, layer: PoolingLayer) {
        self.pool_layers.push(layer);
    }
    
    pub fn add_fc_layer(&mut self, layer: Layer) {
        self.fc_layers.push(layer);
    }
    
    pub fn forward(&mut self, input: &[Vec<f64>]) -> Vec<f64> {
        let mut current_input = input.to_vec();
        
        // 卷积和池化层
        for (conv_layer, pool_layer) in self.conv_layers.iter().zip(self.pool_layers.iter()) {
            current_input = conv_layer.forward(&current_input);
            current_input = pool_layer.forward(&current_input);
        }
        
        // 展平为一维向量
        let flattened: Vec<f64> = current_input.into_iter().flatten().collect();
        
        // 全连接层
        let mut fc_input = flattened;
        for fc_layer in &mut self.fc_layers {
            fc_input = fc_layer.forward(&fc_input);
        }
        
        fc_input
    }
    
    pub fn predict(&mut self, input: &[Vec<f64>]) -> Vec<f64> {
        self.forward(input)
    }
}

// 简化的CNN示例
pub fn cnn_example() {
    let mut cnn = ConvolutionalNN::new(0.01);
    
    // 添加卷积层
    cnn.add_conv_layer(ConvolutionLayer::new(1, 16, 3, 1, 0));
    cnn.add_pool_layer(PoolingLayer::new(2, 2, PoolingType::Max));
    
    cnn.add_conv_layer(ConvolutionLayer::new(16, 32, 3, 1, 0));
    cnn.add_pool_layer(PoolingLayer::new(2, 2, PoolingType::Max));
    
    // 添加全连接层（需要根据实际输出尺寸调整）
    cnn.add_fc_layer(Layer::new(32, 10));
    
    // 创建示例输入（28x28图像）
    let input: Vec<Vec<f64>> = (0..28)
        .map(|i| {
            (0..28)
                .map(|j| if (i + j) % 2 == 0 { 1.0 } else { 0.0 })
                .collect()
        })
        .collect();
    
    let output = cnn.predict(&input);
    println!("CNN输出: {:?}", output);
}
```

## 递归神经网络 / Recurrent Neural Networks

### LSTM实现 / LSTM Implementation

```rust
// LSTM神经网络实现
// LSTM Neural Network implementation

#[derive(Clone, Debug)]
pub struct LSTMCell {
    input_size: usize,
    hidden_size: usize,
    
    // 门控权重矩阵
    w_forget: Vec<Vec<f64>>,
    w_input: Vec<Vec<f64>>,
    w_candidate: Vec<Vec<f64>>,
    w_output: Vec<Vec<f64>>,
    
    // 偏置向量
    b_forget: Vec<f64>,
    b_input: Vec<f64>,
    b_candidate: Vec<f64>,
    b_output: Vec<f64>,
    
    // 状态向量
    hidden_state: Vec<f64>,
    cell_state: Vec<f64>,
}

impl LSTMCell {
    pub fn new(input_size: usize, hidden_size: usize) -> Self {
        let mut rng = rand::thread_rng();
        
        let init_weight = |rows: usize, cols: usize| -> Vec<Vec<f64>> {
            (0..rows)
                .map(|_| {
                    (0..cols)
                        .map(|_| rng.gen_range(-0.1..0.1))
                        .collect()
                })
                .collect()
        };
        
        let total_input_size = input_size + hidden_size;
        
        Self {
            input_size,
            hidden_size,
            
            w_forget: init_weight(hidden_size, total_input_size),
            w_input: init_weight(hidden_size, total_input_size),
            w_candidate: init_weight(hidden_size, total_input_size),
            w_output: init_weight(hidden_size, total_input_size),
            
            b_forget: vec![0.0; hidden_size],
            b_input: vec![0.0; hidden_size],
            b_candidate: vec![0.0; hidden_size],
            b_output: vec![0.0; hidden_size],
            
            hidden_state: vec![0.0; hidden_size],
            cell_state: vec![0.0; hidden_size],
        }
    }
    
    pub fn forward(&mut self, input: &[f64]) -> Vec<f64> {
        assert_eq!(input.len(), self.input_size);
        
        // 拼接输入和隐藏状态
        let mut combined_input = input.to_vec();
        combined_input.extend(self.hidden_state.iter());
        
        // 遗忘门
        let forget_gate = self.sigmoid_vector(&self.linear_transform(
            &self.w_forget, &combined_input, &self.b_forget
        ));
        
        // 输入门
        let input_gate = self.sigmoid_vector(&self.linear_transform(
            &self.w_input, &combined_input, &self.b_input
        ));
        
        // 候选值
        let candidate_values = self.tanh_vector(&self.linear_transform(
            &self.w_candidate, &combined_input, &self.b_candidate
        ));
        
        // 输出门
        let output_gate = self.sigmoid_vector(&self.linear_transform(
            &self.w_output, &combined_input, &self.b_output
        ));
        
        // 更新细胞状态
        for i in 0..self.hidden_size {
            self.cell_state[i] = forget_gate[i] * self.cell_state[i] + 
                                input_gate[i] * candidate_values[i];
        }
        
        // 更新隐藏状态
        let tanh_cell_state = self.tanh_vector(&self.cell_state);
        for i in 0..self.hidden_size {
            self.hidden_state[i] = output_gate[i] * tanh_cell_state[i];
        }
        
        self.hidden_state.clone()
    }
    
    fn linear_transform(&self, weights: &[Vec<f64>], input: &[f64], bias: &[f64]) -> Vec<f64> {
        let mut output = vec![0.0; weights.len()];
        
        for i in 0..weights.len() {
            for j in 0..input.len() {
                output[i] += weights[i][j] * input[j];
            }
            output[i] += bias[i];
        }
        
        output
    }
    
    fn sigmoid(&self, x: f64) -> f64 {
        1.0 / (1.0 + (-x).exp())
    }
    
    fn sigmoid_vector(&self, vec: &[f64]) -> Vec<f64> {
        vec.iter().map(|&x| self.sigmoid(x)).collect()
    }
    
    fn tanh(&self, x: f64) -> f64 {
        x.tanh()
    }
    
    fn tanh_vector(&self, vec: &[f64]) -> Vec<f64> {
        vec.iter().map(|&x| self.tanh(x)).collect()
    }
    
    pub fn reset_state(&mut self) {
        self.hidden_state.fill(0.0);
        self.cell_state.fill(0.0);
    }
    
    pub fn get_hidden_state(&self) -> &[f64] {
        &self.hidden_state
    }
    
    pub fn get_cell_state(&self) -> &[f64] {
        &self.cell_state
    }
}

#[derive(Clone, Debug)]
pub struct LSTMNetwork {
    lstm_layers: Vec<LSTMCell>,
    output_layer: Layer,
    learning_rate: f64,
}

impl LSTMNetwork {
    pub fn new(input_size: usize, hidden_sizes: &[usize], output_size: usize, learning_rate: f64) -> Self {
        let mut lstm_layers = Vec::new();
        
        // 第一层LSTM
        lstm_layers.push(LSTMCell::new(input_size, hidden_sizes[0]));
        
        // 后续LSTM层
        for i in 1..hidden_sizes.len() {
            lstm_layers.push(LSTMCell::new(hidden_sizes[i-1], hidden_sizes[i]));
        }
        
        // 输出层
        let final_hidden_size = hidden_sizes.last().unwrap_or(&input_size);
        let output_layer = Layer::new(*final_hidden_size, output_size);
        
        Self {
            lstm_layers,
            output_layer,
            learning_rate,
        }
    }
    
    pub fn forward(&mut self, sequence: &[Vec<f64>]) -> Vec<Vec<f64>> {
        let mut outputs = Vec::new();
        
        // 重置所有LSTM层的状态
        for lstm_layer in &mut self.lstm_layers {
            lstm_layer.reset_state();
        }
        
        // 处理序列中的每个时间步
        for time_step in sequence {
            let mut current_input = time_step.clone();
            
            // 通过所有LSTM层
            for lstm_layer in &mut self.lstm_layers {
                current_input = lstm_layer.forward(&current_input);
            }
            
            // 通过输出层
            let output = self.output_layer.forward(&current_input);
            outputs.push(output);
        }
        
        outputs
    }
    
    pub fn predict(&mut self, sequence: &[Vec<f64>]) -> Vec<Vec<f64>> {
        self.forward(sequence)
    }
    
    // 简化的训练方法（实际应该实现BPTT）
    pub fn train_sequence(&mut self, input_sequence: &[Vec<f64>], target_sequence: &[Vec<f64>]) -> f64 {
        let predictions = self.forward(input_sequence);
        
        let mut total_error = 0.0;
        for (pred, target) in predictions.iter().zip(target_sequence.iter()) {
            for (p, t) in pred.iter().zip(target.iter()) {
                total_error += (t - p).powi(2);
            }
        }
        
        total_error / (predictions.len() * predictions[0].len()) as f64
    }
}

// 序列预测示例
pub fn lstm_sequence_example() {
    let mut lstm = LSTMNetwork::new(1, &[10, 10], 1, 0.01);
    
    // 生成正弦波序列数据
    let sequence_length = 20;
    let mut input_sequence = Vec::new();
    let mut target_sequence = Vec::new();
    
    for i in 0..sequence_length {
        let x = i as f64 * 0.1;
        let input_val = (x).sin();
        let target_val = (x + 0.1).sin(); // 预测下一个值
        
        input_sequence.push(vec![input_val]);
        target_sequence.push(vec![target_val]);
    }
    
    println!("训练LSTM序列预测:");
    for epoch in 0..100 {
        let error = lstm.train_sequence(&input_sequence, &target_sequence);
        if epoch % 20 == 0 {
            println!("Epoch {}: Error = {:.6}", epoch, error);
        }
    }
    
    // 测试预测
    let predictions = lstm.predict(&input_sequence);
    println!("预测结果 (前5个):");
    for i in 0..5 {
        println!("输入: {:.3}, 预测: {:.3}, 实际: {:.3}", 
            input_sequence[i][0], predictions[i][0], target_sequence[i][0]);
    }
}
```

## 学习算法理论 / Learning Algorithm Theory

### 反向传播算法 / Backpropagation Algorithm

```rust
// 梯度计算和反向传播的详细实现
// Detailed implementation of gradient computation and backpropagation

#[derive(Clone, Debug)]
pub struct BackpropagationTrainer {
    network: MultilayerPerceptron,
    momentum: f64,
    weight_decay: f64,
    previous_weight_updates: Vec<Vec<Vec<f64>>>,
    previous_bias_updates: Vec<Vec<f64>>,
}

impl BackpropagationTrainer {
    pub fn new(mut network: MultilayerPerceptron, momentum: f64, weight_decay: f64) -> Self {
        // 初始化动量项
        let mut previous_weight_updates = Vec::new();
        let mut previous_bias_updates = Vec::new();
        
        for layer in &network.layers {
            let layer_weight_updates = layer.weights
                .iter()
                .map(|row| vec![0.0; row.len()])
                .collect();
            previous_weight_updates.push(layer_weight_updates);
            
            let layer_bias_updates = vec![0.0; layer.biases.len()];
            previous_bias_updates.push(layer_bias_updates);
        }
        
        Self {
            network,
            momentum,
            weight_decay,
            previous_weight_updates,
            previous_bias_updates,
        }
    }
    
    pub fn train_with_momentum(&mut self, inputs: &[f64], targets: &[f64]) -> f64 {
        // 前向传播
        let outputs = self.network.forward(inputs);
        
        // 计算输出误差
        let output_errors: Vec<f64> = outputs
            .iter()
            .zip(targets.iter())
            .map(|(output, target)| target - output)
            .collect();
        
        // 反向传播计算梯度
        let gradients = self.compute_gradients(&output_errors);
        
        // 使用动量更新权重
        self.update_weights_with_momentum(&gradients);
        
        // 计算总误差
        output_errors.iter().map(|e| e * e).sum::<f64>() / 2.0
    }
    
    fn compute_gradients(&self, output_errors: &[f64]) -> Vec<LayerGradients> {
        let num_layers = self.network.layers.len();
        let mut all_gradients = vec![LayerGradients::new(0, 0); num_layers];
        let mut errors = output_errors.to_vec();
        
        // 从输出层向前逐层计算梯度
        for layer_idx in (0..num_layers).rev() {
            let layer = &self.network.layers[layer_idx];
            let mut weight_gradients = vec![vec![0.0; layer.weights[0].len()]; layer.weights.len()];
            let mut bias_gradients = vec![0.0; layer.biases.len()];
            let mut next_errors = vec![0.0; layer.inputs.len()];
            
            for neuron_idx in 0..layer.weights.len() {
                let activation = layer.activations[neuron_idx];
                let delta = errors[neuron_idx] * activation * (1.0 - activation);
                
                // 计算权重梯度
                for weight_idx in 0..layer.weights[neuron_idx].len() {
                    weight_gradients[neuron_idx][weight_idx] = delta * layer.inputs[weight_idx];
                    
                    // 计算传播到前一层的误差
                    next_errors[weight_idx] += delta * layer.weights[neuron_idx][weight_idx];
                }
                
                // 计算偏置梯度
                bias_gradients[neuron_idx] = delta;
            }
            
            all_gradients[layer_idx] = LayerGradients {
                weight_gradients,
                bias_gradients,
            };
            
            errors = next_errors;
        }
        
        all_gradients
    }
    
    fn update_weights_with_momentum(&mut self, gradients: &[LayerGradients]) {
        for (layer_idx, layer_gradients) in gradients.iter().enumerate() {
            let layer = &mut self.network.layers[layer_idx];
            
            // 更新权重
            for (neuron_idx, neuron_weights) in layer.weights.iter_mut().enumerate() {
                for (weight_idx, weight) in neuron_weights.iter_mut().enumerate() {
                    let gradient = layer_gradients.weight_gradients[neuron_idx][weight_idx];
                    let weight_decay_term = self.weight_decay * *weight;
                    
                    // 计算权重更新量（包含动量和权重衰减）
                    let weight_update = self.network.learning_rate * gradient - weight_decay_term +
                        self.momentum * self.previous_weight_updates[layer_idx][neuron_idx][weight_idx];
                    
                    *weight += weight_update;
                    self.previous_weight_updates[layer_idx][neuron_idx][weight_idx] = weight_update;
                }
            }
            
            // 更新偏置
            for (bias_idx, bias) in layer.biases.iter_mut().enumerate() {
                let gradient = layer_gradients.bias_gradients[bias_idx];
                
                let bias_update = self.network.learning_rate * gradient +
                    self.momentum * self.previous_bias_updates[layer_idx][bias_idx];
                
                *bias += bias_update;
                self.previous_bias_updates[layer_idx][bias_idx] = bias_update;
            }
        }
    }
    
    pub fn get_network(&self) -> &MultilayerPerceptron {
        &self.network
    }
    
    pub fn get_network_mut(&mut self) -> &mut MultilayerPerceptron {
        &mut self.network
    }
}

#[derive(Clone, Debug)]
struct LayerGradients {
    weight_gradients: Vec<Vec<f64>>,
    bias_gradients: Vec<f64>,
}

impl LayerGradients {
    fn new(num_neurons: usize, input_size: usize) -> Self {
        Self {
            weight_gradients: vec![vec![0.0; input_size]; num_neurons],
            bias_gradients: vec![0.0; num_neurons],
        }
    }
}

// 自适应学习率算法 - Adam优化器
#[derive(Clone, Debug)]
pub struct AdamOptimizer {
    network: MultilayerPerceptron,
    beta1: f64,
    beta2: f64,
    epsilon: f64,
    learning_rate: f64,
    
    // 一阶和二阶矩估计
    m_weights: Vec<Vec<Vec<f64>>>,
    v_weights: Vec<Vec<Vec<f64>>>,
    m_biases: Vec<Vec<f64>>,
    v_biases: Vec<Vec<f64>>,
    
    time_step: usize,
}

impl AdamOptimizer {
    pub fn new(network: MultilayerPerceptron, learning_rate: f64) -> Self {
        let mut m_weights = Vec::new();
        let mut v_weights = Vec::new();
        let mut m_biases = Vec::new();
        let mut v_biases = Vec::new();
        
        for layer in &network.layers {
            let layer_m_weights = layer.weights
                .iter()
                .map(|row| vec![0.0; row.len()])
                .collect();
            let layer_v_weights = layer.weights
                .iter()
                .map(|row| vec![0.0; row.len()])
                .collect();
            
            m_weights.push(layer_m_weights);
            v_weights.push(layer_v_weights);
            m_biases.push(vec![0.0; layer.biases.len()]);
            v_biases.push(vec![0.0; layer.biases.len()]);
        }
        
        Self {
            network,
            beta1: 0.9,
            beta2: 0.999,
            epsilon: 1e-8,
            learning_rate,
            m_weights,
            v_weights,
            m_biases,
            v_biases,
            time_step: 0,
        }
    }
    
    pub fn train(&mut self, inputs: &[f64], targets: &[f64]) -> f64 {
        self.time_step += 1;
        
        // 前向传播
        let outputs = self.network.forward(inputs);
        
        // 计算输出误差
        let output_errors: Vec<f64> = outputs
            .iter()
            .zip(targets.iter())
            .map(|(output, target)| target - output)
            .collect();
        
        // 计算梯度
        let gradients = self.compute_gradients(&output_errors);
        
        // Adam优化器更新
        self.adam_update(&gradients);
        
        // 计算总误差
        output_errors.iter().map(|e| e * e).sum::<f64>() / 2.0
    }
    
    fn compute_gradients(&self, output_errors: &[f64]) -> Vec<LayerGradients> {
        // 使用与BackpropagationTrainer相同的梯度计算方法
        let num_layers = self.network.layers.len();
        let mut all_gradients = vec![LayerGradients::new(0, 0); num_layers];
        let mut errors = output_errors.to_vec();
        
        for layer_idx in (0..num_layers).rev() {
            let layer = &self.network.layers[layer_idx];
            let mut weight_gradients = vec![vec![0.0; layer.weights[0].len()]; layer.weights.len()];
            let mut bias_gradients = vec![0.0; layer.biases.len()];
            let mut next_errors = vec![0.0; layer.inputs.len()];
            
            for neuron_idx in 0..layer.weights.len() {
                let activation = layer.activations[neuron_idx];
                let delta = errors[neuron_idx] * activation * (1.0 - activation);
                
                for weight_idx in 0..layer.weights[neuron_idx].len() {
                    weight_gradients[neuron_idx][weight_idx] = delta * layer.inputs[weight_idx];
                    next_errors[weight_idx] += delta * layer.weights[neuron_idx][weight_idx];
                }
                
                bias_gradients[neuron_idx] = delta;
            }
            
            all_gradients[layer_idx] = LayerGradients {
                weight_gradients,
                bias_gradients,
            };
            
            errors = next_errors;
        }
        
        all_gradients
    }
    
    fn adam_update(&mut self, gradients: &[LayerGradients]) {
        let bias_correction1 = 1.0 - self.beta1.powi(self.time_step as i32);
        let bias_correction2 = 1.0 - self.beta2.powi(self.time_step as i32);
        
        for (layer_idx, layer_gradients) in gradients.iter().enumerate() {
            let layer = &mut self.network.layers[layer_idx];
            
            // 更新权重
            for (neuron_idx, neuron_weights) in layer.weights.iter_mut().enumerate() {
                for (weight_idx, weight) in neuron_weights.iter_mut().enumerate() {
                    let gradient = layer_gradients.weight_gradients[neuron_idx][weight_idx];
                    
                    // 更新一阶矩估计
                    self.m_weights[layer_idx][neuron_idx][weight_idx] = 
                        self.beta1 * self.m_weights[layer_idx][neuron_idx][weight_idx] + 
                        (1.0 - self.beta1) * gradient;
                    
                    // 更新二阶矩估计
                    self.v_weights[layer_idx][neuron_idx][weight_idx] = 
                        self.beta2 * self.v_weights[layer_idx][neuron_idx][weight_idx] + 
                        (1.0 - self.beta2) * gradient * gradient;
                    
                    // 偏置校正
                    let m_hat = self.m_weights[layer_idx][neuron_idx][weight_idx] / bias_correction1;
                    let v_hat = self.v_weights[layer_idx][neuron_idx][weight_idx] / bias_correction2;
                    
                    // 更新权重
                    *weight += self.learning_rate * m_hat / (v_hat.sqrt() + self.epsilon);
                }
            }
            
            // 更新偏置（类似权重更新）
            for (bias_idx, bias) in layer.biases.iter_mut().enumerate() {
                let gradient = layer_gradients.bias_gradients[bias_idx];
                
                self.m_biases[layer_idx][bias_idx] = 
                    self.beta1 * self.m_biases[layer_idx][bias_idx] + 
                    (1.0 - self.beta1) * gradient;
                
                self.v_biases[layer_idx][bias_idx] = 
                    self.beta2 * self.v_biases[layer_idx][bias_idx] + 
                    (1.0 - self.beta2) * gradient * gradient;
                
                let m_hat = self.m_biases[layer_idx][bias_idx] / bias_correction1;
                let v_hat = self.v_biases[layer_idx][bias_idx] / bias_correction2;
                
                *bias += self.learning_rate * m_hat / (v_hat.sqrt() + self.epsilon);
            }
        }
    }
    
    pub fn get_network(&self) -> &MultilayerPerceptron {
        &self.network
    }
    
    pub fn get_network_mut(&mut self) -> &mut MultilayerPerceptron {
        &mut self.network
    }
}
```

## 总结 / Summary

神经网络计算模型为我们提供了强大的工具来解决复杂的模式识别、函数逼近和序列建模问题。从简单的感知机到复杂的深度学习架构，神经网络展现了令人印象深刻的学习和泛化能力。

Neural network computational models provide us with powerful tools for solving complex pattern recognition, function approximation, and sequence modeling problems. From simple perceptrons to complex deep learning architectures, neural networks demonstrate impressive learning and generalization capabilities.

### 关键特点 / Key Features

1. **自适应学习** / Adaptive Learning
   - 通过训练数据自动调整参数
   - 具有泛化能力

2. **并行处理** / Parallel Processing
   - 分布式信息处理
   - 容错性强

3. **通用逼近能力** / Universal Approximation
   - 能够逼近任意连续函数
   - 强大的表示能力

4. **多样化架构** / Diverse Architectures
   - 前馈、循环、卷积网络
   - 适应不同应用场景

---

**参考文献 / References**:

1. McCulloch, W. S., & Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4), 115-133.
2. Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6), 386.
3. Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533-536.
4. Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.
5. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.
