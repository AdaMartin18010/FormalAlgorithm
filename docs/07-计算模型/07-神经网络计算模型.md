---
title: 7.7 ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å‹ / Neural Network Computational Models
version: 1.1
status: maintained
last_updated: 2025-01-11
owner: è®¡ç®—æ¨¡å‹å·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)

## 7.7 ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å‹ / Neural Network Computational Models

### æ‘˜è¦ / Executive Summary

- ç»Ÿä¸€ç¥ç»ç½‘ç»œçš„å½¢å¼åŒ–å®šä¹‰ã€æ„ŸçŸ¥æœºã€å¤šå±‚æ„ŸçŸ¥æœºä¸æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚
- å»ºç«‹ç¥ç»ç½‘ç»œåœ¨æœºå™¨å­¦ä¹ ä¸äººå·¥æ™ºèƒ½ä¸­çš„åœ°ä½ã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- ç¥ç»ç½‘ç»œã€äººå·¥ç¥ç»å…ƒã€æ„ŸçŸ¥æœºã€å¤šå±‚æ„ŸçŸ¥æœºã€å·ç§¯ç¥ç»ç½‘ç»œã€é€’å½’ç¥ç»ç½‘ç»œã€åå‘ä¼ æ’­ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology & Notation

- ç¥ç»ç½‘ç»œï¼ˆNeural Networkï¼‰ï¼šç”±äº’è¿çš„äººå·¥ç¥ç»å…ƒç»„æˆçš„è®¡ç®—æ¨¡å‹ã€‚
- äººå·¥ç¥ç»å…ƒï¼ˆArtificial Neuronï¼‰ï¼šç¥ç»ç½‘ç»œçš„åŸºæœ¬è®¡ç®—å•å…ƒã€‚
- åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰ï¼šè®­ç»ƒç¥ç»ç½‘ç»œçš„å­¦ä¹ ç®—æ³•ã€‚
- è®°å·çº¦å®šï¼š`w` è¡¨ç¤ºæƒé‡ï¼Œ`b` è¡¨ç¤ºåç½®ï¼Œ`f` è¡¨ç¤ºæ¿€æ´»å‡½æ•°ã€‚

### äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References

- è®¡ç®—æ¨¡å‹ï¼šå‚è§ `07-è®¡ç®—æ¨¡å‹/` ç›¸å…³æ–‡æ¡£ã€‚
- æœºå™¨å­¦ä¹ ï¼šå‚è§ç›¸å…³æ–‡æ¡£ã€‚
- ç®—æ³•ç†è®ºï¼šå‚è§ `09-ç®—æ³•ç†è®º/` ç›¸å…³æ–‡æ¡£ã€‚

### å¿«é€Ÿå¯¼èˆª / Quick Links

- æ¦‚è¿°
- åŸºæœ¬æ¦‚å¿µ
- åŸºç¡€ç¥ç»ç½‘ç»œ
- æ·±åº¦å­¦ä¹ æ¨¡å‹

## ç›®å½• (Table of Contents)

- [7.7 ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å‹ / Neural Network Computational Models](#77-ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å‹--neural-network-computational-models)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology \& Notation](#æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ--terminology--notation)
  - [äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References](#äº¤å‰å¼•ç”¨å¯¼èˆª--cross-references)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½• (Table of Contents)](#ç›®å½•-table-of-contents)
- [æ¦‚è¿° / Overview](#æ¦‚è¿°--overview)
- [åŸºæœ¬æ¦‚å¿µ / Basic Concepts](#åŸºæœ¬æ¦‚å¿µ--basic-concepts)
  - [äººå·¥ç¥ç»å…ƒ / Artificial Neuron](#äººå·¥ç¥ç»å…ƒ--artificial-neuron)
  - [ç¥ç»ç½‘ç»œçš„ç»„æˆè¦ç´  / Components of Neural Networks](#ç¥ç»ç½‘ç»œçš„ç»„æˆè¦ç´ --components-of-neural-networks)
- [åŸºç¡€ç¥ç»ç½‘ç»œå®ç° / Basic Neural Network Implementation](#åŸºç¡€ç¥ç»ç½‘ç»œå®ç°--basic-neural-network-implementation)
  - [æ„ŸçŸ¥æœºæ¨¡å‹ / Perceptron Model](#æ„ŸçŸ¥æœºæ¨¡å‹--perceptron-model)
  - [å¤šå±‚æ„ŸçŸ¥æœº / Multi-Layer Perceptron](#å¤šå±‚æ„ŸçŸ¥æœº--multi-layer-perceptron)
- [æ·±åº¦å­¦ä¹ æ¨¡å‹ / Deep Learning Models](#æ·±åº¦å­¦ä¹ æ¨¡å‹--deep-learning-models)
  - [å·ç§¯ç¥ç»ç½‘ç»œ / Convolutional Neural Networks](#å·ç§¯ç¥ç»ç½‘ç»œ--convolutional-neural-networks)
- [é€’å½’ç¥ç»ç½‘ç»œ / Recurrent Neural Networks](#é€’å½’ç¥ç»ç½‘ç»œ--recurrent-neural-networks)
  - [LSTMå®ç° / LSTM Implementation](#lstmå®ç°--lstm-implementation)
- [å­¦ä¹ ç®—æ³•ç†è®º / Learning Algorithm Theory](#å­¦ä¹ ç®—æ³•ç†è®º--learning-algorithm-theory)
  - [åå‘ä¼ æ’­ç®—æ³• / Backpropagation Algorithm](#åå‘ä¼ æ’­ç®—æ³•--backpropagation-algorithm)
- [æ€»ç»“ / Summary](#æ€»ç»“--summary)
  - [å…³é”®ç‰¹ç‚¹ / Key Features](#å…³é”®ç‰¹ç‚¹--key-features)
- [å‚è€ƒæ–‡çŒ® / References](#å‚è€ƒæ–‡çŒ®--references)
  - [ç»å…¸å¥ åŸºæ–‡çŒ® / Classic Foundational Literature](#ç»å…¸å¥ åŸºæ–‡çŒ®--classic-foundational-literature)
  - [æ ‡å‡†æ•™æ / Standard Textbooks](#æ ‡å‡†æ•™æ--standard-textbooks)

## æ¦‚è¿° / Overview

ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å‹æ˜¯å—ç”Ÿç‰©ç¥ç»ç³»ç»Ÿå¯å‘çš„è®¡ç®—èŒƒå¼ï¼Œé€šè¿‡äº’è¿çš„äººå·¥ç¥ç»å…ƒç½‘ç»œæ¥å¤„ç†ä¿¡æ¯ã€‚è¿™äº›æ¨¡å‹å…·æœ‰å­¦ä¹ ã€é€‚åº”å’Œæ³›åŒ–çš„èƒ½åŠ›ï¼Œæ˜¯æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„é‡è¦åŸºç¡€ï¼Œå¹¿æ³›åº”ç”¨äºæ¨¡å¼è¯†åˆ«ã€å‡½æ•°é€¼è¿‘ã€æ•°æ®åˆ†æç­‰é¢†åŸŸã€‚

Neural network computational models are computational paradigms inspired by biological nervous systems, processing information through networks of interconnected artificial neurons. These models possess capabilities for learning, adaptation, and generalization, serving as important foundations for machine learning and artificial intelligence, with wide applications in pattern recognition, function approximation, and data analysis.

## åŸºæœ¬æ¦‚å¿µ / Basic Concepts

### äººå·¥ç¥ç»å…ƒ / Artificial Neuron

**å®šä¹‰ 1.1** (äººå·¥ç¥ç»å…ƒ / Artificial Neuron)
ä¸€ä¸ªäººå·¥ç¥ç»å…ƒæ˜¯ä¸€ä¸ªè®¡ç®—å•å…ƒï¼Œå®ƒæ¥æ”¶å¤šä¸ªè¾“å…¥ä¿¡å·ï¼Œé€šè¿‡åŠ æƒæ±‚å’Œå¹¶åº”ç”¨æ¿€æ´»å‡½æ•°æ¥äº§ç”Ÿè¾“å‡ºã€‚æ•°å­¦ä¸Šè¡¨ç¤ºä¸ºï¼š
y = f(âˆ‘(wáµ¢xáµ¢) + b)

**Definition 1.1** (Artificial Neuron)
An artificial neuron is a computational unit that receives multiple input signals, produces output through weighted summation and application of an activation function. Mathematically represented as:
y = f(âˆ‘(wáµ¢xáµ¢) + b)

### ç¥ç»ç½‘ç»œçš„ç»„æˆè¦ç´  / Components of Neural Networks

1. **ç¥ç»å…ƒ** / Neurons
   - ç½‘ç»œçš„åŸºæœ¬è®¡ç®—å•å…ƒ
   - å…·æœ‰æƒé‡ã€åç½®å’Œæ¿€æ´»å‡½æ•°

2. **è¿æ¥** / Connections
   - ç¥ç»å…ƒä¹‹é—´çš„ä¿¡æ¯ä¼ é€’è·¯å¾„
   - å…·æœ‰æƒé‡å‚æ•°

3. **å±‚æ¬¡ç»“æ„** / Layer Structure
   - è¾“å…¥å±‚ã€éšè—å±‚ã€è¾“å‡ºå±‚
   - å‰é¦ˆæˆ–å¾ªç¯è¿æ¥

4. **å­¦ä¹ ç®—æ³•** / Learning Algorithms
   - æƒé‡æ›´æ–°æœºåˆ¶
   - ç›‘ç£ã€æ— ç›‘ç£æˆ–å¼ºåŒ–å­¦ä¹ 

## åŸºç¡€ç¥ç»ç½‘ç»œå®ç° / Basic Neural Network Implementation

### æ„ŸçŸ¥æœºæ¨¡å‹ / Perceptron Model

```rust
// æ„ŸçŸ¥æœºå®ç°
// Perceptron implementation

use rand::Rng;

#[derive(Clone, Debug)]
pub struct Perceptron {
    weights: Vec<f64>,
    bias: f64,
    learning_rate: f64,
}

impl Perceptron {
    pub fn new(input_size: usize, learning_rate: f64) -> Self {
        let mut rng = rand::thread_rng();
        let weights = (0..input_size)
            .map(|_| rng.gen_range(-1.0..1.0))
            .collect();

        Self {
            weights,
            bias: rng.gen_range(-1.0..1.0),
            learning_rate,
        }
    }

    pub fn predict(&self, inputs: &[f64]) -> f64 {
        assert_eq!(inputs.len(), self.weights.len());

        let weighted_sum: f64 = inputs
            .iter()
            .zip(self.weights.iter())
            .map(|(x, w)| x * w)
            .sum::<f64>() + self.bias;

        self.step_function(weighted_sum)
    }

    pub fn predict_continuous(&self, inputs: &[f64]) -> f64 {
        assert_eq!(inputs.len(), self.weights.len());

        let weighted_sum: f64 = inputs
            .iter()
            .zip(self.weights.iter())
            .map(|(x, w)| x * w)
            .sum::<f64>() + self.bias;

        self.sigmoid(weighted_sum)
    }

    fn step_function(&self, x: f64) -> f64 {
        if x >= 0.0 { 1.0 } else { 0.0 }
    }

    fn sigmoid(&self, x: f64) -> f64 {
        1.0 / (1.0 + (-x).exp())
    }

    pub fn train(&mut self, inputs: &[f64], target: f64) -> f64 {
        let prediction = self.predict(inputs);
        let error = target - prediction;

        // æƒé‡æ›´æ–°
        for i in 0..self.weights.len() {
            self.weights[i] += self.learning_rate * error * inputs[i];
        }
        self.bias += self.learning_rate * error;

        error.abs()
    }

    pub fn train_epoch(&mut self, training_data: &[(Vec<f64>, f64)]) -> f64 {
        let mut total_error = 0.0;

        for (inputs, target) in training_data {
            total_error += self.train(inputs, *target);
        }

        total_error / training_data.len() as f64
    }

    pub fn get_weights(&self) -> &[f64] {
        &self.weights
    }

    pub fn get_bias(&self) -> f64 {
        self.bias
    }
}

// æ„ŸçŸ¥æœºè®­ç»ƒç¤ºä¾‹
pub fn perceptron_example() {
    // è®­ç»ƒæ„ŸçŸ¥æœºå­¦ä¹ ANDé€»è¾‘é—¨
    let mut perceptron = Perceptron::new(2, 0.1);

    let training_data = vec![
        (vec![0.0, 0.0], 0.0),
        (vec![0.0, 1.0], 0.0),
        (vec![1.0, 0.0], 0.0),
        (vec![1.0, 1.0], 1.0),
    ];

    println!("è®­ç»ƒANDé€»è¾‘é—¨:");
    for epoch in 0..100 {
        let error = perceptron.train_epoch(&training_data);
        if epoch % 20 == 0 {
            println!("Epoch {}: Error = {:.4}", epoch, error);
        }

        if error < 0.01 {
            break;
        }
    }

    println!("æœ€ç»ˆæƒé‡: {:?}", perceptron.get_weights());
    println!("æœ€ç»ˆåç½®: {:.4}", perceptron.get_bias());

    // æµ‹è¯•
    println!("æµ‹è¯•ç»“æœ:");
    for (inputs, expected) in &training_data {
        let prediction = perceptron.predict(inputs);
        println!("{:?} -> {:.1} (æœŸæœ›: {:.1})", inputs, prediction, expected);
    }
}
```

### å¤šå±‚æ„ŸçŸ¥æœº / Multi-Layer Perceptron

```rust
// å¤šå±‚æ„ŸçŸ¥æœºå®ç°
// Multi-layer perceptron implementation

#[derive(Clone, Debug)]
pub struct Layer {
    weights: Vec<Vec<f64>>,  // weights[neuron][input]
    biases: Vec<f64>,
    activations: Vec<f64>,
    inputs: Vec<f64>,
}

impl Layer {
    pub fn new(input_size: usize, output_size: usize) -> Self {
        let mut rng = rand::thread_rng();

        let weights = (0..output_size)
            .map(|_| {
                (0..input_size)
                    .map(|_| rng.gen_range(-1.0..1.0))
                    .collect()
            })
            .collect();

        let biases = (0..output_size)
            .map(|_| rng.gen_range(-1.0..1.0))
            .collect();

        Self {
            weights,
            biases,
            activations: vec![0.0; output_size],
            inputs: vec![0.0; input_size],
        }
    }

    pub fn forward(&mut self, inputs: &[f64]) -> Vec<f64> {
        assert_eq!(inputs.len(), self.weights[0].len());

        self.inputs = inputs.to_vec();

        for i in 0..self.weights.len() {
            let weighted_sum: f64 = inputs
                .iter()
                .zip(self.weights[i].iter())
                .map(|(x, w)| x * w)
                .sum::<f64>() + self.biases[i];

            self.activations[i] = self.sigmoid(weighted_sum);
        }

        self.activations.clone()
    }

    fn sigmoid(&self, x: f64) -> f64 {
        1.0 / (1.0 + (-x).exp())
    }

    fn sigmoid_derivative(&self, x: f64) -> f64 {
        let s = self.sigmoid(x);
        s * (1.0 - s)
    }

    pub fn get_activations(&self) -> &[f64] {
        &self.activations
    }

    pub fn get_weights(&self) -> &[Vec<f64>] {
        &self.weights
    }

    pub fn get_biases(&self) -> &[f64] {
        &self.biases
    }
}

#[derive(Clone, Debug)]
pub struct MultilayerPerceptron {
    layers: Vec<Layer>,
    learning_rate: f64,
}

impl MultilayerPerceptron {
    pub fn new(layer_sizes: &[usize], learning_rate: f64) -> Self {
        assert!(layer_sizes.len() >= 2, "è‡³å°‘éœ€è¦è¾“å…¥å±‚å’Œè¾“å‡ºå±‚");

        let mut layers = Vec::new();

        for i in 0..layer_sizes.len() - 1 {
            layers.push(Layer::new(layer_sizes[i], layer_sizes[i + 1]));
        }

        Self {
            layers,
            learning_rate,
        }
    }

    pub fn forward(&mut self, inputs: &[f64]) -> Vec<f64> {
        let mut current_inputs = inputs.to_vec();

        for layer in &mut self.layers {
            current_inputs = layer.forward(&current_inputs);
        }

        current_inputs
    }

    pub fn train(&mut self, inputs: &[f64], targets: &[f64]) -> f64 {
        // å‰å‘ä¼ æ’­
        let outputs = self.forward(inputs);

        // è®¡ç®—è¾“å‡ºè¯¯å·®
        let output_errors: Vec<f64> = outputs
            .iter()
            .zip(targets.iter())
            .map(|(output, target)| target - output)
            .collect();

        // åå‘ä¼ æ’­
        self.backward(&output_errors);

        // è®¡ç®—æ€»è¯¯å·®
        output_errors.iter().map(|e| e * e).sum::<f64>() / 2.0
    }

    fn backward(&mut self, output_errors: &[f64]) {
        let num_layers = self.layers.len();
        let mut errors = output_errors.to_vec();

        // ä»è¾“å‡ºå±‚å‘å‰é€å±‚åå‘ä¼ æ’­
        for layer_idx in (0..num_layers).rev() {
            let layer = &mut self.layers[layer_idx];
            let mut next_errors = vec![0.0; layer.inputs.len()];

            // æ›´æ–°æƒé‡å’Œåç½®
            for neuron_idx in 0..layer.weights.len() {
                let activation = layer.activations[neuron_idx];
                let delta = errors[neuron_idx] * activation * (1.0 - activation);

                // æ›´æ–°æƒé‡
                for weight_idx in 0..layer.weights[neuron_idx].len() {
                    let input_value = layer.inputs[weight_idx];
                    layer.weights[neuron_idx][weight_idx] +=
                        self.learning_rate * delta * input_value;

                    // è®¡ç®—ä¼ æ’­åˆ°å‰ä¸€å±‚çš„è¯¯å·®
                    next_errors[weight_idx] += delta * layer.weights[neuron_idx][weight_idx];
                }

                // æ›´æ–°åç½®
                layer.biases[neuron_idx] += self.learning_rate * delta;
            }

            errors = next_errors;
        }
    }

    pub fn train_epoch(&mut self, training_data: &[(Vec<f64>, Vec<f64>)]) -> f64 {
        let mut total_error = 0.0;

        for (inputs, targets) in training_data {
            total_error += self.train(inputs, targets);
        }

        total_error / training_data.len() as f64
    }

    pub fn predict(&mut self, inputs: &[f64]) -> Vec<f64> {
        self.forward(inputs)
    }
}

// XORé—®é¢˜ç¤ºä¾‹
pub fn xor_example() {
    let mut mlp = MultilayerPerceptron::new(&[2, 4, 1], 0.5);

    let training_data = vec![
        (vec![0.0, 0.0], vec![0.0]),
        (vec![0.0, 1.0], vec![1.0]),
        (vec![1.0, 0.0], vec![1.0]),
        (vec![1.0, 1.0], vec![0.0]),
    ];

    println!("è®­ç»ƒXORé—®é¢˜:");
    for epoch in 0..1000 {
        let error = mlp.train_epoch(&training_data);
        if epoch % 200 == 0 {
            println!("Epoch {}: Error = {:.6}", epoch, error);
        }

        if error < 0.001 {
            break;
        }
    }

    println!("æµ‹è¯•ç»“æœ:");
    for (inputs, expected) in &training_data {
        let prediction = mlp.predict(inputs);
        println!("{:?} -> {:.3} (æœŸæœ›: {:.1})", inputs, prediction[0], expected[0]);
    }
}
```

## æ·±åº¦å­¦ä¹ æ¨¡å‹ / Deep Learning Models

### å·ç§¯ç¥ç»ç½‘ç»œ / Convolutional Neural Networks

```rust
// å·ç§¯ç¥ç»ç½‘ç»œå®ç°
// Convolutional Neural Network implementation

#[derive(Clone, Debug)]
pub struct ConvolutionLayer {
    kernels: Vec<Vec<Vec<f64>>>,  // kernels[filter][row][col]
    biases: Vec<f64>,
    stride: usize,
    padding: usize,
    input_channels: usize,
    output_channels: usize,
    kernel_size: usize,
}

impl ConvolutionLayer {
    pub fn new(
        input_channels: usize,
        output_channels: usize,
        kernel_size: usize,
        stride: usize,
        padding: usize,
    ) -> Self {
        let mut rng = rand::thread_rng();

        let kernels = (0..output_channels)
            .map(|_| {
                (0..kernel_size)
                    .map(|_| {
                        (0..kernel_size)
                            .map(|_| rng.gen_range(-0.1..0.1))
                            .collect()
                    })
                    .collect()
            })
            .collect();

        let biases = (0..output_channels)
            .map(|_| rng.gen_range(-0.1..0.1))
            .collect();

        Self {
            kernels,
            biases,
            stride,
            padding,
            input_channels,
            output_channels,
            kernel_size,
        }
    }

    pub fn forward(&self, input: &[Vec<f64>]) -> Vec<Vec<f64>> {
        let input_height = input.len();
        let input_width = input[0].len();

        let output_height = (input_height + 2 * self.padding - self.kernel_size) / self.stride + 1;
        let output_width = (input_width + 2 * self.padding - self.kernel_size) / self.stride + 1;

        let mut output = vec![vec![0.0; output_width]; output_height];

        for filter_idx in 0..self.output_channels {
            for out_row in 0..output_height {
                for out_col in 0..output_width {
                    let mut sum = 0.0;

                    for kernel_row in 0..self.kernel_size {
                        for kernel_col in 0..self.kernel_size {
                            let in_row = out_row * self.stride + kernel_row;
                            let in_col = out_col * self.stride + kernel_col;

                            if in_row < input_height && in_col < input_width {
                                sum += input[in_row][in_col] *
                                       self.kernels[filter_idx][kernel_row][kernel_col];
                            }
                        }
                    }

                    output[out_row][out_col] = self.relu(sum + self.biases[filter_idx]);
                }
            }
        }

        output
    }

    fn relu(&self, x: f64) -> f64 {
        f64::max(0.0, x)
    }
}

#[derive(Clone, Debug)]
pub struct PoolingLayer {
    pool_size: usize,
    stride: usize,
    pooling_type: PoolingType,
}

#[derive(Clone, Debug, PartialEq)]
pub enum PoolingType {
    Max,
    Average,
}

impl PoolingLayer {
    pub fn new(pool_size: usize, stride: usize, pooling_type: PoolingType) -> Self {
        Self {
            pool_size,
            stride,
            pooling_type,
        }
    }

    pub fn forward(&self, input: &[Vec<f64>]) -> Vec<Vec<f64>> {
        let input_height = input.len();
        let input_width = input[0].len();

        let output_height = (input_height - self.pool_size) / self.stride + 1;
        let output_width = (input_width - self.pool_size) / self.stride + 1;

        let mut output = vec![vec![0.0; output_width]; output_height];

        for out_row in 0..output_height {
            for out_col in 0..output_width {
                let start_row = out_row * self.stride;
                let start_col = out_col * self.stride;

                let mut pool_values = Vec::new();
                for pool_row in 0..self.pool_size {
                    for pool_col in 0..self.pool_size {
                        let in_row = start_row + pool_row;
                        let in_col = start_col + pool_col;

                        if in_row < input_height && in_col < input_width {
                            pool_values.push(input[in_row][in_col]);
                        }
                    }
                }

                output[out_row][out_col] = match self.pooling_type {
                    PoolingType::Max => {
                        pool_values.into_iter().fold(f64::NEG_INFINITY, f64::max)
                    }
                    PoolingType::Average => {
                        pool_values.iter().sum::<f64>() / pool_values.len() as f64
                    }
                };
            }
        }

        output
    }
}

#[derive(Clone, Debug)]
pub struct ConvolutionalNN {
    conv_layers: Vec<ConvolutionLayer>,
    pool_layers: Vec<PoolingLayer>,
    fc_layers: Vec<Layer>,
    learning_rate: f64,
}

impl ConvolutionalNN {
    pub fn new(learning_rate: f64) -> Self {
        Self {
            conv_layers: Vec::new(),
            pool_layers: Vec::new(),
            fc_layers: Vec::new(),
            learning_rate,
        }
    }

    pub fn add_conv_layer(&mut self, layer: ConvolutionLayer) {
        self.conv_layers.push(layer);
    }

    pub fn add_pool_layer(&mut self, layer: PoolingLayer) {
        self.pool_layers.push(layer);
    }

    pub fn add_fc_layer(&mut self, layer: Layer) {
        self.fc_layers.push(layer);
    }

    pub fn forward(&mut self, input: &[Vec<f64>]) -> Vec<f64> {
        let mut current_input = input.to_vec();

        // å·ç§¯å’Œæ± åŒ–å±‚
        for (conv_layer, pool_layer) in self.conv_layers.iter().zip(self.pool_layers.iter()) {
            current_input = conv_layer.forward(&current_input);
            current_input = pool_layer.forward(&current_input);
        }

        // å±•å¹³ä¸ºä¸€ç»´å‘é‡
        let flattened: Vec<f64> = current_input.into_iter().flatten().collect();

        // å…¨è¿æ¥å±‚
        let mut fc_input = flattened;
        for fc_layer in &mut self.fc_layers {
            fc_input = fc_layer.forward(&fc_input);
        }

        fc_input
    }

    pub fn predict(&mut self, input: &[Vec<f64>]) -> Vec<f64> {
        self.forward(input)
    }
}

// ç®€åŒ–çš„CNNç¤ºä¾‹
pub fn cnn_example() {
    let mut cnn = ConvolutionalNN::new(0.01);

    // æ·»åŠ å·ç§¯å±‚
    cnn.add_conv_layer(ConvolutionLayer::new(1, 16, 3, 1, 0));
    cnn.add_pool_layer(PoolingLayer::new(2, 2, PoolingType::Max));

    cnn.add_conv_layer(ConvolutionLayer::new(16, 32, 3, 1, 0));
    cnn.add_pool_layer(PoolingLayer::new(2, 2, PoolingType::Max));

    // æ·»åŠ å…¨è¿æ¥å±‚ï¼ˆéœ€è¦æ ¹æ®å®é™…è¾“å‡ºå°ºå¯¸è°ƒæ•´ï¼‰
    cnn.add_fc_layer(Layer::new(32, 10));

    // åˆ›å»ºç¤ºä¾‹è¾“å…¥ï¼ˆ28x28å›¾åƒï¼‰
    let input: Vec<Vec<f64>> = (0..28)
        .map(|i| {
            (0..28)
                .map(|j| if (i + j) % 2 == 0 { 1.0 } else { 0.0 })
                .collect()
        })
        .collect();

    let output = cnn.predict(&input);
    println!("CNNè¾“å‡º: {:?}", output);
}
```

## é€’å½’ç¥ç»ç½‘ç»œ / Recurrent Neural Networks

### LSTMå®ç° / LSTM Implementation

```rust
// LSTMç¥ç»ç½‘ç»œå®ç°
// LSTM Neural Network implementation

#[derive(Clone, Debug)]
pub struct LSTMCell {
    input_size: usize,
    hidden_size: usize,

    // é—¨æ§æƒé‡çŸ©é˜µ
    w_forget: Vec<Vec<f64>>,
    w_input: Vec<Vec<f64>>,
    w_candidate: Vec<Vec<f64>>,
    w_output: Vec<Vec<f64>>,

    // åç½®å‘é‡
    b_forget: Vec<f64>,
    b_input: Vec<f64>,
    b_candidate: Vec<f64>,
    b_output: Vec<f64>,

    // çŠ¶æ€å‘é‡
    hidden_state: Vec<f64>,
    cell_state: Vec<f64>,
}

impl LSTMCell {
    pub fn new(input_size: usize, hidden_size: usize) -> Self {
        let mut rng = rand::thread_rng();

        let init_weight = |rows: usize, cols: usize| -> Vec<Vec<f64>> {
            (0..rows)
                .map(|_| {
                    (0..cols)
                        .map(|_| rng.gen_range(-0.1..0.1))
                        .collect()
                })
                .collect()
        };

        let total_input_size = input_size + hidden_size;

        Self {
            input_size,
            hidden_size,

            w_forget: init_weight(hidden_size, total_input_size),
            w_input: init_weight(hidden_size, total_input_size),
            w_candidate: init_weight(hidden_size, total_input_size),
            w_output: init_weight(hidden_size, total_input_size),

            b_forget: vec![0.0; hidden_size],
            b_input: vec![0.0; hidden_size],
            b_candidate: vec![0.0; hidden_size],
            b_output: vec![0.0; hidden_size],

            hidden_state: vec![0.0; hidden_size],
            cell_state: vec![0.0; hidden_size],
        }
    }

    pub fn forward(&mut self, input: &[f64]) -> Vec<f64> {
        assert_eq!(input.len(), self.input_size);

        // æ‹¼æ¥è¾“å…¥å’Œéšè—çŠ¶æ€
        let mut combined_input = input.to_vec();
        combined_input.extend(self.hidden_state.iter());

        // é—å¿˜é—¨
        let forget_gate = self.sigmoid_vector(&self.linear_transform(
            &self.w_forget, &combined_input, &self.b_forget
        ));

        // è¾“å…¥é—¨
        let input_gate = self.sigmoid_vector(&self.linear_transform(
            &self.w_input, &combined_input, &self.b_input
        ));

        // å€™é€‰å€¼
        let candidate_values = self.tanh_vector(&self.linear_transform(
            &self.w_candidate, &combined_input, &self.b_candidate
        ));

        // è¾“å‡ºé—¨
        let output_gate = self.sigmoid_vector(&self.linear_transform(
            &self.w_output, &combined_input, &self.b_output
        ));

        // æ›´æ–°ç»†èƒçŠ¶æ€
        for i in 0..self.hidden_size {
            self.cell_state[i] = forget_gate[i] * self.cell_state[i] +
                                input_gate[i] * candidate_values[i];
        }

        // æ›´æ–°éšè—çŠ¶æ€
        let tanh_cell_state = self.tanh_vector(&self.cell_state);
        for i in 0..self.hidden_size {
            self.hidden_state[i] = output_gate[i] * tanh_cell_state[i];
        }

        self.hidden_state.clone()
    }

    fn linear_transform(&self, weights: &[Vec<f64>], input: &[f64], bias: &[f64]) -> Vec<f64> {
        let mut output = vec![0.0; weights.len()];

        for i in 0..weights.len() {
            for j in 0..input.len() {
                output[i] += weights[i][j] * input[j];
            }
            output[i] += bias[i];
        }

        output
    }

    fn sigmoid(&self, x: f64) -> f64 {
        1.0 / (1.0 + (-x).exp())
    }

    fn sigmoid_vector(&self, vec: &[f64]) -> Vec<f64> {
        vec.iter().map(|&x| self.sigmoid(x)).collect()
    }

    fn tanh(&self, x: f64) -> f64 {
        x.tanh()
    }

    fn tanh_vector(&self, vec: &[f64]) -> Vec<f64> {
        vec.iter().map(|&x| self.tanh(x)).collect()
    }

    pub fn reset_state(&mut self) {
        self.hidden_state.fill(0.0);
        self.cell_state.fill(0.0);
    }

    pub fn get_hidden_state(&self) -> &[f64] {
        &self.hidden_state
    }

    pub fn get_cell_state(&self) -> &[f64] {
        &self.cell_state
    }
}

#[derive(Clone, Debug)]
pub struct LSTMNetwork {
    lstm_layers: Vec<LSTMCell>,
    output_layer: Layer,
    learning_rate: f64,
}

impl LSTMNetwork {
    pub fn new(input_size: usize, hidden_sizes: &[usize], output_size: usize, learning_rate: f64) -> Self {
        let mut lstm_layers = Vec::new();

        // ç¬¬ä¸€å±‚LSTM
        lstm_layers.push(LSTMCell::new(input_size, hidden_sizes[0]));

        // åç»­LSTMå±‚
        for i in 1..hidden_sizes.len() {
            lstm_layers.push(LSTMCell::new(hidden_sizes[i-1], hidden_sizes[i]));
        }

        // è¾“å‡ºå±‚
        let final_hidden_size = hidden_sizes.last().unwrap_or(&input_size);
        let output_layer = Layer::new(*final_hidden_size, output_size);

        Self {
            lstm_layers,
            output_layer,
            learning_rate,
        }
    }

    pub fn forward(&mut self, sequence: &[Vec<f64>]) -> Vec<Vec<f64>> {
        let mut outputs = Vec::new();

        // é‡ç½®æ‰€æœ‰LSTMå±‚çš„çŠ¶æ€
        for lstm_layer in &mut self.lstm_layers {
            lstm_layer.reset_state();
        }

        // å¤„ç†åºåˆ—ä¸­çš„æ¯ä¸ªæ—¶é—´æ­¥
        for time_step in sequence {
            let mut current_input = time_step.clone();

            // é€šè¿‡æ‰€æœ‰LSTMå±‚
            for lstm_layer in &mut self.lstm_layers {
                current_input = lstm_layer.forward(&current_input);
            }

            // é€šè¿‡è¾“å‡ºå±‚
            let output = self.output_layer.forward(&current_input);
            outputs.push(output);
        }

        outputs
    }

    pub fn predict(&mut self, sequence: &[Vec<f64>]) -> Vec<Vec<f64>> {
        self.forward(sequence)
    }

    // ç®€åŒ–çš„è®­ç»ƒæ–¹æ³•ï¼ˆå®é™…åº”è¯¥å®ç°BPTTï¼‰
    pub fn train_sequence(&mut self, input_sequence: &[Vec<f64>], target_sequence: &[Vec<f64>]) -> f64 {
        let predictions = self.forward(input_sequence);

        let mut total_error = 0.0;
        for (pred, target) in predictions.iter().zip(target_sequence.iter()) {
            for (p, t) in pred.iter().zip(target.iter()) {
                total_error += (t - p).powi(2);
            }
        }

        total_error / (predictions.len() * predictions[0].len()) as f64
    }
}

// åºåˆ—é¢„æµ‹ç¤ºä¾‹
pub fn lstm_sequence_example() {
    let mut lstm = LSTMNetwork::new(1, &[10, 10], 1, 0.01);

    // ç”Ÿæˆæ­£å¼¦æ³¢åºåˆ—æ•°æ®
    let sequence_length = 20;
    let mut input_sequence = Vec::new();
    let mut target_sequence = Vec::new();

    for i in 0..sequence_length {
        let x = i as f64 * 0.1;
        let input_val = (x).sin();
        let target_val = (x + 0.1).sin(); // é¢„æµ‹ä¸‹ä¸€ä¸ªå€¼

        input_sequence.push(vec![input_val]);
        target_sequence.push(vec![target_val]);
    }

    println!("è®­ç»ƒLSTMåºåˆ—é¢„æµ‹:");
    for epoch in 0..100 {
        let error = lstm.train_sequence(&input_sequence, &target_sequence);
        if epoch % 20 == 0 {
            println!("Epoch {}: Error = {:.6}", epoch, error);
        }
    }

    // æµ‹è¯•é¢„æµ‹
    let predictions = lstm.predict(&input_sequence);
    println!("é¢„æµ‹ç»“æœ (å‰5ä¸ª):");
    for i in 0..5 {
        println!("è¾“å…¥: {:.3}, é¢„æµ‹: {:.3}, å®é™…: {:.3}",
            input_sequence[i][0], predictions[i][0], target_sequence[i][0]);
    }
}
```

## å­¦ä¹ ç®—æ³•ç†è®º / Learning Algorithm Theory

### åå‘ä¼ æ’­ç®—æ³• / Backpropagation Algorithm

```rust
// æ¢¯åº¦è®¡ç®—å’Œåå‘ä¼ æ’­çš„è¯¦ç»†å®ç°
// Detailed implementation of gradient computation and backpropagation

#[derive(Clone, Debug)]
pub struct BackpropagationTrainer {
    network: MultilayerPerceptron,
    momentum: f64,
    weight_decay: f64,
    previous_weight_updates: Vec<Vec<Vec<f64>>>,
    previous_bias_updates: Vec<Vec<f64>>,
}

impl BackpropagationTrainer {
    pub fn new(mut network: MultilayerPerceptron, momentum: f64, weight_decay: f64) -> Self {
        // åˆå§‹åŒ–åŠ¨é‡é¡¹
        let mut previous_weight_updates = Vec::new();
        let mut previous_bias_updates = Vec::new();

        for layer in &network.layers {
            let layer_weight_updates = layer.weights
                .iter()
                .map(|row| vec![0.0; row.len()])
                .collect();
            previous_weight_updates.push(layer_weight_updates);

            let layer_bias_updates = vec![0.0; layer.biases.len()];
            previous_bias_updates.push(layer_bias_updates);
        }

        Self {
            network,
            momentum,
            weight_decay,
            previous_weight_updates,
            previous_bias_updates,
        }
    }

    pub fn train_with_momentum(&mut self, inputs: &[f64], targets: &[f64]) -> f64 {
        // å‰å‘ä¼ æ’­
        let outputs = self.network.forward(inputs);

        // è®¡ç®—è¾“å‡ºè¯¯å·®
        let output_errors: Vec<f64> = outputs
            .iter()
            .zip(targets.iter())
            .map(|(output, target)| target - output)
            .collect();

        // åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
        let gradients = self.compute_gradients(&output_errors);

        // ä½¿ç”¨åŠ¨é‡æ›´æ–°æƒé‡
        self.update_weights_with_momentum(&gradients);

        // è®¡ç®—æ€»è¯¯å·®
        output_errors.iter().map(|e| e * e).sum::<f64>() / 2.0
    }

    fn compute_gradients(&self, output_errors: &[f64]) -> Vec<LayerGradients> {
        let num_layers = self.network.layers.len();
        let mut all_gradients = vec![LayerGradients::new(0, 0); num_layers];
        let mut errors = output_errors.to_vec();

        // ä»è¾“å‡ºå±‚å‘å‰é€å±‚è®¡ç®—æ¢¯åº¦
        for layer_idx in (0..num_layers).rev() {
            let layer = &self.network.layers[layer_idx];
            let mut weight_gradients = vec![vec![0.0; layer.weights[0].len()]; layer.weights.len()];
            let mut bias_gradients = vec![0.0; layer.biases.len()];
            let mut next_errors = vec![0.0; layer.inputs.len()];

            for neuron_idx in 0..layer.weights.len() {
                let activation = layer.activations[neuron_idx];
                let delta = errors[neuron_idx] * activation * (1.0 - activation);

                // è®¡ç®—æƒé‡æ¢¯åº¦
                for weight_idx in 0..layer.weights[neuron_idx].len() {
                    weight_gradients[neuron_idx][weight_idx] = delta * layer.inputs[weight_idx];

                    // è®¡ç®—ä¼ æ’­åˆ°å‰ä¸€å±‚çš„è¯¯å·®
                    next_errors[weight_idx] += delta * layer.weights[neuron_idx][weight_idx];
                }

                // è®¡ç®—åç½®æ¢¯åº¦
                bias_gradients[neuron_idx] = delta;
            }

            all_gradients[layer_idx] = LayerGradients {
                weight_gradients,
                bias_gradients,
            };

            errors = next_errors;
        }

        all_gradients
    }

    fn update_weights_with_momentum(&mut self, gradients: &[LayerGradients]) {
        for (layer_idx, layer_gradients) in gradients.iter().enumerate() {
            let layer = &mut self.network.layers[layer_idx];

            // æ›´æ–°æƒé‡
            for (neuron_idx, neuron_weights) in layer.weights.iter_mut().enumerate() {
                for (weight_idx, weight) in neuron_weights.iter_mut().enumerate() {
                    let gradient = layer_gradients.weight_gradients[neuron_idx][weight_idx];
                    let weight_decay_term = self.weight_decay * *weight;

                    // è®¡ç®—æƒé‡æ›´æ–°é‡ï¼ˆåŒ…å«åŠ¨é‡å’Œæƒé‡è¡°å‡ï¼‰
                    let weight_update = self.network.learning_rate * gradient - weight_decay_term +
                        self.momentum * self.previous_weight_updates[layer_idx][neuron_idx][weight_idx];

                    *weight += weight_update;
                    self.previous_weight_updates[layer_idx][neuron_idx][weight_idx] = weight_update;
                }
            }

            // æ›´æ–°åç½®
            for (bias_idx, bias) in layer.biases.iter_mut().enumerate() {
                let gradient = layer_gradients.bias_gradients[bias_idx];

                let bias_update = self.network.learning_rate * gradient +
                    self.momentum * self.previous_bias_updates[layer_idx][bias_idx];

                *bias += bias_update;
                self.previous_bias_updates[layer_idx][bias_idx] = bias_update;
            }
        }
    }

    pub fn get_network(&self) -> &MultilayerPerceptron {
        &self.network
    }

    pub fn get_network_mut(&mut self) -> &mut MultilayerPerceptron {
        &mut self.network
    }
}

#[derive(Clone, Debug)]
struct LayerGradients {
    weight_gradients: Vec<Vec<f64>>,
    bias_gradients: Vec<f64>,
}

impl LayerGradients {
    fn new(num_neurons: usize, input_size: usize) -> Self {
        Self {
            weight_gradients: vec![vec![0.0; input_size]; num_neurons],
            bias_gradients: vec![0.0; num_neurons],
        }
    }
}

// è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³• - Adamä¼˜åŒ–å™¨
#[derive(Clone, Debug)]
pub struct AdamOptimizer {
    network: MultilayerPerceptron,
    beta1: f64,
    beta2: f64,
    epsilon: f64,
    learning_rate: f64,

    // ä¸€é˜¶å’ŒäºŒé˜¶çŸ©ä¼°è®¡
    m_weights: Vec<Vec<Vec<f64>>>,
    v_weights: Vec<Vec<Vec<f64>>>,
    m_biases: Vec<Vec<f64>>,
    v_biases: Vec<Vec<f64>>,

    time_step: usize,
}

impl AdamOptimizer {
    pub fn new(network: MultilayerPerceptron, learning_rate: f64) -> Self {
        let mut m_weights = Vec::new();
        let mut v_weights = Vec::new();
        let mut m_biases = Vec::new();
        let mut v_biases = Vec::new();

        for layer in &network.layers {
            let layer_m_weights = layer.weights
                .iter()
                .map(|row| vec![0.0; row.len()])
                .collect();
            let layer_v_weights = layer.weights
                .iter()
                .map(|row| vec![0.0; row.len()])
                .collect();

            m_weights.push(layer_m_weights);
            v_weights.push(layer_v_weights);
            m_biases.push(vec![0.0; layer.biases.len()]);
            v_biases.push(vec![0.0; layer.biases.len()]);
        }

        Self {
            network,
            beta1: 0.9,
            beta2: 0.999,
            epsilon: 1e-8,
            learning_rate,
            m_weights,
            v_weights,
            m_biases,
            v_biases,
            time_step: 0,
        }
    }

    pub fn train(&mut self, inputs: &[f64], targets: &[f64]) -> f64 {
        self.time_step += 1;

        // å‰å‘ä¼ æ’­
        let outputs = self.network.forward(inputs);

        // è®¡ç®—è¾“å‡ºè¯¯å·®
        let output_errors: Vec<f64> = outputs
            .iter()
            .zip(targets.iter())
            .map(|(output, target)| target - output)
            .collect();

        // è®¡ç®—æ¢¯åº¦
        let gradients = self.compute_gradients(&output_errors);

        // Adamä¼˜åŒ–å™¨æ›´æ–°
        self.adam_update(&gradients);

        // è®¡ç®—æ€»è¯¯å·®
        output_errors.iter().map(|e| e * e).sum::<f64>() / 2.0
    }

    fn compute_gradients(&self, output_errors: &[f64]) -> Vec<LayerGradients> {
        // ä½¿ç”¨ä¸BackpropagationTrainerç›¸åŒçš„æ¢¯åº¦è®¡ç®—æ–¹æ³•
        let num_layers = self.network.layers.len();
        let mut all_gradients = vec![LayerGradients::new(0, 0); num_layers];
        let mut errors = output_errors.to_vec();

        for layer_idx in (0..num_layers).rev() {
            let layer = &self.network.layers[layer_idx];
            let mut weight_gradients = vec![vec![0.0; layer.weights[0].len()]; layer.weights.len()];
            let mut bias_gradients = vec![0.0; layer.biases.len()];
            let mut next_errors = vec![0.0; layer.inputs.len()];

            for neuron_idx in 0..layer.weights.len() {
                let activation = layer.activations[neuron_idx];
                let delta = errors[neuron_idx] * activation * (1.0 - activation);

                for weight_idx in 0..layer.weights[neuron_idx].len() {
                    weight_gradients[neuron_idx][weight_idx] = delta * layer.inputs[weight_idx];
                    next_errors[weight_idx] += delta * layer.weights[neuron_idx][weight_idx];
                }

                bias_gradients[neuron_idx] = delta;
            }

            all_gradients[layer_idx] = LayerGradients {
                weight_gradients,
                bias_gradients,
            };

            errors = next_errors;
        }

        all_gradients
    }

    fn adam_update(&mut self, gradients: &[LayerGradients]) {
        let bias_correction1 = 1.0 - self.beta1.powi(self.time_step as i32);
        let bias_correction2 = 1.0 - self.beta2.powi(self.time_step as i32);

        for (layer_idx, layer_gradients) in gradients.iter().enumerate() {
            let layer = &mut self.network.layers[layer_idx];

            // æ›´æ–°æƒé‡
            for (neuron_idx, neuron_weights) in layer.weights.iter_mut().enumerate() {
                for (weight_idx, weight) in neuron_weights.iter_mut().enumerate() {
                    let gradient = layer_gradients.weight_gradients[neuron_idx][weight_idx];

                    // æ›´æ–°ä¸€é˜¶çŸ©ä¼°è®¡
                    self.m_weights[layer_idx][neuron_idx][weight_idx] =
                        self.beta1 * self.m_weights[layer_idx][neuron_idx][weight_idx] +
                        (1.0 - self.beta1) * gradient;

                    // æ›´æ–°äºŒé˜¶çŸ©ä¼°è®¡
                    self.v_weights[layer_idx][neuron_idx][weight_idx] =
                        self.beta2 * self.v_weights[layer_idx][neuron_idx][weight_idx] +
                        (1.0 - self.beta2) * gradient * gradient;

                    // åç½®æ ¡æ­£
                    let m_hat = self.m_weights[layer_idx][neuron_idx][weight_idx] / bias_correction1;
                    let v_hat = self.v_weights[layer_idx][neuron_idx][weight_idx] / bias_correction2;

                    // æ›´æ–°æƒé‡
                    *weight += self.learning_rate * m_hat / (v_hat.sqrt() + self.epsilon);
                }
            }

            // æ›´æ–°åç½®ï¼ˆç±»ä¼¼æƒé‡æ›´æ–°ï¼‰
            for (bias_idx, bias) in layer.biases.iter_mut().enumerate() {
                let gradient = layer_gradients.bias_gradients[bias_idx];

                self.m_biases[layer_idx][bias_idx] =
                    self.beta1 * self.m_biases[layer_idx][bias_idx] +
                    (1.0 - self.beta1) * gradient;

                self.v_biases[layer_idx][bias_idx] =
                    self.beta2 * self.v_biases[layer_idx][bias_idx] +
                    (1.0 - self.beta2) * gradient * gradient;

                let m_hat = self.m_biases[layer_idx][bias_idx] / bias_correction1;
                let v_hat = self.v_biases[layer_idx][bias_idx] / bias_correction2;

                *bias += self.learning_rate * m_hat / (v_hat.sqrt() + self.epsilon);
            }
        }
    }

    pub fn get_network(&self) -> &MultilayerPerceptron {
        &self.network
    }

    pub fn get_network_mut(&mut self) -> &mut MultilayerPerceptron {
        &mut self.network
    }
}
```

## æ€»ç»“ / Summary

ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å‹ä¸ºæˆ‘ä»¬æä¾›äº†å¼ºå¤§çš„å·¥å…·æ¥è§£å†³å¤æ‚çš„æ¨¡å¼è¯†åˆ«ã€å‡½æ•°é€¼è¿‘å’Œåºåˆ—å»ºæ¨¡é—®é¢˜ã€‚ä»ç®€å•çš„æ„ŸçŸ¥æœºåˆ°å¤æ‚çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œç¥ç»ç½‘ç»œå±•ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„å­¦ä¹ å’Œæ³›åŒ–èƒ½åŠ›ã€‚

Neural network computational models provide us with powerful tools for solving complex pattern recognition, function approximation, and sequence modeling problems. From simple perceptrons to complex deep learning architectures, neural networks demonstrate impressive learning and generalization capabilities.

### å…³é”®ç‰¹ç‚¹ / Key Features

1. **è‡ªé€‚åº”å­¦ä¹ ** / Adaptive Learning
   - é€šè¿‡è®­ç»ƒæ•°æ®è‡ªåŠ¨è°ƒæ•´å‚æ•°
   - å…·æœ‰æ³›åŒ–èƒ½åŠ›

2. **å¹¶è¡Œå¤„ç†** / Parallel Processing
   - åˆ†å¸ƒå¼ä¿¡æ¯å¤„ç†
   - å®¹é”™æ€§å¼º

3. **é€šç”¨é€¼è¿‘èƒ½åŠ›** / Universal Approximation
   - èƒ½å¤Ÿé€¼è¿‘ä»»æ„è¿ç»­å‡½æ•°
   - å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›

4. **å¤šæ ·åŒ–æ¶æ„** / Diverse Architectures
   - å‰é¦ˆã€å¾ªç¯ã€å·ç§¯ç½‘ç»œ
   - é€‚åº”ä¸åŒåº”ç”¨åœºæ™¯

---

## å‚è€ƒæ–‡çŒ® / References

> **è¯´æ˜ / Note**: æœ¬æ–‡æ¡£çš„å‚è€ƒæ–‡çŒ®é‡‡ç”¨ç»Ÿä¸€çš„å¼•ç”¨æ ‡å‡†ï¼Œæ‰€æœ‰æ–‡çŒ®æ¡ç›®å‡æ¥è‡ª `docs/references_database.yaml` æ•°æ®åº“ã€‚æ–‡çŒ®æŒ‰ç…§"ç»å…¸å¥ åŸºæ–‡çŒ® â†’ æ ‡å‡†æ•™æ"çš„å±‚æ¬¡ç»„ç»‡ã€‚

### ç»å…¸å¥ åŸºæ–‡çŒ® / Classic Foundational Literature

1. [McCullochPitts1943] McCulloch, W. S., & Pitts, W. (1943). "A Logical Calculus of the Ideas Immanent in Nervous Activity". *The Bulletin of Mathematical Biophysics*, 5(4), 115-133. DOI: 10.1007/BF02478259
   - **McCulloch-Pittsç¥ç»å…ƒæ¨¡å‹çš„å¼€åˆ›æ€§è®ºæ–‡**ï¼Œäººå·¥ç¥ç»ç½‘ç»œçš„å¥ åŸºä¹‹ä½œã€‚æœ¬æ–‡æ¡£çš„åŸºç¡€æ¦‚å¿µå‚è€ƒæ­¤è®ºæ–‡ã€‚

2. [Rosenblatt1958] Rosenblatt, F. (1958). "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain". *Psychological Review*, 65(6), 386-408. DOI: 10.1037/h0042519
   - **Rosenblattæ„ŸçŸ¥æœºçš„å¼€åˆ›æ€§è®ºæ–‡**ï¼Œç¬¬ä¸€ä¸ªå¯å­¦ä¹ çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚æœ¬æ–‡æ¡£çš„æ„ŸçŸ¥æœºéƒ¨åˆ†å‚è€ƒæ­¤è®ºæ–‡ã€‚

3. [RumelhartHintonWilliams1986] Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). "Learning Representations by Back-Propagating Errors". *Nature*, 323(6088), 533-536. DOI: 10.1038/323533a0
   - **Rumelhart-Hinton-Williamsåå‘ä¼ æ’­ç®—æ³•çš„ç»å…¸è®ºæ–‡**ï¼Œæ·±åº¦å­¦ä¹ çš„åŸºç¡€ã€‚æœ¬æ–‡æ¡£çš„åå‘ä¼ æ’­éƒ¨åˆ†å‚è€ƒæ­¤è®ºæ–‡ã€‚

4. [HochreiterSchmidhuber1997] Hochreiter, S., & Schmidhuber, J. (1997). "Long Short-Term Memory". *Neural Computation*, 9(8), 1735-1780. DOI: 10.1162/neco.1997.9.8.1735
   - Hochreiter-Schmidhuber LSTMçš„å¼€åˆ›æ€§è®ºæ–‡ï¼Œè§£å†³äº†RNNçš„é•¿æœŸä¾èµ–é—®é¢˜ã€‚æœ¬æ–‡æ¡£çš„LSTMéƒ¨åˆ†å‚è€ƒæ­¤è®ºæ–‡ã€‚

### æ ‡å‡†æ•™æ / Standard Textbooks

1. [GoodfellowBengioCourville2016] Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. ISBN: 978-0262035613
   - **Goodfellow-Bengio-Courvilleæ·±åº¦å­¦ä¹ çš„æƒå¨æ•™æ**ï¼Œè¢«èª‰ä¸º"æ·±åº¦å­¦ä¹ åœ£ç»"ã€‚æœ¬æ–‡æ¡£çš„åŸºç¡€æ¡†æ¶å‚è€ƒæ­¤ä¹¦ã€‚

**åœ¨çº¿èµ„æº / Online Resources**:

1. **Wikipedia - Artificial Neural Network**: <https://en.wikipedia.org/wiki/Artificial_neural_network>
   - äººå·¥ç¥ç»ç½‘ç»œçš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«åŸºæœ¬ç»“æ„å’Œå­¦ä¹ ç®—æ³•ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

2. **Wikipedia - Deep Learning**: <https://en.wikipedia.org/wiki/Deep_learning>
   - æ·±åº¦å­¦ä¹ çš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»æ·±åº¦ç¥ç»ç½‘ç»œå’Œè®­ç»ƒæ–¹æ³•ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

3. **Wikipedia - Backpropagation**: <https://en.wikipedia.org/wiki/Backpropagation>
   - åå‘ä¼ æ’­ç®—æ³•çš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«æ¢¯åº¦ä¸‹é™å’Œé“¾å¼æ³•åˆ™ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

4. **Wikipedia - Long Short-Term Memory**: <https://en.wikipedia.org/wiki/Long_short-term_memory>
   - LSTMçš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

**å¼•ç”¨è§„èŒƒè¯´æ˜ / Citation Guidelines**:

æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®å¼•ç”¨è§„èŒƒï¼ˆè§ `docs/å¼•ç”¨è§„èŒƒä¸æ•°æ®åº“.md`ï¼‰ã€‚æ‰€æœ‰å¼•ç”¨æ¡ç›®åœ¨ `docs/references_database.yaml` ä¸­æœ‰å®Œæ•´è®°å½•ã€‚

æœ¬æ–‡æ¡£å†…å®¹å·²å¯¹ç…§Wikipediaç›¸å…³æ¡ç›®ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æœ¯è¯­å®šä¹‰å’Œç†è®ºæ¡†æ¶ä¸å½“å‰å­¦æœ¯æ ‡å‡†ä¸€è‡´ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.1
****æœ€åæ›´æ–° / Last Updated**: 2025-01-11
**çŠ¶æ€ / Status**: å·²å¯¹ç…§Wikipediaæ›´æ–° / Updated with Wikipedia references (as of 2025-01-11)

---

*æœ¬æ–‡æ¡£æä¾›äº†ç¥ç»ç½‘ç»œè®¡ç®—æ¨¡å‹çš„å®Œæ•´å½¢å¼åŒ–æ¡†æ¶ï¼ŒåŒ…æ‹¬æ„ŸçŸ¥æœºã€å¤šå±‚æ„ŸçŸ¥æœºã€åå‘ä¼ æ’­ã€å·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ çš„ç†è®ºåŸºç¡€ã€å½¢å¼åŒ–å®šä¹‰å’Œå®ç°ç¤ºä¾‹ã€‚*
