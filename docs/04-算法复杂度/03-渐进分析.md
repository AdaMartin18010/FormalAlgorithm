---
title: 4.3 æ¸è¿›åˆ†æ / Asymptotic Analysis
version: 1.1
status: maintained
last_updated: 2025-01-11
owner: å¤æ‚åº¦ç†è®ºå·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)

## 4.3 æ¸è¿›åˆ†æ / Asymptotic Analysis

### æ‘˜è¦ / Executive Summary

- ç»Ÿä¸€æ¸è¿›åˆ†æçš„å½¢å¼åŒ–å®šä¹‰ã€æ¸è¿›è®°å·ä¸åˆ†ææ–¹æ³•ã€‚
- å»ºç«‹ç®—æ³•æ€§èƒ½åˆ†æçš„ç»Ÿä¸€ç†è®ºæ¡†æ¶ã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- æ¸è¿›åˆ†æã€å¤§Oè®°å·ã€å¤§Î©è®°å·ã€å¤§Î˜è®°å·ã€æ¸è¿›è®°å·æ€§è´¨ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology & Notation

- æ¸è¿›åˆ†æï¼ˆAsymptotic Analysisï¼‰ï¼šç ”ç©¶ç®—æ³•åœ¨è¾“å…¥è§„æ¨¡è¶‹å‘æ— ç©·å¤§æ—¶çš„æ€§èƒ½è¡Œä¸ºã€‚
- å¤§Oè®°å·ï¼ˆBig-O Notationï¼‰ï¼š`O(f(n))` è¡¨ç¤ºä¸Šç•Œã€‚
- å¤§Î©è®°å·ï¼ˆBig-Omega Notationï¼‰ï¼š`Î©(f(n))` è¡¨ç¤ºä¸‹ç•Œã€‚
- å¤§Î˜è®°å·ï¼ˆBig-Theta Notationï¼‰ï¼š`Î˜(f(n))` è¡¨ç¤ºç´§ç•Œã€‚
- è®°å·çº¦å®šï¼š`O`ã€`Î©`ã€`Î˜`ã€`o`ã€`Ï‰` è¡¨ç¤ºä¸åŒçš„æ¸è¿›å…³ç³»ã€‚

### äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References

- æ—¶é—´å¤æ‚åº¦ï¼šå‚è§ `04-ç®—æ³•å¤æ‚åº¦/01-æ—¶é—´å¤æ‚åº¦.md`ã€‚
- ç©ºé—´å¤æ‚åº¦ï¼šå‚è§ `04-ç®—æ³•å¤æ‚åº¦/02-ç©ºé—´å¤æ‚åº¦.md`ã€‚
- å¤æ‚åº¦ç±»ï¼šå‚è§ `04-ç®—æ³•å¤æ‚åº¦/04-å¤æ‚åº¦ç±».md`ã€‚
- ç®—æ³•å¤æ‚åº¦åŸºç¡€ï¼šå‚è§ `04-ç®—æ³•å¤æ‚åº¦/` ç›¸å…³æ–‡æ¡£ã€‚

### å¿«é€Ÿå¯¼èˆª / Quick Links

- æ¸è¿›è®°å·
- æ¸è¿›åˆ†ææŠ€æœ¯
- æ¸è¿›åˆ†æåº”ç”¨
- å®ç°ç¤ºä¾‹

## ç›®å½• (Table of Contents)

- [4.3 æ¸è¿›åˆ†æ / Asymptotic Analysis](#43-æ¸è¿›åˆ†æ--asymptotic-analysis)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology \& Notation](#æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ--terminology--notation)
  - [äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References](#äº¤å‰å¼•ç”¨å¯¼èˆª--cross-references)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½• (Table of Contents)](#ç›®å½•-table-of-contents)
- [1. åŸºæœ¬æ¦‚å¿µ (Basic Concepts)](#1-åŸºæœ¬æ¦‚å¿µ-basic-concepts)
  - [1.1 æ¸è¿›åˆ†æå®šä¹‰ (Definition of Asymptotic Analysis)](#11-æ¸è¿›åˆ†æå®šä¹‰-definition-of-asymptotic-analysis)
  - [1.2 æ¸è¿›åˆ†æçš„é‡è¦æ€§ (Importance of Asymptotic Analysis)](#12-æ¸è¿›åˆ†æçš„é‡è¦æ€§-importance-of-asymptotic-analysis)
  - [1.3 æ¸è¿›åˆ†æçš„åŸºæœ¬å‡è®¾ (Basic Assumptions of Asymptotic Analysis)](#13-æ¸è¿›åˆ†æçš„åŸºæœ¬å‡è®¾-basic-assumptions-of-asymptotic-analysis)
- [2. æ¸è¿›è®°å· (Asymptotic Notation)](#2-æ¸è¿›è®°å·-asymptotic-notation)
  - [2.1 å¤§Oè®°å· (Big-O Notation)](#21-å¤§oè®°å·-big-o-notation)
  - [2.2 å¤§Î©è®°å· (Big-Omega Notation)](#22-å¤§Ï‰è®°å·-big-omega-notation)
  - [2.3 å¤§Î˜è®°å· (Big-Theta Notation)](#23-å¤§Î¸è®°å·-big-theta-notation)
  - [2.4 å°oå’Œå°Ï‰è®°å· (Little-o and Little-omega Notation)](#24-å°oå’Œå°Ï‰è®°å·-little-o-and-little-omega-notation)
  - [2.5 æ¸è¿›è®°å·çš„æ€§è´¨ (Properties of Asymptotic Notation)](#25-æ¸è¿›è®°å·çš„æ€§è´¨-properties-of-asymptotic-notation)
- [3. æ¸è¿›åˆ†ææŠ€æœ¯ (Asymptotic Analysis Techniques)](#3-æ¸è¿›åˆ†ææŠ€æœ¯-asymptotic-analysis-techniques)
  - [3.1 å¾ªç¯åˆ†æ (Loop Analysis)](#31-å¾ªç¯åˆ†æ-loop-analysis)
  - [3.2 é€’å½’åˆ†æ (Recursion Analysis)](#32-é€’å½’åˆ†æ-recursion-analysis)
  - [3.3 åˆ†æ²»åˆ†æ (Divide and Conquer Analysis)](#33-åˆ†æ²»åˆ†æ-divide-and-conquer-analysis)
  - [3.4 åŠ¨æ€è§„åˆ’åˆ†æ (Dynamic Programming Analysis)](#34-åŠ¨æ€è§„åˆ’åˆ†æ-dynamic-programming-analysis)
- [4. æ¸è¿›åˆ†æåº”ç”¨ (Applications of Asymptotic Analysis)](#4-æ¸è¿›åˆ†æåº”ç”¨-applications-of-asymptotic-analysis)
  - [4.1 ç®—æ³•é€‰æ‹© (Algorithm Selection)](#41-ç®—æ³•é€‰æ‹©-algorithm-selection)
  - [4.2 ç³»ç»Ÿè®¾è®¡ (System Design)](#42-ç³»ç»Ÿè®¾è®¡-system-design)
  - [4.3 æ€§èƒ½ä¼˜åŒ– (Performance Optimization)](#43-æ€§èƒ½ä¼˜åŒ–-performance-optimization)
- [5. æ¸è¿›åˆ†æå·¥å…· (Asymptotic Analysis Tools)](#5-æ¸è¿›åˆ†æå·¥å…·-asymptotic-analysis-tools)
  - [5.1 æ•°å­¦å·¥å…· (Mathematical Tools)](#51-æ•°å­¦å·¥å…·-mathematical-tools)
  - [5.2 è®¡ç®—æœºå·¥å…· (Computer Tools)](#52-è®¡ç®—æœºå·¥å…·-computer-tools)
  - [5.3 å¯è§†åŒ–å·¥å…· (Visualization Tools)](#53-å¯è§†åŒ–å·¥å…·-visualization-tools)
- [6. æ¸è¿›åˆ†æå±€é™æ€§ (Limitations of Asymptotic Analysis)](#6-æ¸è¿›åˆ†æå±€é™æ€§-limitations-of-asymptotic-analysis)
  - [6.1 å¸¸æ•°å› å­å¿½ç•¥ (Ignoring Constant Factors)](#61-å¸¸æ•°å› å­å¿½ç•¥-ignoring-constant-factors)
  - [6.2 è¾“å…¥ç‰¹æ€§å¿½ç•¥ (Ignoring Input Characteristics)](#62-è¾“å…¥ç‰¹æ€§å¿½ç•¥-ignoring-input-characteristics)
  - [6.3 å®é™…çº¦æŸå¿½ç•¥ (Ignoring Practical Constraints)](#63-å®é™…çº¦æŸå¿½ç•¥-ignoring-practical-constraints)
- [7. å®ç°ç¤ºä¾‹ (Implementation Examples)](#7-å®ç°ç¤ºä¾‹-implementation-examples)
  - [7.1 æ¸è¿›åˆ†ææ¡†æ¶ (Asymptotic Analysis Framework)](#71-æ¸è¿›åˆ†ææ¡†æ¶-asymptotic-analysis-framework)
  - [7.2 å…·ä½“ç®—æ³•åˆ†æ (Specific Algorithm Analysis)](#72-å…·ä½“ç®—æ³•åˆ†æ-specific-algorithm-analysis)
  - [7.3 æ¸è¿›åˆ†ææµ‹è¯• (Asymptotic Analysis Testing)](#73-æ¸è¿›åˆ†ææµ‹è¯•-asymptotic-analysis-testing)
- [8. å‚è€ƒæ–‡çŒ® / References](#8-å‚è€ƒæ–‡çŒ®--references)
- [ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure](#ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½--alignment-with-project-structure)
  - [ç›¸å…³æ–‡æ¡£ / Related Documents](#ç›¸å…³æ–‡æ¡£--related-documents)
  - [çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position](#çŸ¥è¯†ä½“ç³»ä½ç½®--knowledge-system-position)
  - [VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents](#viewæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£--view-folder-related-documents)

---

## 1. åŸºæœ¬æ¦‚å¿µ (Basic Concepts)

### 1.1 æ¸è¿›åˆ†æå®šä¹‰ (Definition of Asymptotic Analysis)

**æ¸è¿›åˆ†æå®šä¹‰ / Definition of Asymptotic Analysis:**

æ¸è¿›åˆ†ææ˜¯ç ”ç©¶ç®—æ³•åœ¨è¾“å…¥è§„æ¨¡è¶‹å‘æ— ç©·å¤§æ—¶æ€§èƒ½è¡Œä¸ºçš„æ–¹æ³•ã€‚å®ƒå…³æ³¨ç®—æ³•çš„å¢é•¿ç‡è€Œä¸æ˜¯å…·ä½“çš„è¿è¡Œæ—¶é—´ã€‚

Asymptotic analysis is a method for studying the performance behavior of algorithms as the input size approaches infinity. It focuses on the growth rate of algorithms rather than specific running times.

**æ¸è¿›åˆ†æç›®æ ‡ / Goals of Asymptotic Analysis:**

1. **æ¯”è¾ƒç®—æ³•æ•ˆç‡ / Compare Algorithm Efficiency:**
   - å¿½ç•¥å¸¸æ•°å› å­ / Ignore constant factors
   - å…³æ³¨å¢é•¿ç‡ / Focus on growth rates
   - æä¾›ç†è®ºæ¡†æ¶ / Provide theoretical framework

2. **é¢„æµ‹ç®—æ³•æ€§èƒ½ / Predict Algorithm Performance:**
   - å¤§è¾“å…¥è§„æ¨¡ä¸‹çš„è¡Œä¸º / Behavior for large input sizes
   - æœ€åæƒ…å†µåˆ†æ / Worst-case analysis
   - å¹³å‡æƒ…å†µåˆ†æ / Average-case analysis

### 1.2 æ¸è¿›åˆ†æçš„é‡è¦æ€§ (Importance of Asymptotic Analysis)

**ä¸ºä»€ä¹ˆä½¿ç”¨æ¸è¿›åˆ†æ / Why Use Asymptotic Analysis:**

1. **ç®€åŒ–æ¯”è¾ƒ / Simplifies Comparison:**
   - å¿½ç•¥ç¡¬ä»¶å·®å¼‚ / Ignores hardware differences
   - å¿½ç•¥å®ç°ç»†èŠ‚ / Ignores implementation details
   - å…³æ³¨ç®—æ³•æœ¬è´¨ / Focuses on algorithm essence

2. **ç†è®ºæŒ‡å¯¼ / Theoretical Guidance:**
   - ç®—æ³•è®¾è®¡æŒ‡å¯¼ / Algorithm design guidance
   - æ€§èƒ½ä¼˜åŒ–æ–¹å‘ / Performance optimization direction
   - å¤æ‚åº¦ä¸‹ç•Œ / Complexity lower bounds

3. **å®é™…åº”ç”¨ / Practical Applications:**
   - ç³»ç»Ÿè®¾è®¡å†³ç­– / System design decisions
   - èµ„æºåˆ†é…è§„åˆ’ / Resource allocation planning
   - æ€§èƒ½é¢„æµ‹ / Performance prediction

### 1.3 æ¸è¿›åˆ†æçš„åŸºæœ¬å‡è®¾ (Basic Assumptions of Asymptotic Analysis)

**è®¡ç®—æ¨¡å‹å‡è®¾ / Computational Model Assumptions:**

1. **éšæœºè®¿é—®æœºå™¨ (RAM) / Random Access Machine (RAM):**
   - å¸¸æ•°æ—¶é—´å†…å­˜è®¿é—® / Constant time memory access
   - åŸºæœ¬æ“ä½œå•ä½æ—¶é—´ / Basic operations unit time
   - æ— é™å†…å­˜ / Unlimited memory

2. **è¾“å…¥è§„æ¨¡å®šä¹‰ / Input Size Definition:**
   - æ•°ç»„é•¿åº¦ / Array length
   - å­—ç¬¦ä¸²é•¿åº¦ / String length
   - å›¾èŠ‚ç‚¹æ•° / Number of graph nodes

3. **æˆæœ¬æ¨¡å‹ / Cost Model:**
   - åŸºæœ¬æ“ä½œæˆæœ¬ / Basic operation costs
   - å†…å­˜è®¿é—®æˆæœ¬ / Memory access costs
   - å‡½æ•°è°ƒç”¨æˆæœ¬ / Function call costs

---

## 2. æ¸è¿›è®°å· (Asymptotic Notation)

### 2.1 å¤§Oè®°å· (Big-O Notation)

**å¤§Oè®°å·å®šä¹‰ / Big-O Notation Definition:**

å‡½æ•° $f(n)$ å±äº $O(g(n))$ï¼Œå¦‚æœå­˜åœ¨å¸¸æ•° $c > 0$ å’Œ $n_0 > 0$ï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ $n \geq n_0$ï¼š

Function $f(n)$ belongs to $O(g(n))$ if there exist constants $c > 0$ and $n_0 > 0$ such that for all $n \geq n_0$:

$$f(n) \leq c \cdot g(n)$$

**å¤§Oè®°å·å«ä¹‰ / Meaning of Big-O Notation:**

$f(n) = O(g(n))$ è¡¨ç¤º $f(n)$ çš„å¢é•¿é€Ÿåº¦ä¸è¶…è¿‡ $g(n)$ã€‚

$f(n) = O(g(n))$ means that $f(n)$ grows no faster than $g(n)$.

**å¸¸è§çš„å¤§Oè®°å· / Common Big-O Notations:**

1. **å¸¸æ•°æ—¶é—´ / Constant Time:** $O(1)$
2. **å¯¹æ•°æ—¶é—´ / Logarithmic Time:** $O(\log n)$
3. **çº¿æ€§æ—¶é—´ / Linear Time:** $O(n)$
4. **çº¿æ€§å¯¹æ•°æ—¶é—´ / Linearithmic Time:** $O(n \log n)$
5. **å¹³æ–¹æ—¶é—´ / Quadratic Time:** $O(n^2)$
6. **ç«‹æ–¹æ—¶é—´ / Cubic Time:** $O(n^3)$
7. **æŒ‡æ•°æ—¶é—´ / Exponential Time:** $O(2^n)$
8. **é˜¶ä¹˜æ—¶é—´ / Factorial Time:** $O(n!)$

### 2.2 å¤§Î©è®°å· (Big-Omega Notation)

**å¤§Î©è®°å·å®šä¹‰ / Big-Omega Notation Definition:**

å‡½æ•° $f(n)$ å±äº $\Omega(g(n))$ï¼Œå¦‚æœå­˜åœ¨å¸¸æ•° $c > 0$ å’Œ $n_0 > 0$ï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ $n \geq n_0$ï¼š

Function $f(n)$ belongs to $\Omega(g(n))$ if there exist constants $c > 0$ and $n_0 > 0$ such that for all $n \geq n_0$:

$$f(n) \geq c \cdot g(n)$$

**å¤§Î©è®°å·å«ä¹‰ / Meaning of Big-Omega Notation:**

$f(n) = \Omega(g(n))$ è¡¨ç¤º $f(n)$ çš„å¢é•¿é€Ÿåº¦è‡³å°‘ä¸ $g(n)$ ä¸€æ ·å¿«ã€‚

$f(n) = \Omega(g(n))$ means that $f(n)$ grows at least as fast as $g(n)$.

### 2.3 å¤§Î˜è®°å· (Big-Theta Notation)

**å¤§Î˜è®°å·å®šä¹‰ / Big-Theta Notation Definition:**

å‡½æ•° $f(n)$ å±äº $\Theta(g(n))$ï¼Œå¦‚æœå­˜åœ¨å¸¸æ•° $c_1, c_2 > 0$ å’Œ $n_0 > 0$ï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ $n \geq n_0$ï¼š

Function $f(n)$ belongs to $\Theta(g(n))$ if there exist constants $c_1, c_2 > 0$ and $n_0 > 0$ such that for all $n \geq n_0$:

$$c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)$$

**å¤§Î˜è®°å·å«ä¹‰ / Meaning of Big-Theta Notation:**

$f(n) = \Theta(g(n))$ è¡¨ç¤º $f(n)$ å’Œ $g(n)$ å…·æœ‰ç›¸åŒçš„å¢é•¿ç‡ã€‚

$f(n) = \Theta(g(n))$ means that $f(n)$ and $g(n)$ have the same growth rate.

### 2.4 å°oå’Œå°Ï‰è®°å· (Little-o and Little-omega Notation)

**å°oè®°å·å®šä¹‰ / Little-o Notation Definition:**

å‡½æ•° $f(n)$ å±äº $o(g(n))$ï¼Œå¦‚æœå¯¹äºä»»æ„å¸¸æ•° $c > 0$ï¼Œå­˜åœ¨ $n_0 > 0$ï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ $n \geq n_0$ï¼š

Function $f(n)$ belongs to $o(g(n))$ if for any constant $c > 0$, there exists $n_0 > 0$ such that for all $n \geq n_0$:

$$f(n) < c \cdot g(n)$$

**å°Ï‰è®°å·å®šä¹‰ / Little-omega Notation Definition:**

å‡½æ•° $f(n)$ å±äº $\omega(g(n))$ï¼Œå¦‚æœå¯¹äºä»»æ„å¸¸æ•° $c > 0$ï¼Œå­˜åœ¨ $n_0 > 0$ï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ $n \geq n_0$ï¼š

Function $f(n)$ belongs to $\omega(g(n))$ if for any constant $c > 0$, there exists $n_0 > 0$ such that for all $n \geq n_0$:

$$f(n) > c \cdot g(n)$$

### 2.5 æ¸è¿›è®°å·çš„æ€§è´¨ (Properties of Asymptotic Notation)

**ä¼ é€’æ€§ (Transitivity) / Transitivity:**

å¦‚æœ $f(n) = O(g(n))$ ä¸” $g(n) = O(h(n))$ï¼Œåˆ™ $f(n) = O(h(n))$

If $f(n) = O(g(n))$ and $g(n) = O(h(n))$, then $f(n) = O(h(n))$

**è‡ªåæ€§ (Reflexivity) / Reflexivity:**

$f(n) = O(f(n))$

**å¯¹ç§°æ€§ (Symmetry) / Symmetry:**

$f(n) = \Theta(g(n))$ å½“ä¸”ä»…å½“ $g(n) = \Theta(f(n))$

$f(n) = \Theta(g(n))$ if and only if $g(n) = \Theta(f(n))$

**è½¬ç½®å¯¹ç§°æ€§ (Transpose Symmetry) / Transpose Symmetry:**

$f(n) = O(g(n))$ å½“ä¸”ä»…å½“ $g(n) = \Omega(f(n))$

$f(n) = O(g(n))$ if and only if $g(n) = \Omega(f(n))$

---

## 3. æ¸è¿›åˆ†ææŠ€æœ¯ (Asymptotic Analysis Techniques)

### 3.1 å¾ªç¯åˆ†æ (Loop Analysis)

**å•å±‚å¾ªç¯åˆ†æ / Single Loop Analysis:**

```rust
for i in 0..n {
    // å¸¸æ•°æ—¶é—´æ“ä½œ / Constant time operation
}
// æ—¶é—´å¤æ‚åº¦: O(n) / Time complexity: O(n)
```

**åµŒå¥—å¾ªç¯åˆ†æ / Nested Loop Analysis:**

```rust
for i in 0..n {
    for j in 0..n {
        // å¸¸æ•°æ—¶é—´æ“ä½œ / Constant time operation
    }
}
// æ—¶é—´å¤æ‚åº¦: O(nÂ²) / Time complexity: O(nÂ²)
```

**å¾ªç¯å˜é‡åˆ†æ / Loop Variable Analysis:**

```rust
for i in 1..n {
    i *= 2;  // æ¯æ¬¡å¾ªç¯iç¿»å€ / i doubles each iteration
}
// æ—¶é—´å¤æ‚åº¦: O(log n) / Time complexity: O(log n)
```

### 3.2 é€’å½’åˆ†æ (Recursion Analysis)

**é€’å½’æ ‘æ–¹æ³• / Recursion Tree Method:**

é€’å½’ç®—æ³•çš„å¤æ‚åº¦å¯ä»¥é€šè¿‡é€’å½’æ ‘æ¥åˆ†æï¼š

The complexity of recursive algorithms can be analyzed through recursion trees:

1. **ç»˜åˆ¶é€’å½’æ ‘ / Draw Recursion Tree:**
   - æ¯ä¸ªèŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªå­é—®é¢˜ / Each node represents a subproblem
   - è¾¹è¡¨ç¤ºé€’å½’è°ƒç”¨ / Edges represent recursive calls

2. **è®¡ç®—æ¯å±‚æˆæœ¬ / Calculate Cost per Level:**
   - æ¯å±‚çš„èŠ‚ç‚¹æ•° / Number of nodes per level
   - æ¯ä¸ªèŠ‚ç‚¹çš„æˆæœ¬ / Cost per node

3. **æ±‚å’Œæ€»æˆæœ¬ / Sum Total Cost:**
   - æ‰€æœ‰å±‚çš„æˆæœ¬ä¹‹å’Œ / Sum of costs from all levels

**ä¸»å®šç† (Master Theorem) / Master Theorem:**

å¯¹äºå½¢å¦‚ $T(n) = aT(n/b) + f(n)$ çš„é€’å½’å…³ç³»ï¼š

For recurrence relations of the form $T(n) = aT(n/b) + f(n)$:

$$
T(n) = \begin{cases}
\Theta(n^{\log_b a}) & \text{if } f(n) = O(n^{\log_b a - \epsilon}) \\
\Theta(n^{\log_b a} \log n) & \text{if } f(n) = \Theta(n^{\log_b a}) \\
\Theta(f(n)) & \text{if } f(n) = \Omega(n^{\log_b a + \epsilon})
\end{cases}
$$

### 3.3 åˆ†æ²»åˆ†æ (Divide and Conquer Analysis)

**åˆ†æ²»ç®—æ³•å¤æ‚åº¦ / Divide and Conquer Complexity:**

å¯¹äºåˆ†æ²»ç®—æ³•ï¼Œå¤æ‚åº¦é€šå¸¸æ»¡è¶³ï¼š

For divide and conquer algorithms, complexity typically satisfies:

$$T(n) = aT(n/b) + D(n) + C(n)$$

å…¶ä¸­ / where:

- $a$ æ˜¯å­é—®é¢˜æ•° / is the number of subproblems
- $b$ æ˜¯é—®é¢˜è§„æ¨¡ç¼©å°å› å­ / is the factor by which problem size is reduced
- $D(n)$ æ˜¯åˆ†è§£æˆæœ¬ / is the cost of dividing
- $C(n)$ æ˜¯åˆå¹¶æˆæœ¬ / is the cost of combining

### 3.4 åŠ¨æ€è§„åˆ’åˆ†æ (Dynamic Programming Analysis)

**çŠ¶æ€ç©ºé—´åˆ†æ / State Space Analysis:**

åŠ¨æ€è§„åˆ’çš„æ—¶é—´å¤æ‚åº¦å–å†³äºçŠ¶æ€ç©ºé—´çš„å¤§å°ï¼š

The time complexity of dynamic programming depends on the size of the state space:

$$T(n) = \text{number of states} \times \text{cost per state}$$

**è®°å¿†åŒ–åˆ†æ / Memoization Analysis:**

è®°å¿†åŒ–å¯ä»¥é¿å…é‡å¤è®¡ç®—ï¼Œä½†ç©ºé—´å¤æ‚åº¦å¢åŠ ï¼š

Memoization can avoid repeated computation, but increases space complexity:

$$S(n) = O(\text{number of unique states})$$

---

## 4. æ¸è¿›åˆ†æåº”ç”¨ (Applications of Asymptotic Analysis)

### 4.1 ç®—æ³•é€‰æ‹© (Algorithm Selection)

**åŸºäºå¤æ‚åº¦çš„é€‰æ‹© / Complexity-Based Selection:**

1. **å°è§„æ¨¡é—®é¢˜ / Small Scale Problems:**
   - ç®€å•ç®—æ³•å¯èƒ½æ›´å¿« / Simple algorithms may be faster
   - å¸¸æ•°å› å­é‡è¦ / Constant factors matter

2. **å¤§è§„æ¨¡é—®é¢˜ / Large Scale Problems:**
   - æ¸è¿›å¤æ‚åº¦é‡è¦ / Asymptotic complexity matters
   - å¸¸æ•°å› å­æ¬¡è¦ / Constant factors secondary

3. **å®æ—¶ç³»ç»Ÿ / Real-Time Systems:**
   - æœ€åæƒ…å†µåˆ†æ / Worst-case analysis
   - ç¡®å®šæ€§ç®—æ³• / Deterministic algorithms

### 4.2 ç³»ç»Ÿè®¾è®¡ (System Design)

**èµ„æºåˆ†é… / Resource Allocation:**

1. **å†…å­˜åˆ†é… / Memory Allocation:**
   - åŸºäºç©ºé—´å¤æ‚åº¦ / Based on space complexity
   - è€ƒè™‘æ•°æ®è§„æ¨¡ / Consider data size

2. **å¤„ç†å™¨åˆ†é… / Processor Allocation:**
   - åŸºäºæ—¶é—´å¤æ‚åº¦ / Based on time complexity
   - è€ƒè™‘å¹¶è¡Œæ€§ / Consider parallelism

3. **ç½‘ç»œå¸¦å®½ / Network Bandwidth:**
   - åŸºäºé€šä¿¡å¤æ‚åº¦ / Based on communication complexity
   - è€ƒè™‘åˆ†å¸ƒå¼ç®—æ³• / Consider distributed algorithms

### 4.3 æ€§èƒ½ä¼˜åŒ– (Performance Optimization)

**ç“¶é¢ˆè¯†åˆ« / Bottleneck Identification:**

1. **æ—¶é—´ç“¶é¢ˆ / Time Bottlenecks:**
   - è¯†åˆ«æœ€è€—æ—¶çš„æ“ä½œ / Identify most time-consuming operations
   - ä¼˜åŒ–ç®—æ³•é€‰æ‹© / Optimize algorithm selection

2. **ç©ºé—´ç“¶é¢ˆ / Space Bottlenecks:**
   - è¯†åˆ«å†…å­˜å¯†é›†æ“ä½œ / Identify memory-intensive operations
   - ä¼˜åŒ–æ•°æ®ç»“æ„ / Optimize data structures

3. **I/Oç“¶é¢ˆ / I/O Bottlenecks:**
   - è¯†åˆ«I/Oå¯†é›†æ“ä½œ / Identify I/O-intensive operations
   - ä¼˜åŒ–ç¼“å­˜ç­–ç•¥ / Optimize caching strategies

---

## 5. æ¸è¿›åˆ†æå·¥å…· (Asymptotic Analysis Tools)

### 5.1 æ•°å­¦å·¥å…· (Mathematical Tools)

**æé™è®¡ç®— / Limit Calculation:**

$$
\lim_{n \to \infty} \frac{f(n)}{g(n)} = \begin{cases}
0 & \text{if } f(n) = o(g(n)) \\
c & \text{if } f(n) = \Theta(g(n)) \\
\infty & \text{if } f(n) = \omega(g(n))
\end{cases}
$$

**æ´›å¿…è¾¾æ³•åˆ™ / L'HÃ´pital's Rule:**

å½“ $\lim_{n \to \infty} f(n) = \lim_{n \to \infty} g(n) = \infty$ æ—¶ï¼š

When $\lim_{n \to \infty} f(n) = \lim_{n \to \infty} g(n) = \infty$:

$$\lim_{n \to \infty} \frac{f(n)}{g(n)} = \lim_{n \to \infty} \frac{f'(n)}{g'(n)}$$

### 5.2 è®¡ç®—æœºå·¥å…· (Computer Tools)

**å¤æ‚åº¦åˆ†æå™¨ / Complexity Analyzer:**

```rust
/// æ¸è¿›åˆ†æå·¥å…· / Asymptotic Analysis Tool
pub struct AsymptoticAnalyzer {
    measurements: Vec<(usize, f64)>,
}

impl AsymptoticAnalyzer {
    /// åˆ›å»ºæ–°çš„åˆ†æå™¨ / Create new analyzer
    pub fn new() -> Self {
        AsymptoticAnalyzer {
            measurements: Vec::new(),
        }
    }

    /// æ·»åŠ æµ‹é‡æ•°æ® / Add measurement data
    pub fn add_measurement(&mut self, input_size: usize, time: f64) {
        self.measurements.push((input_size, time));
    }

    /// åˆ†æå¢é•¿ç‡ / Analyze growth rate
    pub fn analyze_growth_rate(&self) -> String {
        if self.measurements.len() < 2 {
            return "Insufficient data".to_string();
        }

        let mut ratios = Vec::new();
        for i in 1..self.measurements.len() {
            let prev_size = self.measurements[i-1].0 as f64;
            let curr_size = self.measurements[i].0 as f64;
            let prev_time = self.measurements[i-1].1;
            let curr_time = self.measurements[i].1;

            let size_ratio = curr_size / prev_size;
            let time_ratio = curr_time / prev_time;

            ratios.push((size_ratio, time_ratio));
        }

        // è®¡ç®—å¹³å‡å¢é•¿ç‡ / Calculate average growth rate
        let avg_time_ratio: f64 = ratios.iter().map(|(_, tr)| tr).sum::<f64>() / ratios.len() as f64;

        match avg_time_ratio {
            r if r < 1.5 => "O(1)".to_string(),
            r if r < 2.5 => "O(log n)".to_string(),
            r if r < 3.5 => "O(n)".to_string(),
            r if r < 4.5 => "O(n log n)".to_string(),
            r if r < 6.0 => "O(nÂ²)".to_string(),
            r if r < 10.0 => "O(nÂ³)".to_string(),
            _ => "O(2â¿) or higher".to_string(),
        }
    }

    /// é¢„æµ‹å¤§è¾“å…¥è§„æ¨¡æ€§èƒ½ / Predict performance for large inputs
    pub fn predict_performance(&self, target_size: usize) -> Option<f64> {
        if self.measurements.is_empty() {
            return None;
        }

        let (last_size, last_time) = self.measurements.last().unwrap();
        let growth_rate = self.analyze_growth_rate();

        let size_ratio = target_size as f64 / *last_size as f64;

        match growth_rate.as_str() {
            "O(1)" => Some(last_time),
            "O(log n)" => Some(last_time * size_ratio.log2()),
            "O(n)" => Some(last_time * size_ratio),
            "O(n log n)" => Some(last_time * size_ratio * size_ratio.log2()),
            "O(nÂ²)" => Some(last_time * size_ratio.powi(2)),
            "O(nÂ³)" => Some(last_time * size_ratio.powi(3)),
            _ => None,
        }
    }
}
```

### 5.3 å¯è§†åŒ–å·¥å…· (Visualization Tools)

**å¤æ‚åº¦å›¾è¡¨ / Complexity Charts:**

```rust
/// å¤æ‚åº¦å¯è§†åŒ–å·¥å…· / Complexity Visualization Tool
pub struct ComplexityVisualizer;

impl ComplexityVisualizer {
    /// ç”Ÿæˆå¤æ‚åº¦æ¯”è¾ƒå›¾ / Generate complexity comparison chart
    pub fn generate_complexity_chart() -> String {
        let complexities = vec![
            ("O(1)", "Constant"),
            ("O(log n)", "Logarithmic"),
            ("O(n)", "Linear"),
            ("O(n log n)", "Linearithmic"),
            ("O(nÂ²)", "Quadratic"),
            ("O(nÂ³)", "Cubic"),
            ("O(2â¿)", "Exponential"),
        ];

        let mut chart = String::new();
        chart.push_str("Complexity Comparison Chart:\n");
        chart.push_str("==========================\n");

        for (notation, name) in complexities {
            chart.push_str(&format!("{:<12} - {}\n", notation, name));
        }

        chart
    }

    /// ç”Ÿæˆæ€§èƒ½é¢„æµ‹å›¾ / Generate performance prediction chart
    pub fn generate_prediction_chart(measurements: &[(usize, f64)]) -> String {
        let mut chart = String::new();
        chart.push_str("Performance Prediction:\n");
        chart.push_str("=====================\n");

        for (size, time) in measurements {
            chart.push_str(&format!("Input size: {:<8} | Time: {:.6}s\n", size, time));
        }

        chart
    }
}
```

---

## 6. æ¸è¿›åˆ†æå±€é™æ€§ (Limitations of Asymptotic Analysis)

### 6.1 å¸¸æ•°å› å­å¿½ç•¥ (Ignoring Constant Factors)

**å¸¸æ•°å› å­çš„é‡è¦æ€§ / Importance of Constant Factors:**

æ¸è¿›åˆ†æå¿½ç•¥å¸¸æ•°å› å­ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼š

Asymptotic analysis ignores constant factors, but in practical applications:

1. **å°è§„æ¨¡é—®é¢˜ / Small Scale Problems:**
   - å¸¸æ•°å› å­å¯èƒ½ä¸»å¯¼æ€§èƒ½ / Constant factors may dominate performance
   - å®é™…è¿è¡Œæ—¶é—´æ›´é‡è¦ / Actual running time more important

2. **ç¡¬ä»¶å·®å¼‚ / Hardware Differences:**
   - ä¸åŒç¡¬ä»¶ä¸Šçš„å¸¸æ•°å› å­ä¸åŒ / Constant factors differ on different hardware
   - ç¼“å­˜æ•ˆåº”å½±å“å¸¸æ•°å› å­ / Cache effects influence constant factors

### 6.2 è¾“å…¥ç‰¹æ€§å¿½ç•¥ (Ignoring Input Characteristics)

**è¾“å…¥ç‰¹æ€§çš„å½±å“ / Impact of Input Characteristics:**

1. **æ•°æ®åˆ†å¸ƒ / Data Distribution:**
   - å¹³å‡æƒ…å†µ vs æœ€åæƒ…å†µ / Average case vs worst case
   - è¾“å…¥æ¨¡å¼å½±å“æ€§èƒ½ / Input patterns affect performance

2. **æ•°æ®å±€éƒ¨æ€§ / Data Locality:**
   - ç¼“å­˜å‹å¥½çš„ç®—æ³• / Cache-friendly algorithms
   - å†…å­˜è®¿é—®æ¨¡å¼ / Memory access patterns

### 6.3 å®é™…çº¦æŸå¿½ç•¥ (Ignoring Practical Constraints)

**å®é™…çº¦æŸçš„å½±å“ / Impact of Practical Constraints:**

1. **å†…å­˜é™åˆ¶ / Memory Constraints:**
   - ç†è®ºç®—æ³•å¯èƒ½ä¸å®ç”¨ / Theoretical algorithms may not be practical
   - ç©ºé—´å¤æ‚åº¦é™åˆ¶ / Space complexity constraints

2. **å¹¶è¡Œæ€§é™åˆ¶ / Parallelism Constraints:**
   - ç†è®ºå¹¶è¡Œç®—æ³•å¯èƒ½ä¸å®ç”¨ / Theoretical parallel algorithms may not be practical
   - é€šä¿¡å¼€é”€ / Communication overhead

---

## 7. å®ç°ç¤ºä¾‹ (Implementation Examples)

### 7.1 æ¸è¿›åˆ†ææ¡†æ¶ (Asymptotic Analysis Framework)

```rust
use std::time::Instant;
use std::collections::HashMap;

/// æ¸è¿›åˆ†ææ¡†æ¶ / Asymptotic Analysis Framework
pub struct AsymptoticAnalysisFramework {
    algorithms: HashMap<String, Box<dyn Fn(usize) -> Vec<usize>>>,
    measurements: HashMap<String, Vec<(usize, f64)>>,
}

impl AsymptoticAnalysisFramework {
    /// åˆ›å»ºæ–°çš„åˆ†ææ¡†æ¶ / Create new analysis framework
    pub fn new() -> Self {
        AsymptoticAnalysisFramework {
            algorithms: HashMap::new(),
            measurements: HashMap::new(),
        }
    }

    /// æ³¨å†Œç®—æ³• / Register algorithm
    pub fn register_algorithm<F>(&mut self, name: &str, algorithm: F)
    where
        F: Fn(usize) -> Vec<usize> + 'static,
    {
        self.algorithms.insert(name.to_string(), Box::new(algorithm));
    }

    /// æµ‹é‡ç®—æ³•æ€§èƒ½ / Measure algorithm performance
    pub fn measure_algorithm(&mut self, name: &str, input_sizes: &[usize]) {
        if let Some(algorithm) = self.algorithms.get(name) {
            let mut measurements = Vec::new();

            for &size in input_sizes {
                let start = Instant::now();
                let _result = algorithm(size);
                let duration = start.elapsed();

                measurements.push((size, duration.as_secs_f64()));
            }

            self.measurements.insert(name.to_string(), measurements);
        }
    }

    /// åˆ†æç®—æ³•å¤æ‚åº¦ / Analyze algorithm complexity
    pub fn analyze_complexity(&self, name: &str) -> Option<String> {
        if let Some(measurements) = self.measurements.get(name) {
            let mut analyzer = AsymptoticAnalyzer::new();

            for &(size, time) in measurements {
                analyzer.add_measurement(size, time);
            }

            Some(analyzer.analyze_growth_rate())
        } else {
            None
        }
    }

    /// æ¯”è¾ƒç®—æ³•æ€§èƒ½ / Compare algorithm performance
    pub fn compare_algorithms(&self, names: &[&str]) -> String {
        let mut comparison = String::new();
        comparison.push_str("Algorithm Complexity Comparison:\n");
        comparison.push_str("================================\n");

        for &name in names {
            if let Some(complexity) = self.analyze_complexity(name) {
                comparison.push_str(&format!("{:<20}: {}\n", name, complexity));
            }
        }

        comparison
    }
}
```

### 7.2 å…·ä½“ç®—æ³•åˆ†æ (Specific Algorithm Analysis)

```rust
/// æ’åºç®—æ³•åˆ†æ / Sorting Algorithm Analysis
pub struct SortingAnalyzer;

impl SortingAnalyzer {
    /// å†’æ³¡æ’åº / Bubble Sort
    pub fn bubble_sort(arr: &mut [usize]) {
        let n = arr.len();
        for i in 0..n {
            for j in 0..n-i-1 {
                if arr[j] > arr[j+1] {
                    arr.swap(j, j+1);
                }
            }
        }
    }

    /// å¿«é€Ÿæ’åº / Quick Sort
    pub fn quick_sort(arr: &mut [usize]) {
        if arr.len() <= 1 {
            return;
        }

        let pivot = arr[arr.len() / 2];
        let mut left = Vec::new();
        let mut right = Vec::new();

        for &x in arr.iter() {
            if x < pivot {
                left.push(x);
            } else if x > pivot {
                right.push(x);
            }
        }

        Self::quick_sort(&mut left);
        Self::quick_sort(&mut right);

        arr[..left.len()].copy_from_slice(&left);
        arr[left.len()] = pivot;
        arr[left.len()+1..].copy_from_slice(&right);
    }

    /// å½’å¹¶æ’åº / Merge Sort
    pub fn merge_sort(arr: &mut [usize]) {
        if arr.len() <= 1 {
            return;
        }

        let mid = arr.len() / 2;
        let (left, right) = arr.split_at_mut(mid);

        Self::merge_sort(left);
        Self::merge_sort(right);

        let mut merged = Vec::with_capacity(arr.len());
        let mut i = 0;
        let mut j = 0;

        while i < left.len() && j < right.len() {
            if left[i] <= right[j] {
                merged.push(left[i]);
                i += 1;
            } else {
                merged.push(right[j]);
                j += 1;
            }
        }

        merged.extend_from_slice(&left[i..]);
        merged.extend_from_slice(&right[j..]);

        arr.copy_from_slice(&merged);
    }
}

/// æœç´¢ç®—æ³•åˆ†æ / Search Algorithm Analysis
pub struct SearchAnalyzer;

impl SearchAnalyzer {
    /// çº¿æ€§æœç´¢ / Linear Search
    pub fn linear_search(arr: &[usize], target: usize) -> Option<usize> {
        for (i, &x) in arr.iter().enumerate() {
            if x == target {
                return Some(i);
            }
        }
        None
    }

    /// äºŒåˆ†æœç´¢ / Binary Search
    pub fn binary_search(arr: &[usize], target: usize) -> Option<usize> {
        let mut left = 0;
        let mut right = arr.len();

        while left < right {
            let mid = left + (right - left) / 2;
            if arr[mid] == target {
                return Some(mid);
            } else if arr[mid] < target {
                left = mid + 1;
            } else {
                right = mid;
            }
        }

        None
    }
}
```

### 7.3 æ¸è¿›åˆ†ææµ‹è¯• (Asymptotic Analysis Testing)

```rust
# [cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_asymptotic_analyzer() {
        let mut analyzer = AsymptoticAnalyzer::new();

        // æ¨¡æ‹Ÿçº¿æ€§å¢é•¿ / Simulate linear growth
        analyzer.add_measurement(100, 1.0);
        analyzer.add_measurement(200, 2.0);
        analyzer.add_measurement(400, 4.0);

        let complexity = analyzer.analyze_growth_rate();
        assert_eq!(complexity, "O(n)");
    }

    #[test]
    fn test_complexity_framework() {
        let mut framework = AsymptoticAnalysisFramework::new();

        // æ³¨å†Œçº¿æ€§ç®—æ³• / Register linear algorithm
        framework.register_algorithm("linear", |n| {
            (0..n).collect()
        });

        // æ³¨å†Œå¹³æ–¹ç®—æ³• / Register quadratic algorithm
        framework.register_algorithm("quadratic", |n| {
            let mut result = Vec::new();
            for i in 0..n {
                for j in 0..n {
                    result.push(i * j);
                }
            }
            result
        });

        let input_sizes = vec![100, 200, 400];
        framework.measure_algorithm("linear", &input_sizes);
        framework.measure_algorithm("quadratic", &input_sizes);

        let comparison = framework.compare_algorithms(&["linear", "quadratic"]);
        assert!(comparison.contains("linear"));
        assert!(comparison.contains("quadratic"));
    }

    #[test]
    fn test_sorting_analysis() {
        let mut arr = vec![3, 1, 4, 1, 5, 9, 2, 6];
        let mut arr_copy = arr.clone();

        // æµ‹è¯•å†’æ³¡æ’åº / Test bubble sort
        SortingAnalyzer::bubble_sort(&mut arr);
        assert_eq!(arr, vec![1, 1, 2, 3, 4, 5, 6, 9]);

        // æµ‹è¯•å¿«é€Ÿæ’åº / Test quick sort
        SortingAnalyzer::quick_sort(&mut arr_copy);
        assert_eq!(arr_copy, vec![1, 1, 2, 3, 4, 5, 6, 9]);
    }

    #[test]
    fn test_search_analysis() {
        let arr = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];

        // æµ‹è¯•çº¿æ€§æœç´¢ / Test linear search
        assert_eq!(SearchAnalyzer::linear_search(&arr, 5), Some(4));
        assert_eq!(SearchAnalyzer::linear_search(&arr, 11), None);

        // æµ‹è¯•äºŒåˆ†æœç´¢ / Test binary search
        assert_eq!(SearchAnalyzer::binary_search(&arr, 5), Some(4));
        assert_eq!(SearchAnalyzer::binary_search(&arr, 11), None);
    }
}
```

---

## 8. å‚è€ƒæ–‡çŒ® / References

æœ¬æ–‡æ¡£åŸºäºå·²å‘è¡¨çš„å­¦æœ¯æ–‡çŒ®å’Œå…¬å¼€èµ„æ–™ç¼–å†™ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦å‚è€ƒæ–‡çŒ®ï¼š

**ç»å…¸å¥ åŸºæ–‡çŒ® / Classic Foundational Literature**:

1. [Knuth1976] Knuth, D. E. (1976). "Big Omicron and Big Omega and Big Theta". *SIGACT News*, 8(2): 18-24. DOI: 10.1145/1008328.1008329.
   - æ¸è¿›è®°å·çš„æ ‡å‡†åŒ–å®šä¹‰ï¼ŒKnuthçš„ç»å…¸è®ºæ–‡ã€‚æœ¬æ–‡æ¡£Â§3.2çš„æ¸è¿›è®°å·åŸºäºæ­¤è®ºæ–‡ã€‚

2. [Knuth1997] Knuth, D. E. (1997). *The Art of Computer Programming, Volume 1: Fundamental Algorithms* (3rd Edition). Addison-Wesley. ISBN: 978-0201896831.
   - ç®—æ³•åˆ†æçš„ç»å…¸å·¨è‘—ï¼Œç³»ç»Ÿä»‹ç»æ¸è¿›åˆ†ææ–¹æ³•ã€‚æœ¬æ–‡æ¡£Â§3.3çš„åˆ†ææŠ€æœ¯å‚è€ƒæ­¤ä¹¦ã€‚

3. [GrahamKnuthPatashnik1994] Graham, R. L., Knuth, D. E., & Patashnik, O. (1994). *Concrete Mathematics: A Foundation for Computer Science* (2nd Edition). Addison-Wesley. ISBN: 978-0201558029.
   - ç¦»æ•£æ•°å­¦ä¸æ¸è¿›åˆ†æçš„ç»å…¸æ•™æï¼ŒåŒ…å«å¤§é‡æ±‚å’Œä¸é€’å½’åˆ†ææŠ€æœ¯ã€‚æœ¬æ–‡æ¡£Â§3.3.2çš„é€’å½’åˆ†æå‚è€ƒæ­¤ä¹¦ã€‚

**æ ‡å‡†æ•™æ / Standard Textbooks**:

1. [Cormen2009] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). *Introduction to Algorithms* (3rd Edition). MIT Press.
   - ç®—æ³•å¯¼è®ºï¼Œå…¨é¢ä»‹ç»æ¸è¿›åˆ†æåŠå…¶åº”ç”¨ã€‚æœ¬æ–‡æ¡£Â§3.1-Â§3.4çš„å†…å®¹å‚è€ƒæ­¤ä¹¦ã€‚

2. Sedgewick, R., & Wayne, K. (2011). *Algorithms* (4th Edition). Addison-Wesley.
   - ç°ä»£ç®—æ³•æ•™æï¼Œå¼ºè°ƒå®è·µä¸­çš„æ¸è¿›åˆ†æã€‚

3. Aho, A. V., Hopcroft, J. E., & Ullman, J. D. (1974). *The Design and Analysis of Computer Algorithms*. Addison-Wesley.
   - ç®—æ³•è®¾è®¡ä¸åˆ†æçš„ç»å…¸æ•™æï¼Œæ—©æœŸæ¸è¿›åˆ†ææ–¹æ³•ã€‚

**ç®—æ³•å¤æ‚åº¦åˆ†æ / Algorithm Complexity Analysis**:

1. [Hartmanis1965] Hartmanis, J., & Stearns, R. E. (1965). "On the Computational Complexity of Algorithms". *Transactions of the American Mathematical Society*, 117: 285-306.
   - è®¡ç®—å¤æ‚æ€§ç†è®ºçš„å¥ åŸºæ€§è®ºæ–‡ï¼Œæ¸è¿›åˆ†æçš„ç†è®ºåŸºç¡€ã€‚

2. [AroraBarak2009] Arora, S., & Barak, B. (2009). *Computational Complexity: A Modern Approach*. Cambridge University Press.
   - è®¡ç®—å¤æ‚åº¦ç†è®ºçš„ç°ä»£ç»¼åˆï¼Œæ·±å…¥ä»‹ç»æ¸è¿›åˆ†æã€‚

**å®è·µåº”ç”¨ / Practical Applications**:

1. Bentley, J. (2000). *Programming Pearls* (2nd Edition). Addison-Wesley.
   - ç¼–ç¨‹å®è·µä¸­çš„ç®—æ³•åˆ†æï¼Œå¼ºè°ƒæ¸è¿›åˆ†æçš„å®ç”¨æ€§ã€‚

2. Kernighan, B. W., & Pike, R. (1999). *The Practice of Programming*. Addison-Wesley.
    - ç¨‹åºè®¾è®¡å®è·µï¼ŒåŒ…å«æ€§èƒ½åˆ†ææ–¹æ³•ã€‚

**åœ¨çº¿èµ„æº / Online Resources**:

1. **Wikipedia - Big O Notation**: <https://en.wikipedia.org/wiki/Big_O_notation>
   - å¤§Oè®°å·çš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«æ¸è¿›åˆ†æçš„è®°å·ç³»ç»Ÿï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

2. **Wikipedia - Asymptotic Analysis**: <https://en.wikipedia.org/wiki/Asymptotic_analysis>
   - æ¸è¿›åˆ†æçš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»ç®—æ³•åˆ†æçš„æ¸è¿›æ–¹æ³•ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

3. **Wikipedia - Computational Complexity Theory**: <https://en.wikipedia.org/wiki/Computational_complexity_theory>
   - è®¡ç®—å¤æ‚åº¦ç†è®ºçš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«æ¸è¿›åˆ†æçš„ç†è®ºåŸºç¡€ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

4. MIT OpenCourseWare - Introduction to Algorithms: <https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/>
   - MITç®—æ³•è¯¾ç¨‹ï¼ŒåŒ…å«æ¸è¿›åˆ†æè®²åº§ã€‚

**å¼•ç”¨è§„èŒƒè¯´æ˜ / Citation Guidelines**:

æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®å¼•ç”¨è§„èŒƒï¼ˆè§ `docs/å¼•ç”¨è§„èŒƒä¸æ•°æ®åº“.md`ï¼‰ã€‚æ‰€æœ‰å¼•ç”¨æ¡ç›®åœ¨ `docs/references_database.yaml` ä¸­æœ‰å®Œæ•´è®°å½•ã€‚

æœ¬æ–‡æ¡£å†…å®¹å·²å¯¹ç…§Wikipediaç›¸å…³æ¡ç›®ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æœ¯è¯­å®šä¹‰å’Œç†è®ºæ¡†æ¶ä¸å½“å‰å­¦æœ¯æ ‡å‡†ä¸€è‡´ã€‚

---

## ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure

### ç›¸å…³æ–‡æ¡£ / Related Documents

- `04-ç®—æ³•å¤æ‚åº¦/01-æ—¶é—´å¤æ‚åº¦.md` - æ—¶é—´å¤æ‚åº¦ï¼ˆæ¸è¿›åˆ†æçš„åº”ç”¨ï¼‰
- `04-ç®—æ³•å¤æ‚åº¦/02-ç©ºé—´å¤æ‚åº¦.md` - ç©ºé—´å¤æ‚åº¦ï¼ˆæ¸è¿›åˆ†æçš„åº”ç”¨ï¼‰
- `04-ç®—æ³•å¤æ‚åº¦/04-å¤æ‚åº¦ç±».md` - å¤æ‚åº¦ç±»ï¼ˆæ¸è¿›åˆ†æçš„åˆ†ç±»ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/01-ç®—æ³•è®¾è®¡ç†è®º.md` - ç®—æ³•è®¾è®¡ç†è®ºï¼ˆæ¸è¿›åˆ†æåœ¨ç®—æ³•è®¾è®¡ä¸­çš„åº”ç”¨ï¼‰
- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` - ç®—æ³•å…¨æ™¯æ¢³ç†ï¼ˆåŒ…å«å¤æ‚åº¦åˆ†ææ¦‚è¿°ï¼‰
- `view/VIEWå†…å®¹æ€»ç´¢å¼•-2025-01-11.md` - VIEWæ–‡ä»¶å¤¹å®Œæ•´ç´¢å¼•

### çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position

æœ¬æ–‡æ¡£å±äº **04-ç®—æ³•å¤æ‚åº¦** æ¨¡å—ï¼Œæ˜¯ç®—æ³•å¤æ‚åº¦åˆ†æçš„å·¥å…·æ–‡æ¡£ï¼Œä¸ºæ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦åˆ†ææä¾›æ¸è¿›åˆ†ææ–¹æ³•ã€‚

### VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents

- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` Â§4 - ä¿¡æ¯Â·æ•°æ®Â·æ•°æ®ç»“æ„ï¼ˆå¤æ‚åº¦åˆ†æï¼‰
- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` Â§5 - ä¿¡æ¯é€šä¿¡ä¸­çš„ç®—æ³•å¤æ‚åº¦ï¼ˆæ¸è¿›åˆ†æï¼‰
- `view/VIEWå†…å®¹æ€»ç´¢å¼•-2025-01-11.md` Â§4 - å†…å®¹ä¸»é¢˜ç´¢å¼•ï¼ˆç®—æ³•å¤æ‚åº¦ï¼‰
- `view/VIEWå†…å®¹æ€»ç´¢å¼•-2025-01-11.md` - VIEWæ–‡ä»¶å¤¹å®Œæ•´ç´¢å¼•

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.1
****æœ€åæ›´æ–° / Last Updated**: 2025-01-11
**çŠ¶æ€ / Status**: å·²å¯¹ç…§Wikipediaæ›´æ–° / Updated with Wikipedia references (as of 2025-01-11)

---

*æœ¬æ–‡æ¡£æä¾›äº†æ¸è¿›åˆ†æçš„å…¨é¢ç†è®ºæ¡†æ¶ï¼ŒåŒ…æ‹¬åŸºæœ¬æ¦‚å¿µã€æ¸è¿›è®°å·ã€åˆ†ææŠ€æœ¯ã€åº”ç”¨é¢†åŸŸã€åˆ†æå·¥å…·å’Œå®ç°ç¤ºä¾‹ã€‚æ‰€æœ‰å†…å®¹å‡é‡‡ç”¨ä¸¥æ ¼çš„æ•°å­¦å½¢å¼åŒ–è¡¨ç¤ºï¼Œå¹¶åŒ…å«å®Œæ•´çš„Rustä»£ç å®ç°ã€‚*
