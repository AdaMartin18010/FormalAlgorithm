# 算法分析理论 / Algorithm Analysis Theory

## 目录

- [算法分析理论 / Algorithm Analysis Theory](#算法分析理论--algorithm-analysis-theory)
  - [目录](#目录)
  - [概述 / Overview](#概述--overview)
  - [1. 理论基础 / Theoretical Foundations](#1-理论基础--theoretical-foundations)
    - [1.1 算法分析基础理论](#11-算法分析基础理论)
    - [1.2 渐进分析理论](#12-渐进分析理论)
    - [1.3 摊还分析理论](#13-摊还分析理论)
    - [1.4 概率分析理论](#14-概率分析理论)
    - [1.5 实验分析理论](#15-实验分析理论)
    - [1.6 分析复杂度理论](#16-分析复杂度理论)
  - [2. 基本概念 / Basic Concepts](#2-基本概念--basic-concepts)
    - [2.1 算法分析定义 / Definition of Algorithm Analysis](#21-算法分析定义--definition-of-algorithm-analysis)
    - [2.2 分析维度 / Analysis Dimensions](#22-分析维度--analysis-dimensions)
  - [3. 渐进分析 / Asymptotic Analysis](#3-渐进分析--asymptotic-analysis)
    - [3.1 渐进记号 / Asymptotic Notation](#31-渐进记号--asymptotic-notation)
    - [3.2 递归关系分析 / Recurrence Relation Analysis](#32-递归关系分析--recurrence-relation-analysis)
  - [4. 摊还分析 / Amortized Analysis](#4-摊还分析--amortized-analysis)
    - [4.1 聚合分析 / Aggregate Analysis](#41-聚合分析--aggregate-analysis)
    - [4.2 银行家方法 / Banker's Method](#42-银行家方法--bankers-method)
  - [5. 概率分析 / Probabilistic Analysis](#5-概率分析--probabilistic-analysis)
    - [5.1 随机算法分析 / Randomized Algorithm Analysis](#51-随机算法分析--randomized-algorithm-analysis)
    - [5.2 马尔可夫链分析 / Markov Chain Analysis](#52-马尔可夫链分析--markov-chain-analysis)
  - [6. 实验分析 / Experimental Analysis](#6-实验分析--experimental-analysis)
    - [6.1 性能测试框架 / Performance Testing Framework](#61-性能测试框架--performance-testing-framework)
  - [7. 应用案例 / Application Cases](#7-应用案例--application-cases)
    - [7.1 案例1：排序算法比较分析 / Case 1: Comparative Analysis of Sorting Algorithms](#71-案例1排序算法比较分析--case-1-comparative-analysis-of-sorting-algorithms)
  - [8. 总结 / Summary](#8-总结--summary)
    - [8.1 关键要点 / Key Points](#81-关键要点--key-points)

## 概述 / Overview

算法分析理论是研究如何分析算法性能和复杂度的学科。它提供了评估算法效率的数学工具和方法，包括时间复杂度分析、空间复杂度分析、摊还分析、概率分析等多个方面。

Algorithm analysis theory studies how to analyze algorithm performance and complexity. It provides mathematical tools and methods for evaluating algorithm efficiency, including time complexity analysis, space complexity analysis, amortized analysis, probabilistic analysis, and other aspects.

## 1. 理论基础 / Theoretical Foundations

### 1.1 算法分析基础理论

**定义 1.1.1** (算法分析系统 / Algorithm Analysis System)
算法分析系统是一个六元组 $(A, I, M, F, P, R)$，其中：

- $A$ 是算法集合
- $I$ 是输入空间
- $M$ 是度量函数集合
- $F$ 是分析函数 $F: A \times I \times M \rightarrow \mathbb{R}^+$
- $P$ 是性能预测函数 $P: A \times I \rightarrow \mathbb{R}^+$
- $R$ 是分析结果集合

**Definition 1.1.1** (Algorithm Analysis System)
An algorithm analysis system is a 6-tuple $(A, I, M, F, P, R)$, where:

- $A$ is the set of algorithms
- $I$ is the input space
- $M$ is the set of metric functions
- $F$ is the analysis function $F: A \times I \times M \rightarrow \mathbb{R}^+$
- $P$ is the performance prediction function $P: A \times I \rightarrow \mathbb{R}^+$
- $R$ is the set of analysis results

**定义 1.1.2** (分析问题 / Analysis Problem)
给定算法分析系统 $(A, I, M, F, P, R)$，分析问题是对于算法 $a \in A$ 和输入 $x \in I$，计算 $F(a, x, m)$ 其中 $m \in M$。

**Definition 1.1.2** (Analysis Problem)
Given an algorithm analysis system $(A, I, M, F, P, R)$, the analysis problem is to compute $F(a, x, m)$ for algorithm $a \in A$ and input $x \in I$ where $m \in M$.

**定理 1.1.1** (分析问题可解性 / Analysis Problem Solvability)
对于任意算法分析系统 $(A, I, M, F, P, R)$，如果 $A$ 和 $I$ 是有限集且 $F$ 是计算函数，则分析问题是可解的。

**Theorem 1.1.1** (Analysis Problem Solvability)
For any algorithm analysis system $(A, I, M, F, P, R)$, if $A$ and $I$ are finite sets and $F$ is a computable function, then the analysis problem is solvable.

**证明** / **Proof**:
由于 $A$ 和 $I$ 是有限集，$F$ 是计算函数，因此对于任意 $a \in A$ 和 $x \in I$，$F(a, x, m)$ 可以在有限步内计算出来。

Since $A$ and $I$ are finite sets and $F$ is a computable function, for any $a \in A$ and $x \in I$, $F(a, x, m)$ can be computed in finite steps.

### 1.2 渐进分析理论

**定义 1.2.1** (渐进关系 / Asymptotic Relation)
对于函数 $f, g: \mathbb{N} \rightarrow \mathbb{R}^+$，我们定义：

1. $f(n) = O(g(n))$ 如果存在常数 $c > 0$ 和 $n_0 \in \mathbb{N}$ 使得：
   $$\forall n \geq n_0: f(n) \leq c \cdot g(n)$$
2. $f(n) = \Omega(g(n))$ 如果存在常数 $c > 0$ 和 $n_0 \in \mathbb{N}$ 使得：
   $$\forall n \geq n_0: f(n) \geq c \cdot g(n)$$
3. $f(n) = \Theta(g(n))$ 如果 $f(n) = O(g(n))$ 且 $f(n) = \Omega(g(n))$

**Definition 1.2.1** (Asymptotic Relation)
For functions $f, g: \mathbb{N} \rightarrow \mathbb{R}^+$, we define:

1. $f(n) = O(g(n))$ if there exist constants $c > 0$ and $n_0 \in \mathbb{N}$ such that:
   $$\forall n \geq n_0: f(n) \leq c \cdot g(n)$$
2. $f(n) = \Omega(g(n))$ if there exist constants $c > 0$ and $n_0 \in \mathbb{N}$ such that:
   $$\forall n \geq n_0: f(n) \geq c \cdot g(n)$$
3. $f(n) = \Theta(g(n))$ if $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$

**定义 1.2.2** (渐进等价性 / Asymptotic Equivalence)
函数 $f$ 和 $g$ 渐进等价，记作 $f \sim g$，如果：
$$\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} = 1$$

**Definition 1.2.2** (Asymptotic Equivalence)
Functions $f$ and $g$ are asymptotically equivalent, denoted $f \sim g$, if:
$$\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} = 1$$

**定理 1.2.1** (渐进关系传递性 / Asymptotic Relation Transitivity)
渐进关系 $O$, $\Omega$, $\Theta$ 都具有传递性：

- 如果 $f = O(g)$ 且 $g = O(h)$，则 $f = O(h)$
- 如果 $f = \Omega(g)$ 且 $g = \Omega(h)$，则 $f = \Omega(h)$
- 如果 $f = \Theta(g)$ 且 $g = \Theta(h)$，则 $f = \Theta(h)$

**Theorem 1.2.1** (Asymptotic Relation Transitivity)
The asymptotic relations $O$, $\Omega$, $\Theta$ are all transitive:

- If $f = O(g)$ and $g = O(h)$, then $f = O(h)$
- If $f = \Omega(g)$ and $g = \Omega(h)$, then $f = \Omega(h)$
- If $f = \Theta(g)$ and $g = \Theta(h)$, then $f = \Theta(h)$

**证明** / **Proof**:
对于 $O$ 关系，存在常数 $c_1, c_2 > 0$ 和 $n_1, n_2 \in \mathbb{N}$ 使得：
$$\forall n \geq n_1: f(n) \leq c_1 \cdot g(n)$$
$$\forall n \geq n_2: g(n) \leq c_2 \cdot h(n)$$
取 $n_0 = \max(n_1, n_2)$，则：
$$\forall n \geq n_0: f(n) \leq c_1 \cdot g(n) \leq c_1 \cdot c_2 \cdot h(n)$$
因此 $f = O(h)$。其他关系类似。

For the $O$ relation, there exist constants $c_1, c_2 > 0$ and $n_1, n_2 \in \mathbb{N}$ such that:
$$\forall n \geq n_1: f(n) \leq c_1 \cdot g(n)$$
$$\forall n \geq n_2: g(n) \leq c_2 \cdot h(n)$$
Let $n_0 = \max(n_1, n_2)$, then:
$$\forall n \geq n_0: f(n) \leq c_1 \cdot g(n) \leq c_1 \cdot c_2 \cdot h(n)$$
Therefore $f = O(h)$. Other relations are similar.

### 1.3 摊还分析理论

**定义 1.3.1** (摊还成本 / Amortized Cost)
对于操作序列 $S = (op_1, op_2, \ldots, op_n)$，每个操作 $op_i$ 的实际成本为 $c_i$，摊还成本为 $a_i$，如果：
$$\sum_{i=1}^n a_i \geq \sum_{i=1}^n c_i$$

**Definition 1.3.1** (Amortized Cost)
For an operation sequence $S = (op_1, op_2, \ldots, op_n)$, where each operation $op_i$ has actual cost $c_i$ and amortized cost $a_i$, if:
$$\sum_{i=1}^n a_i \geq \sum_{i=1}^n c_i$$

**定义 1.3.2** (势能函数 / Potential Function)
势能函数 $\Phi: \mathcal{S} \rightarrow \mathbb{R}^+$ 将数据结构状态映射到非负实数，满足：
$$\Phi(s_0) = 0$$
其中 $s_0$ 是初始状态。

**Definition 1.3.2** (Potential Function)
A potential function $\Phi: \mathcal{S} \rightarrow \mathbb{R}^+$ maps data structure states to non-negative real numbers, satisfying:
$$\Phi(s_0) = 0$$
where $s_0$ is the initial state.

**定理 1.3.1** (势能方法摊还成本 / Potential Method Amortized Cost)
使用势能函数 $\Phi$，操作 $op_i$ 的摊还成本为：
$$a_i = c_i + \Phi(s_i) - \Phi(s_{i-1})$$

**Theorem 1.3.1** (Potential Method Amortized Cost)
Using potential function $\Phi$, the amortized cost of operation $op_i$ is:
$$a_i = c_i + \Phi(s_i) - \Phi(s_{i-1})$$

**证明** / **Proof**:
总摊还成本为：
$$\sum_{i=1}^n a_i = \sum_{i=1}^n (c_i + \Phi(s_i) - \Phi(s_{i-1})) = \sum_{i=1}^n c_i + \Phi(s_n) - \Phi(s_0)$$
由于 $\Phi(s_0) = 0$ 且 $\Phi(s_n) \geq 0$，因此：
$$\sum_{i=1}^n a_i \geq \sum_{i=1}^n c_i$$

The total amortized cost is:
$$\sum_{i=1}^n a_i = \sum_{i=1}^n (c_i + \Phi(s_i) - \Phi(s_{i-1})) = \sum_{i=1}^n c_i + \Phi(s_n) - \Phi(s_0)$$
Since $\Phi(s_0) = 0$ and $\Phi(s_n) \geq 0$, we have:
$$\sum_{i=1}^n a_i \geq \sum_{i=1}^n c_i$$

### 1.4 概率分析理论

**定义 1.4.1** (随机算法 / Randomized Algorithm)
随机算法是一个三元组 $(A, \mathcal{R}, P)$，其中：

- $A$ 是算法集合
- $\mathcal{R}$ 是随机数生成器
- $P$ 是概率分布函数

**Definition 1.4.1** (Randomized Algorithm)
A randomized algorithm is a 3-tuple $(A, \mathcal{R}, P)$, where:

- $A$ is the set of algorithms
- $\mathcal{R}$ is the random number generator
- $P$ is the probability distribution function

**定义 1.4.2** (期望复杂度 / Expected Complexity)
随机算法的期望复杂度是：
$$E[T(n)] = \sum_{r \in \mathcal{R}} P(r) \cdot T(n, r)$$
其中 $T(n, r)$ 是使用随机数 $r$ 时的运行时间。

**Definition 1.4.2** (Expected Complexity)
The expected complexity of a randomized algorithm is:
$$E[T(n)] = \sum_{r \in \mathcal{R}} P(r) \cdot T(n, r)$$
where $T(n, r)$ is the running time using random number $r$.

**定理 1.4.1** (马尔可夫不等式 / Markov's Inequality)
对于非负随机变量 $X$ 和任意 $a > 0$：
$$P(X \geq a) \leq \frac{E[X]}{a}$$

**Theorem 1.4.1** (Markov's Inequality)
For non-negative random variable $X$ and any $a > 0$:
$$P(X \geq a) \leq \frac{E[X]}{a}$$

**证明** / **Proof**:
$$E[X] = \int_0^{\infty} x f(x) dx \geq \int_a^{\infty} x f(x) dx \geq a \int_a^{\infty} f(x) dx = a \cdot P(X \geq a)$$
因此 $P(X \geq a) \leq \frac{E[X]}{a}$。

$$E[X] = \int_0^{\infty} x f(x) dx \geq \int_a^{\infty} x f(x) dx \geq a \int_a^{\infty} f(x) dx = a \cdot P(X \geq a)$$
Therefore $P(X \geq a) \leq \frac{E[X]}{a}$.

### 1.5 实验分析理论

**定义 1.5.1** (实验设计 / Experimental Design)
实验设计是一个四元组 $(H, M, P, E)$，其中：

- $H$ 是假设集合
- $M$ 是测量方法集合
- $P$ 是参数空间
- $E$ 是评估函数

**Definition 1.5.1** (Experimental Design)
An experimental design is a 4-tuple $(H, M, P, E)$, where:

- $H$ is the set of hypotheses
- $M$ is the set of measurement methods
- $P$ is the parameter space
- $E$ is the evaluation function

**定义 1.5.2** (统计显著性 / Statistical Significance)
实验结果具有统计显著性，如果 $p$-值小于显著性水平 $\alpha$：
$$p < \alpha$$

**Definition 1.5.2** (Statistical Significance)
An experimental result is statistically significant if the $p$-value is less than the significance level $\alpha$:
$$p < \alpha$$

**定理 1.5.1** (中心极限定理 / Central Limit Theorem)
对于独立同分布的随机变量 $X_1, X_2, \ldots, X_n$，如果 $E[X_i] = \mu$ 且 $Var(X_i) = \sigma^2$，则：
$$\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} N(0,1)$$
其中 $\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$。

**Theorem 1.5.1** (Central Limit Theorem)
For independent and identically distributed random variables $X_1, X_2, \ldots, X_n$, if $E[X_i] = \mu$ and $Var(X_i) = \sigma^2$, then:
$$\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} N(0,1)$$
where $\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$.

### 1.6 分析复杂度理论

**定义 1.6.1** (分析复杂度 / Analysis Complexity)
分析复杂度是分析算法所需的时间和空间资源：
$$C_{analysis}(A) = (T_{analysis}(A), S_{analysis}(A))$$

**Definition 1.6.1** (Analysis Complexity)
Analysis complexity is the time and space resources required to analyze an algorithm:
$$C_{analysis}(A) = (T_{analysis}(A), S_{analysis}(A))$$

**定义 1.6.2** (分析下界 / Analysis Lower Bound)
对于算法类 $\mathcal{A}$，分析下界是：
$$\Omega_{analysis}(\mathcal{A}) = \inf_{M} \sup_{A \in \mathcal{A}} C_M(A)$$
其中 $M$ 是所有可能的分析方法。

**Definition 1.6.2** (Analysis Lower Bound)
For algorithm class $\mathcal{A}$, the analysis lower bound is:
$$\Omega_{analysis}(\mathcal{A}) = \inf_{M} \sup_{A \in \mathcal{A}} C_M(A)$$
where $M$ is the set of all possible analysis methods.

**定理 1.6.1** (分析复杂度下界 / Analysis Complexity Lower Bound)
对于任意算法分析系统，分析复杂度下界是：
$$\Omega(\log n)$$
其中 $n$ 是输入规模。

**Theorem 1.6.1** (Analysis Complexity Lower Bound)
For any algorithm analysis system, the analysis complexity lower bound is:
$$\Omega(\log n)$$
where $n$ is the input size.

**证明** / **Proof**:
任何分析方法至少需要读取输入的一部分，因此需要至少 $\Omega(\log n)$ 的时间来识别输入规模。

Any analysis method must read at least part of the input, therefore requiring at least $\Omega(\log n)$ time to identify the input size.

## 2. 基本概念 / Basic Concepts

### 2.1 算法分析定义 / Definition of Algorithm Analysis

**定义 1.1** (算法分析 / Algorithm Analysis)
算法分析是评估算法性能的过程，主要关注算法在时间和空间消耗方面的表现，以及算法的正确性和可靠性。

**Definition 1.1** (Algorithm Analysis)
Algorithm analysis is the process of evaluating algorithm performance, primarily focusing on the algorithm's performance in terms of time and space consumption, as well as algorithm correctness and reliability.

### 2.2 分析维度 / Analysis Dimensions

1. **时间复杂度** / Time Complexity
   - 算法执行所需的计算步骤数
   - 与输入规模的关系

2. **空间复杂度** / Space Complexity
   - 算法执行所需的内存空间
   - 辅助空间的使用

3. **正确性** / Correctness
   - 算法是否产生正确的输出
   - 满足前置和后置条件

4. **稳定性** / Stability
   - 算法在不同输入下的表现
   - 数值稳定性

## 3. 渐进分析 / Asymptotic Analysis

### 3.1 渐进记号 / Asymptotic Notation

```rust
// 渐进分析工具实现
// Asymptotic analysis tools implementation

pub struct AsymptoticAnalyzer {
    name: String,
}

impl AsymptoticAnalyzer {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// Big-O 分析
    /// Big-O analysis
    pub fn big_o_analysis(&self, function_values: &[f64], input_sizes: &[usize]) -> String {
        if function_values.len() != input_sizes.len() || function_values.len() < 2 {
            return "Insufficient data for analysis".to_string();
        }
        
        let n = function_values.len();
        let mut growth_ratios = Vec::new();
        
        // 计算增长比率
        // Calculate growth ratios
        for i in 1..n {
            let size_ratio = input_sizes[i] as f64 / input_sizes[i-1] as f64;
            let value_ratio = function_values[i] / function_values[i-1];
            let growth_ratio = value_ratio / size_ratio;
            growth_ratios.push(growth_ratio);
        }
        
        let avg_growth = growth_ratios.iter().sum::<f64>() / growth_ratios.len() as f64;
        
        // 分类复杂度
        // Classify complexity
        if avg_growth < 1.2 {
            "O(1) - Constant".to_string()
        } else if avg_growth < 2.0 {
            "O(log n) - Logarithmic".to_string()
        } else if avg_growth < 3.0 {
            "O(n) - Linear".to_string()
        } else if avg_growth < 4.0 {
            "O(n log n) - Linearithmic".to_string()
        } else if avg_growth < 6.0 {
            "O(n²) - Quadratic".to_string()
        } else {
            "O(n^k) where k > 2 - Polynomial or higher".to_string()
        }
    }
    
    /// Theta 分析（紧确界）
    /// Theta analysis (tight bound)
    pub fn theta_analysis(&self, best_case: &[f64], worst_case: &[f64], input_sizes: &[usize]) -> String {
        let best_complexity = self.big_o_analysis(best_case, input_sizes);
        let worst_complexity = self.big_o_analysis(worst_case, input_sizes);
        
        if best_complexity == worst_complexity {
            format!("Θ({}) - Tight bound", best_complexity.split_whitespace().next().unwrap_or("unknown"))
        } else {
            format!("No tight bound: Best case {}, Worst case {}", best_complexity, worst_complexity)
        }
    }
    
    /// Omega 分析（下界）
    /// Omega analysis (lower bound)
    pub fn omega_analysis(&self, best_case: &[f64], input_sizes: &[usize]) -> String {
        let complexity = self.big_o_analysis(best_case, input_sizes);
        format!("Ω({}) - Lower bound", complexity.split_whitespace().next().unwrap_or("unknown"))
    }
}
```

### 3.2 递归关系分析 / Recurrence Relation Analysis

```rust
// 递归关系分析器
// Recurrence relation analyzer

pub struct RecurrenceAnalyzer {
    name: String,
}

impl RecurrenceAnalyzer {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// 主定理分析
    /// Master theorem analysis
    pub fn master_theorem(&self, a: f64, b: f64, d: f64) -> String {
        if b <= 1.0 || a <= 0.0 {
            return "Invalid parameters for master theorem".to_string();
        }
        
        let log_b_a = a.log(b);
        
        if d < log_b_a {
            format!("Case 1: T(n) = Θ(n^{:.2})", log_b_a)
        } else if d == log_b_a {
            format!("Case 2: T(n) = Θ(n^{:.2} log n)", d)
        } else {
            format!("Case 3: T(n) = Θ(n^{:.2})", d)
        }
    }
    
    /// 展开法分析
    /// Substitution method analysis
    pub fn substitution_method(&self, recurrence_type: &str, n: usize) -> f64 {
        match recurrence_type {
            "binary_search" => self.binary_search_recurrence(n),
            "merge_sort" => self.merge_sort_recurrence(n),
            "fibonacci" => self.fibonacci_recurrence(n),
            _ => 0.0,
        }
    }
    
    fn binary_search_recurrence(&self, n: usize) -> f64 {
        if n <= 1 {
            1.0
        } else {
            1.0 + self.binary_search_recurrence(n / 2)
        }
    }
    
    fn merge_sort_recurrence(&self, n: usize) -> f64 {
        if n <= 1 {
            1.0
        } else {
            2.0 * self.merge_sort_recurrence(n / 2) + n as f64
        }
    }
    
    fn fibonacci_recurrence(&self, n: usize) -> f64 {
        if n <= 1 {
            1.0
        } else {
            self.fibonacci_recurrence(n - 1) + self.fibonacci_recurrence(n - 2)
        }
    }
    
    /// 递归树分析
    /// Recursion tree analysis
    pub fn recursion_tree_analysis(&self, a: usize, b: usize, depth: usize) -> Vec<f64> {
        let mut tree_levels = Vec::new();
        
        for level in 0..depth {
            let nodes_at_level = a.pow(level as u32) as f64;
            let work_per_node = (1.0 / b as f64).powi(level as i32);
            let total_work = nodes_at_level * work_per_node;
            tree_levels.push(total_work);
        }
        
        tree_levels
    }
}
```

## 4. 摊还分析 / Amortized Analysis

### 4.1 聚合分析 / Aggregate Analysis

```rust
// 摊还分析工具
// Amortized analysis tools

pub struct AmortizedAnalyzer {
    name: String,
}

impl AmortizedAnalyzer {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// 动态数组的摊还分析
    /// Amortized analysis of dynamic arrays
    pub struct DynamicArray<T> {
        data: Vec<T>,
        size: usize,
        capacity: usize,
        total_operations: usize,
        total_cost: usize,
    }
    
    impl<T: Clone> DynamicArray<T> {
        pub fn new() -> Self {
            Self {
                data: Vec::new(),
                size: 0,
                capacity: 1,
                total_operations: 0,
                total_cost: 0,
            }
        }
        
        pub fn push(&mut self, item: T) {
            self.total_operations += 1;
            
            if self.size >= self.capacity {
                // 需要扩容
                // Need to resize
                self.resize();
                self.total_cost += self.size; // 复制成本
            }
            
            self.data.push(item);
            self.size += 1;
            self.total_cost += 1; // 插入成本
        }
        
        fn resize(&mut self) {
            self.capacity *= 2;
            // 在实际实现中，这里会重新分配内存
            // In actual implementation, memory would be reallocated here
        }
        
        pub fn amortized_cost(&self) -> f64 {
            if self.total_operations == 0 {
                0.0
            } else {
                self.total_cost as f64 / self.total_operations as f64
            }
        }
        
        pub fn size(&self) -> usize {
            self.size
        }
    }
    
    /// 二项堆的摊还分析
    /// Amortized analysis of binomial heaps
    pub struct BinomialHeap {
        min_node: Option<usize>,
        size: usize,
        potential: usize, // 势能函数
    }
    
    impl BinomialHeap {
        pub fn new() -> Self {
            Self {
                min_node: None,
                size: 0,
                potential: 0,
            }
        }
        
        pub fn insert(&mut self, value: i32) -> usize {
            self.size += 1;
            let old_potential = self.potential;
            
            // 更新势能（二项堆中树的数量）
            // Update potential (number of trees in binomial heap)
            self.potential = self.count_trees();
            
            let actual_cost = 1; // 实际插入成本
            let potential_change = self.potential as i32 - old_potential as i32;
            let amortized_cost = actual_cost + potential_change;
            
            amortized_cost as usize
        }
        
        pub fn extract_min(&mut self) -> Option<i32> {
            if self.size == 0 {
                return None;
            }
            
            self.size -= 1;
            let old_potential = self.potential;
            
            // 模拟提取最小值操作
            // Simulate extract minimum operation
            self.potential = self.count_trees();
            
            let actual_cost = self.potential + 1; // 实际提取成本
            let potential_change = self.potential as i32 - old_potential as i32;
            let _amortized_cost = actual_cost as i32 + potential_change;
            
            Some(0) // 简化返回
        }
        
        fn count_trees(&self) -> usize {
            // 计算二项堆中的树数量（简化版本）
            // Count number of trees in binomial heap (simplified)
            self.size.count_ones() as usize
        }
    }
}
```

### 4.2 银行家方法 / Banker's Method

```rust
// 银行家方法分析
// Banker's method analysis

pub struct BankersMethodAnalyzer {
    name: String,
}

impl BankersMethodAnalyzer {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// 栈的摊还分析（银行家方法）
    /// Amortized analysis of stack (banker's method)
    pub struct AmortizedStack<T> {
        data: Vec<T>,
        credits: usize, // 信用点数
    }
    
    impl<T> AmortizedStack<T> {
        pub fn new() -> Self {
            Self {
                data: Vec::new(),
                credits: 0,
            }
        }
        
        pub fn push(&mut self, item: T) -> usize {
            self.data.push(item);
            self.credits += 2; // 为每个元素分配2个信用点
            1 // 摊还成本为1
        }
        
        pub fn pop(&mut self) -> Option<T> {
            if let Some(item) = self.data.pop() {
                self.credits = self.credits.saturating_sub(2); // 使用2个信用点
                Some(item)
            } else {
                None
            }
        }
        
        pub fn multipop(&mut self, k: usize) -> Vec<T> {
            let mut result = Vec::new();
            let actual_pops = std::cmp::min(k, self.data.len());
            
            for _ in 0..actual_pops {
                if let Some(item) = self.data.pop() {
                    result.push(item);
                    self.credits = self.credits.saturating_sub(2);
                }
            }
            
            result
        }
        
        pub fn size(&self) -> usize {
            self.data.len()
        }
        
        pub fn credits(&self) -> usize {
            self.credits
        }
    }
    
    /// 二进制计数器的摊还分析
    /// Amortized analysis of binary counter
    pub struct BinaryCounter {
        bits: Vec<bool>,
        credits: Vec<usize>, // 每个位的信用点
    }
    
    impl BinaryCounter {
        pub fn new(size: usize) -> Self {
            Self {
                bits: vec![false; size],
                credits: vec![0; size],
            }
        }
        
        pub fn increment(&mut self) -> usize {
            let mut i = 0;
            let mut amortized_cost = 0;
            
            // 找到第一个0位
            // Find first 0 bit
            while i < self.bits.len() && self.bits[i] {
                self.bits[i] = false;
                // 使用信用点支付翻转成本
                // Use credits to pay for flip cost
                if self.credits[i] > 0 {
                    self.credits[i] -= 1;
                } else {
                    amortized_cost += 1;
                }
                i += 1;
            }
            
            // 设置第一个0位为1
            // Set first 0 bit to 1
            if i < self.bits.len() {
                self.bits[i] = true;
                self.credits[i] += 1; // 为这一位分配信用点
                amortized_cost += 2; // 实际成本1 + 信用点1
            }
            
            amortized_cost
        }
        
        pub fn value(&self) -> usize {
            let mut result = 0;
            for (i, &bit) in self.bits.iter().enumerate() {
                if bit {
                    result += 1 << i;
                }
            }
            result
        }
    }
}
```

## 5. 概率分析 / Probabilistic Analysis

### 5.1 随机算法分析 / Randomized Algorithm Analysis

```rust
// 概率分析工具
// Probabilistic analysis tools

use rand::{Rng, thread_rng};

pub struct ProbabilisticAnalyzer {
    name: String,
}

impl ProbabilisticAnalyzer {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// 快速排序的概率分析
    /// Probabilistic analysis of quicksort
    pub fn analyze_randomized_quicksort(&self, n: usize, trials: usize) -> (f64, f64, f64) {
        let mut times = Vec::new();
        
        for _ in 0..trials {
            let mut arr: Vec<i32> = (0..n as i32).collect();
            self.shuffle(&mut arr);
            
            let start = std::time::Instant::now();
            self.randomized_quicksort(&mut arr);
            let duration = start.elapsed().as_nanos() as f64;
            times.push(duration);
        }
        
        let mean = times.iter().sum::<f64>() / times.len() as f64;
        let variance = times.iter()
            .map(|&x| (x - mean).powi(2))
            .sum::<f64>() / times.len() as f64;
        let std_dev = variance.sqrt();
        
        (mean, variance, std_dev)
    }
    
    fn randomized_quicksort(&self, arr: &mut [i32]) {
        if arr.len() <= 1 {
            return;
        }
        
        // 随机选择pivot
        // Randomly select pivot
        let mut rng = thread_rng();
        let pivot_index = rng.gen_range(0..arr.len());
        arr.swap(0, pivot_index);
        
        let pivot = self.partition(arr);
        let (left, right) = arr.split_at_mut(pivot);
        
        self.randomized_quicksort(left);
        self.randomized_quicksort(&mut right[1..]);
    }
    
    fn partition(&self, arr: &mut [i32]) -> usize {
        let pivot = arr[0];
        let mut i = 1;
        
        for j in 1..arr.len() {
            if arr[j] <= pivot {
                arr.swap(i, j);
                i += 1;
            }
        }
        
        arr.swap(0, i - 1);
        i - 1
    }
    
    fn shuffle(&self, arr: &mut [i32]) {
        let mut rng = thread_rng();
        for i in (1..arr.len()).rev() {
            let j = rng.gen_range(0..=i);
            arr.swap(i, j);
        }
    }
    
    /// 期望值分析
    /// Expected value analysis
    pub fn expected_value_analysis(&self, outcomes: &[f64], probabilities: &[f64]) -> f64 {
        if outcomes.len() != probabilities.len() {
            return 0.0;
        }
        
        outcomes.iter()
            .zip(probabilities.iter())
            .map(|(&outcome, &prob)| outcome * prob)
            .sum()
    }
    
    /// 方差分析
    /// Variance analysis
    pub fn variance_analysis(&self, outcomes: &[f64], probabilities: &[f64]) -> f64 {
        let expected_value = self.expected_value_analysis(outcomes, probabilities);
        
        outcomes.iter()
            .zip(probabilities.iter())
            .map(|(&outcome, &prob)| (outcome - expected_value).powi(2) * prob)
            .sum()
    }
    
    /// 尾界分析（Chernoff界）
    /// Tail bound analysis (Chernoff bound)
    pub fn chernoff_bound(&self, n: usize, p: f64, delta: f64) -> f64 {
        let mu = n as f64 * p;
        if delta <= 0.0 {
            return 1.0;
        }
        
        // Chernoff界: P(X > (1+δ)μ) ≤ e^(-δ²μ/3)
        // Chernoff bound: P(X > (1+δ)μ) ≤ e^(-δ²μ/3)
        (-delta * delta * mu / 3.0).exp()
    }
}
```

### 5.2 马尔可夫链分析 / Markov Chain Analysis

```rust
// 马尔可夫链分析
// Markov chain analysis

pub struct MarkovChainAnalyzer {
    name: String,
}

impl MarkovChainAnalyzer {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// 马尔可夫链模拟
    /// Markov chain simulation
    pub struct MarkovChain {
        states: Vec<String>,
        transition_matrix: Vec<Vec<f64>>,
        current_state: usize,
    }
    
    impl MarkovChain {
        pub fn new(states: Vec<String>, transition_matrix: Vec<Vec<f64>>) -> Self {
            Self {
                states,
                transition_matrix,
                current_state: 0,
            }
        }
        
        pub fn next_state(&mut self) -> &str {
            let mut rng = thread_rng();
            let random_value: f64 = rng.gen();
            
            let mut cumulative_prob = 0.0;
            for (next_state, &prob) in self.transition_matrix[self.current_state].iter().enumerate() {
                cumulative_prob += prob;
                if random_value <= cumulative_prob {
                    self.current_state = next_state;
                    break;
                }
            }
            
            &self.states[self.current_state]
        }
        
        pub fn simulate_steps(&mut self, steps: usize) -> Vec<String> {
            let mut path = Vec::new();
            
            for _ in 0..steps {
                path.push(self.next_state().to_string());
            }
            
            path
        }
        
        pub fn steady_state_distribution(&self, iterations: usize) -> Vec<f64> {
            let n = self.states.len();
            let mut distribution = vec![1.0 / n as f64; n];
            
            for _ in 0..iterations {
                let mut new_distribution = vec![0.0; n];
                
                for i in 0..n {
                    for j in 0..n {
                        new_distribution[j] += distribution[i] * self.transition_matrix[i][j];
                    }
                }
                
                distribution = new_distribution;
            }
            
            distribution
        }
    }
    
    /// 随机游走分析
    /// Random walk analysis
    pub fn analyze_random_walk(&self, steps: usize, start_position: i32) -> (f64, f64) {
        let mut positions = Vec::new();
        let mut current_position = start_position;
        
        let mut rng = thread_rng();
        
        for _ in 0..steps {
            if rng.gen::<f64>() < 0.5 {
                current_position += 1;
            } else {
                current_position -= 1;
            }
            positions.push(current_position);
        }
        
        let mean_position = positions.iter().sum::<i32>() as f64 / positions.len() as f64;
        let variance = positions.iter()
            .map(|&pos| (pos as f64 - mean_position).powi(2))
            .sum::<f64>() / positions.len() as f64;
        
        (mean_position, variance)
    }
}
```

## 6. 实验分析 / Experimental Analysis

### 6.1 性能测试框架 / Performance Testing Framework

```rust
// 性能测试框架
// Performance testing framework

use std::time::{Duration, Instant};

pub struct PerformanceTester {
    name: String,
}

impl PerformanceTester {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// 基准测试
    /// Benchmark testing
    pub fn benchmark<F, T>(&self, name: &str, setup: F, iterations: usize) -> BenchmarkResult
    where F: Fn() -> T {
        let mut times = Vec::new();
        
        for _ in 0..iterations {
            let start = Instant::now();
            let _result = setup();
            let duration = start.elapsed();
            times.push(duration);
        }
        
        BenchmarkResult::new(name.to_string(), times)
    }
    
    /// 可扩展性测试
    /// Scalability testing
    pub fn scalability_test<F, T>(&self, algorithm: F, input_sizes: &[usize]) -> ScalabilityResult
    where F: Fn(usize) -> T {
        let mut results = Vec::new();
        
        for &size in input_sizes {
            let start = Instant::now();
            let _result = algorithm(size);
            let duration = start.elapsed();
            results.push((size, duration));
        }
        
        ScalabilityResult::new(results)
    }
    
    /// 内存使用分析
    /// Memory usage analysis
    pub fn memory_analysis<F, T>(&self, algorithm: F) -> MemoryResult
    where F: FnOnce() -> T {
        let start_memory = self.get_memory_usage();
        let _result = algorithm();
        let end_memory = self.get_memory_usage();
        
        MemoryResult {
            peak_usage: end_memory - start_memory,
            allocations: 0, // 简化版本
        }
    }
    
    fn get_memory_usage(&self) -> usize {
        // 简化的内存使用获取
        // Simplified memory usage retrieval
        0
    }
}

pub struct BenchmarkResult {
    name: String,
    times: Vec<Duration>,
}

impl BenchmarkResult {
    pub fn new(name: String, times: Vec<Duration>) -> Self {
        Self { name, times }
    }
    
    pub fn mean(&self) -> Duration {
        let total: Duration = self.times.iter().sum();
        total / self.times.len() as u32
    }
    
    pub fn median(&self) -> Duration {
        let mut sorted_times = self.times.clone();
        sorted_times.sort();
        sorted_times[sorted_times.len() / 2]
    }
    
    pub fn min(&self) -> Duration {
        *self.times.iter().min().unwrap()
    }
    
    pub fn max(&self) -> Duration {
        *self.times.iter().max().unwrap()
    }
    
    pub fn standard_deviation(&self) -> f64 {
        let mean = self.mean().as_nanos() as f64;
        let variance = self.times.iter()
            .map(|t| (t.as_nanos() as f64 - mean).powi(2))
            .sum::<f64>() / self.times.len() as f64;
        variance.sqrt()
    }
}

pub struct ScalabilityResult {
    data_points: Vec<(usize, Duration)>,
}

impl ScalabilityResult {
    pub fn new(data_points: Vec<(usize, Duration)>) -> Self {
        Self { data_points }
    }
    
    pub fn growth_rate(&self) -> f64 {
        if self.data_points.len() < 2 {
            return 0.0;
        }
        
        let (size1, time1) = self.data_points[0];
        let (size2, time2) = self.data_points[self.data_points.len() - 1];
        
        let size_ratio = size2 as f64 / size1 as f64;
        let time_ratio = time2.as_nanos() as f64 / time1.as_nanos() as f64;
        
        time_ratio.log(size_ratio)
    }
    
    pub fn efficiency(&self) -> Vec<f64> {
        self.data_points.iter()
            .map(|(size, time)| *size as f64 / time.as_nanos() as f64)
            .collect()
    }
}

pub struct MemoryResult {
    peak_usage: usize,
    allocations: usize,
}

impl MemoryResult {
    pub fn peak_usage(&self) -> usize {
        self.peak_usage
    }
    
    pub fn allocations(&self) -> usize {
        self.allocations
    }
}
```

## 7. 应用案例 / Application Cases

### 7.1 案例1：排序算法比较分析 / Case 1: Comparative Analysis of Sorting Algorithms

```rust
// 排序算法比较分析
// Comparative analysis of sorting algorithms

pub struct SortingAnalyzer {
    name: String,
}

impl SortingAnalyzer {
    pub fn new(name: String) -> Self {
        Self { name }
    }
    
    /// 排序算法比较
    /// Sorting algorithm comparison
    pub fn compare_sorting_algorithms(&self, input_sizes: &[usize]) -> ComparisonResult {
        let mut results = ComparisonResult::new();
        
        for &size in input_sizes {
            // 生成测试数据
            // Generate test data
            let random_data: Vec<i32> = (0..size).map(|_| rand::random()).collect();
            let sorted_data: Vec<i32> = (0..size as i32).collect();
            let reverse_sorted_data: Vec<i32> = (0..size as i32).rev().collect();
            
            // 测试不同算法
            // Test different algorithms
            results.add_result("QuickSort", "Random", 
                self.test_quicksort(random_data.clone()));
            results.add_result("QuickSort", "Sorted", 
                self.test_quicksort(sorted_data.clone()));
            results.add_result("QuickSort", "Reverse", 
                self.test_quicksort(reverse_sorted_data.clone()));
            
            results.add_result("MergeSort", "Random", 
                self.test_mergesort(random_data.clone()));
            results.add_result("MergeSort", "Sorted", 
                self.test_mergesort(sorted_data.clone()));
            results.add_result("MergeSort", "Reverse", 
                self.test_mergesort(reverse_sorted_data.clone()));
            
            results.add_result("HeapSort", "Random", 
                self.test_heapsort(random_data.clone()));
            results.add_result("HeapSort", "Sorted", 
                self.test_heapsort(sorted_data.clone()));
            results.add_result("HeapSort", "Reverse", 
                self.test_heapsort(reverse_sorted_data));
        }
        
        results
    }
    
    fn test_quicksort(&self, mut data: Vec<i32>) -> Duration {
        let start = Instant::now();
        self.quicksort(&mut data);
        start.elapsed()
    }
    
    fn test_mergesort(&self, mut data: Vec<i32>) -> Duration {
        let start = Instant::now();
        self.mergesort(&mut data);
        start.elapsed()
    }
    
    fn test_heapsort(&self, mut data: Vec<i32>) -> Duration {
        let start = Instant::now();
        self.heapsort(&mut data);
        start.elapsed()
    }
    
    fn quicksort(&self, arr: &mut [i32]) {
        if arr.len() <= 1 {
            return;
        }
        
        let pivot = self.partition(arr);
        let (left, right) = arr.split_at_mut(pivot);
        
        self.quicksort(left);
        self.quicksort(&mut right[1..]);
    }
    
    fn mergesort(&self, arr: &mut [i32]) {
        if arr.len() <= 1 {
            return;
        }
        
        let mid = arr.len() / 2;
        let (left, right) = arr.split_at_mut(mid);
        
        self.mergesort(left);
        self.mergesort(right);
        
        self.merge(arr, mid);
    }
    
    fn heapsort(&self, arr: &mut [i32]) {
        let n = arr.len();
        
        // 建堆
        // Build heap
        for i in (0..n/2).rev() {
            self.heapify(arr, n, i);
        }
        
        // 排序
        // Sort
        for i in (1..n).rev() {
            arr.swap(0, i);
            self.heapify(arr, i, 0);
        }
    }
    
    fn partition(&self, arr: &mut [i32]) -> usize {
        let pivot = arr[arr.len() - 1];
        let mut i = 0;
        
        for j in 0..arr.len() - 1 {
            if arr[j] <= pivot {
                arr.swap(i, j);
                i += 1;
            }
        }
        
        arr.swap(i, arr.len() - 1);
        i
    }
    
    fn merge(&self, arr: &mut [i32], mid: usize) {
        let left = arr[..mid].to_vec();
        let right = arr[mid..].to_vec();
        
        let mut i = 0;
        let mut j = 0;
        let mut k = 0;
        
        while i < left.len() && j < right.len() {
            if left[i] <= right[j] {
                arr[k] = left[i];
                i += 1;
            } else {
                arr[k] = right[j];
                j += 1;
            }
            k += 1;
        }
        
        while i < left.len() {
            arr[k] = left[i];
            i += 1;
            k += 1;
        }
        
        while j < right.len() {
            arr[k] = right[j];
            j += 1;
            k += 1;
        }
    }
    
    fn heapify(&self, arr: &mut [i32], n: usize, i: usize) {
        let mut largest = i;
        let left = 2 * i + 1;
        let right = 2 * i + 2;
        
        if left < n && arr[left] > arr[largest] {
            largest = left;
        }
        
        if right < n && arr[right] > arr[largest] {
            largest = right;
        }
        
        if largest != i {
            arr.swap(i, largest);
            self.heapify(arr, n, largest);
        }
    }
}

pub struct ComparisonResult {
    results: std::collections::HashMap<String, Duration>,
}

impl ComparisonResult {
    pub fn new() -> Self {
        Self {
            results: std::collections::HashMap::new(),
        }
    }
    
    pub fn add_result(&mut self, algorithm: &str, input_type: &str, duration: Duration) {
        let key = format!("{}_{}", algorithm, input_type);
        self.results.insert(key, duration);
    }
    
    pub fn get_result(&self, algorithm: &str, input_type: &str) -> Option<&Duration> {
        let key = format!("{}_{}", algorithm, input_type);
        self.results.get(&key)
    }
    
    pub fn print_summary(&self) {
        println!("Algorithm Performance Comparison:");
        println!("================================");
        
        for (key, duration) in &self.results {
            println!("{}: {:?}", key, duration);
        }
    }
}
```

## 8. 总结 / Summary

算法分析理论为我们提供了评估和比较算法性能的强大工具。通过渐进分析、摊还分析、概率分析和实验分析等方法，我们可以深入理解算法的行为特征和性能表现。

Algorithm analysis theory provides us with powerful tools for evaluating and comparing algorithm performance. Through asymptotic analysis, amortized analysis, probabilistic analysis, and experimental analysis, we can deeply understand the behavioral characteristics and performance of algorithms.

### 8.1 关键要点 / Key Points

1. **多维度分析** / Multi-dimensional Analysis
   - 时间复杂度、空间复杂度、正确性
   - 理论分析与实验验证相结合

2. **渐进分析** / Asymptotic Analysis
   - Big-O、Theta、Omega记号
   - 递归关系的求解

3. **摊还分析** / Amortized Analysis
   - 聚合分析、银行家方法、势能方法
   - 动态数据结构的性能保证

4. **概率分析** / Probabilistic Analysis
   - 随机算法的期望性能
   - 尾界分析和集中不等式

---

**参考文献 / References**:

1. Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to algorithms. MIT press.
2. Knuth, D. E. (1997). The art of computer programming. Addison-Wesley.
3. Sedgewick, R., & Wayne, K. (2011). Algorithms. Addison-Wesley Professional.
4. Kleinberg, J., & Tardos, E. (2005). Algorithm design. Pearson Education India.
5. Motwani, R., & Raghavan, P. (1995). Randomized algorithms. Cambridge university press.
