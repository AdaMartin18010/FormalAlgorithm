# 02-并行算法理论

## 目录 (Table of Contents)

- [02-并行算法理论](#02-并行算法理论)
  - [目录 (Table of Contents)](#目录-table-of-contents)
  - [1. 基本概念 (Basic Concepts)](#1-基本概念-basic-concepts)
    - [1.1 并行性定义 (Definition of Parallelism)](#11-并行性定义-definition-of-parallelism)
    - [1.2 并行算法分类 (Classification of Parallel Algorithms)](#12-并行算法分类-classification-of-parallel-algorithms)
    - [1.3 并行性能度量 (Parallel Performance Metrics)](#13-并行性能度量-parallel-performance-metrics)
  - [2. 并行计算模型 (Parallel Computation Models)](#2-并行计算模型-parallel-computation-models)
    - [2.1 PRAM模型 (PRAM Model)](#21-pram模型-pram-model)
    - [2.2 网络模型 (Network Models)](#22-网络模型-network-models)
    - [2.3 分布式内存模型 (Distributed Memory Models)](#23-分布式内存模型-distributed-memory-models)
  - [3. 并行算法设计 (Parallel Algorithm Design)](#3-并行算法设计-parallel-algorithm-design)
    - [3.1 分治并行 (Divide-and-Conquer Parallelism)](#31-分治并行-divide-and-conquer-parallelism)
    - [3.2 流水线并行 (Pipeline Parallelism)](#32-流水线并行-pipeline-parallelism)
    - [3.3 数据并行 (Data Parallelism)](#33-数据并行-data-parallelism)
  - [4. 并行复杂度理论 (Parallel Complexity Theory)](#4-并行复杂度理论-parallel-complexity-theory)
    - [4.1 NC类 (NC Class)](#41-nc类-nc-class)
    - [4.2 P-完全性 (P-Completeness)](#42-p-完全性-p-completeness)
    - [4.3 并行下界 (Parallel Lower Bounds)](#43-并行下界-parallel-lower-bounds)
  - [5. 并行排序算法 (Parallel Sorting Algorithms)](#5-并行排序算法-parallel-sorting-algorithms)
    - [5.1 并行归并排序 (Parallel Merge Sort)](#51-并行归并排序-parallel-merge-sort)
    - [5.2 并行快速排序 (Parallel Quick Sort)](#52-并行快速排序-parallel-quick-sort)
    - [5.3 并行基数排序 (Parallel Radix Sort)](#53-并行基数排序-parallel-radix-sort)
  - [6. 并行图算法 (Parallel Graph Algorithms)](#6-并行图算法-parallel-graph-algorithms)
    - [6.1 并行BFS (Parallel BFS)](#61-并行bfs-parallel-bfs)
    - [6.2 并行最短路径 (Parallel Shortest Paths)](#62-并行最短路径-parallel-shortest-paths)
    - [6.3 并行连通分量 (Parallel Connected Components)](#63-并行连通分量-parallel-connected-components)
  - [7. 实现示例 (Implementation Examples)](#7-实现示例-implementation-examples)
    - [7.1 并行归并排序实现 (Parallel Merge Sort Implementation)](#71-并行归并排序实现-parallel-merge-sort-implementation)
    - [7.2 并行BFS实现 (Parallel BFS Implementation)](#72-并行bfs实现-parallel-bfs-implementation)
    - [7.3 并行图算法框架 (Parallel Graph Algorithm Framework)](#73-并行图算法框架-parallel-graph-algorithm-framework)
    - [7.4 并行性能分析 (Parallel Performance Analysis)](#74-并行性能分析-parallel-performance-analysis)
  - [8. 参考文献 (References)](#8-参考文献-references)

---

## 1. 基本概念 (Basic Concepts)

### 1.1 并行性定义 (Definition of Parallelism)

**定义 1.1.1** (并行性 / Parallelism)
并行性是指同时执行多个计算任务的能力。

**Definition 1.1.1** (Parallelism)
Parallelism is the ability to execute multiple computational tasks simultaneously.

**形式化表示 (Formal Representation):**
$$P(n) = \frac{T_1(n)}{T_p(n)}$$

其中 (where):

- $P(n)$ 是并行加速比 (is the parallel speedup)
- $T_1(n)$ 是串行时间 (is the serial time)
- $T_p(n)$ 是并行时间 (is the parallel time)

### 1.2 并行算法分类 (Classification of Parallel Algorithms)

**定义 1.2.1** (数据并行 / Data Parallelism)
数据并行是指对不同的数据元素同时执行相同的操作。

**Definition 1.2.1** (Data Parallelism)
Data parallelism is the simultaneous execution of the same operation on different data elements.

**定义 1.2.2** (任务并行 / Task Parallelism)
任务并行是指同时执行不同的任务。

**Definition 1.2.2** (Task Parallelism)
Task parallelism is the simultaneous execution of different tasks.

**定义 1.2.3** (流水线并行 / Pipeline Parallelism)
流水线并行是指将计算分解为多个阶段，不同阶段同时处理不同的数据。

**Definition 1.2.3** (Pipeline Parallelism)
Pipeline parallelism is the decomposition of computation into multiple stages, with different stages processing different data simultaneously.

### 1.3 并行性能度量 (Parallel Performance Metrics)

**定义 1.3.1** (加速比 / Speedup)
$$S(p) = \frac{T_1}{T_p}$$

其中 $T_1$ 是串行时间，$T_p$ 是使用 $p$ 个处理器的并行时间。

**Definition 1.3.1** (Speedup)
$$S(p) = \frac{T_1}{T_p}$$

where $T_1$ is the serial time and $T_p$ is the parallel time using $p$ processors.

**定义 1.3.2** (效率 / Efficiency)
$$E(p) = \frac{S(p)}{p} = \frac{T_1}{p \cdot T_p}$$

**Definition 1.3.2** (Efficiency)
$$E(p) = \frac{S(p)}{p} = \frac{T_1}{p \cdot T_p}$$

**定义 1.3.3** (可扩展性 / Scalability)
可扩展性是指算法在增加处理器数量时保持效率的能力。

**Definition 1.3.3** (Scalability)
Scalability is the ability of an algorithm to maintain efficiency when increasing the number of processors.

---

## 2. 并行计算模型 (Parallel Computation Models)

### 2.1 PRAM模型 (PRAM Model)

**定义 2.1.1** (PRAM / Parallel Random Access Machine)
PRAM是一个共享内存的并行计算模型，包含多个处理器和一个共享内存。

**Definition 2.1.1** (PRAM)
PRAM is a shared-memory parallel computation model with multiple processors and a shared memory.

**PRAM变种 (PRAM Variants):**

1. **EREW-PRAM**: Exclusive Read, Exclusive Write
2. **CREW-PRAM**: Concurrent Read, Exclusive Write
3. **CRCW-PRAM**: Concurrent Read, Concurrent Write

**定理 2.1.1** (PRAM层次定理 / PRAM Hierarchy Theorem)
对于任意函数 $f$，存在常数 $c$ 使得：
$$T_{CRCW}(f) \leq T_{CREW}(f) \leq T_{EREW}(f) \leq c \cdot T_{CRCW}(f) \cdot \log p$$

**Theorem 2.1.1** (PRAM Hierarchy Theorem)
For any function $f$, there exists a constant $c$ such that:
$$T_{CRCW}(f) \leq T_{CREW}(f) \leq T_{EREW}(f) \leq c \cdot T_{CRCW}(f) \cdot \log p$$

### 2.2 网络模型 (Network Models)

**定义 2.2.1** (网格网络 / Mesh Network)
网格网络是一个二维阵列，每个节点连接到其四个邻居。

**Definition 2.2.1** (Mesh Network)
A mesh network is a two-dimensional array where each node is connected to its four neighbors.

**定义 2.2.2** (超立方体网络 / Hypercube Network)
超立方体网络是一个 $d$ 维立方体，每个节点连接到 $d$ 个邻居。

**Definition 2.2.2** (Hypercube Network)
A hypercube network is a $d$-dimensional cube where each node is connected to $d$ neighbors.

### 2.3 分布式内存模型 (Distributed Memory Models)

**定义 2.3.1** (消息传递模型 / Message Passing Model)
消息传递模型中的处理器通过发送和接收消息进行通信。

**Definition 2.3.1** (Message Passing Model)
In the message passing model, processors communicate by sending and receiving messages.

**定义 2.3.2** (BSP模型 / Bulk Synchronous Parallel Model)
BSP模型将计算分为超步，每个超步包含计算、通信和同步阶段。

**Definition 2.3.2** (BSP Model)
The BSP model divides computation into supersteps, each containing computation, communication, and synchronization phases.

---

## 3. 并行算法设计 (Parallel Algorithm Design)

### 3.1 分治并行 (Divide-and-Conquer Parallelism)

**定义 3.1.1** (并行分治 / Parallel Divide-and-Conquer)
并行分治将问题分解为独立的子问题，并行求解后合并结果。

**Definition 3.1.1** (Parallel Divide-and-Conquer)
Parallel divide-and-conquer decomposes a problem into independent subproblems, solves them in parallel, and combines the results.

**算法描述 (Algorithm Description):**

```text
ParallelDivideAndConquer(P, n):
    if n ≤ threshold:
        return SequentialSolve(P)
    
    P1, P2, ..., Pk = Divide(P)
    results = ParallelFor(i = 1 to k):
        ParallelDivideAndConquer(Pi, n/k)
    
    return Combine(results)
```

### 3.2 流水线并行 (Pipeline Parallelism)

**定义 3.2.1** (并行流水线 / Parallel Pipeline)
并行流水线将计算分解为多个阶段，不同阶段同时处理不同的数据。

**Definition 3.2.1** (Parallel Pipeline)
A parallel pipeline decomposes computation into multiple stages, with different stages processing different data simultaneously.

**定理 3.2.1** (流水线加速比 / Pipeline Speedup)
对于 $k$ 阶段的流水线：
$$S(k) = \frac{k \cdot T}{T + (k-1) \cdot \tau}$$

其中 $T$ 是每个阶段的时间，$\tau$ 是流水线延迟。

**Theorem 3.2.1** (Pipeline Speedup)
For a $k$-stage pipeline:
$$S(k) = \frac{k \cdot T}{T + (k-1) \cdot \tau}$$

where $T$ is the time per stage and $\tau$ is the pipeline latency.

### 3.3 数据并行 (Data Parallelism)

**定义 3.3.1** (并行映射 / Parallel Map)
并行映射对数组的每个元素应用相同的函数。

**Definition 3.3.1** (Parallel Map)
Parallel map applies the same function to each element of an array.

**算法描述 (Algorithm Description):**

```text
ParallelMap(f, A, p):
    chunk_size = n / p
    results = ParallelFor(i = 0 to p-1):
        start = i * chunk_size
        end = min((i+1) * chunk_size, n)
        for j = start to end-1:
            B[j] = f(A[j])
    return B
```

---

## 4. 并行复杂度理论 (Parallel Complexity Theory)

### 4.1 NC类 (NC Class)

**定义 4.1.1** (NC类 / NC Class)
NC是可以在多对数时间内用多项式数量处理器解决的问题类：
$$\text{NC} = \bigcup_{k \geq 1} \text{NC}^k$$

其中 $\text{NC}^k$ 是可以在 $O(\log^k n)$ 时间内用 $O(n^{O(1)})$ 个处理器解决的问题。

**Definition 4.1.1** (NC Class)
NC is the class of problems that can be solved in polylogarithmic time using a polynomial number of processors:
$$\text{NC} = \bigcup_{k \geq 1} \text{NC}^k$$

where $\text{NC}^k$ is the class of problems that can be solved in $O(\log^k n)$ time using $O(n^{O(1)})$ processors.

### 4.2 P-完全性 (P-Completeness)

**定义 4.2.1** (P-完全问题 / P-Complete Problems)
P-完全问题是P类中最难的问题，如果它们可以在NC中解决，则P = NC。

**Definition 4.2.1** (P-Complete Problems)
P-complete problems are the hardest problems in P. If they can be solved in NC, then P = NC.

**定理 4.2.1** (P-完全性定理 / P-Completeness Theorem)
电路值问题是P-完全的。

**Theorem 4.2.1** (P-Completeness Theorem)
The circuit value problem is P-complete.

### 4.3 并行下界 (Parallel Lower Bounds)

**定义 4.3.1** (工作下界 / Work Lower Bounds)
对于某些问题，任何并行算法都必须执行一定数量的工作。

**Definition 4.3.1** (Work Lower Bounds)
For certain problems, any parallel algorithm must perform a certain amount of work.

**定理 4.3.1** (并行排序下界 / Parallel Sorting Lower Bound)
任何并行比较排序算法都需要 $\Omega(n \log n)$ 的总工作。

**Theorem 4.3.1** (Parallel Sorting Lower Bound)
Any parallel comparison-based sorting algorithm requires $\Omega(n \log n)$ total work.

---

## 5. 并行排序算法 (Parallel Sorting Algorithms)

### 5.1 并行归并排序 (Parallel Merge Sort)

**定义 5.1.1** (并行归并排序 / Parallel Merge Sort)
并行归并排序使用分治策略并行排序。

**Definition 5.1.1** (Parallel Merge Sort)
Parallel merge sort uses divide-and-conquer strategy to sort in parallel.

**算法描述 (Algorithm Description):**

```text
ParallelMergeSort(A, p):
    if p == 1:
        return SequentialMergeSort(A)
    
    mid = n / 2
    left, right = ParallelFor(i = 0 to 1):
        if i == 0:
            ParallelMergeSort(A[0:mid], p/2)
        else:
            ParallelMergeSort(A[mid:n], p/2)
    
    return ParallelMerge(left, right)
```

**定理 5.1.1** (并行归并排序复杂度 / Parallel Merge Sort Complexity)
并行归并排序的时间复杂度为 $O(\frac{n \log n}{p} + \log n)$。

**Theorem 5.1.1** (Parallel Merge Sort Complexity)
The time complexity of parallel merge sort is $O(\frac{n \log n}{p} + \log n)$.

### 5.2 并行快速排序 (Parallel Quick Sort)

**定义 5.2.1** (并行快速排序 / Parallel Quick Sort)
并行快速排序并行执行分区操作。

**Definition 5.2.1** (Parallel Quick Sort)
Parallel quick sort performs partitioning operations in parallel.

**算法描述 (Algorithm Description):**

```text
ParallelQuickSort(A, p):
    if p == 1:
        return SequentialQuickSort(A)
    
    pivot = SelectPivot(A)
    left, right = ParallelPartition(A, pivot)
    
    ParallelFor(i = 0 to 1):
        if i == 0:
            ParallelQuickSort(left, p/2)
        else:
            ParallelQuickSort(right, p/2)
    
    return Concatenate(left, right)
```

### 5.3 并行基数排序 (Parallel Radix Sort)

**定义 5.3.1** (并行基数排序 / Parallel Radix Sort)
并行基数排序并行处理每个数字位。

**Definition 5.3.1** (Parallel Radix Sort)
Parallel radix sort processes each digit position in parallel.

**定理 5.3.1** (并行基数排序复杂度 / Parallel Radix Sort Complexity)
并行基数排序的时间复杂度为 $O(\frac{n \log n}{p} + \log n)$。

**Theorem 5.3.1** (Parallel Radix Sort Complexity)
The time complexity of parallel radix sort is $O(\frac{n \log n}{p} + \log n)$.

---

## 6. 并行图算法 (Parallel Graph Algorithms)

### 6.1 并行BFS (Parallel BFS)

**定义 6.1.1** (并行BFS / Parallel BFS)
并行BFS同时处理同一层的所有节点。

**Definition 6.1.1** (Parallel BFS)
Parallel BFS processes all nodes at the same level simultaneously.

**算法描述 (Algorithm Description):**

```text
ParallelBFS(G, s):
    level[s] = 0
    current_level = [s]
    
    while current_level is not empty:
        next_level = ParallelFor each v in current_level:
            neighbors = G.neighbors(v)
            for each u in neighbors:
                if level[u] == undefined:
                    level[u] = level[v] + 1
                    next_level.add(u)
        current_level = next_level
```

### 6.2 并行最短路径 (Parallel Shortest Paths)

**定义 6.2.1** (并行Dijkstra算法 / Parallel Dijkstra Algorithm)
并行Dijkstra算法并行更新距离值。

**Definition 6.2.1** (Parallel Dijkstra Algorithm)
Parallel Dijkstra algorithm updates distance values in parallel.

**算法描述 (Algorithm Description):**

```text
ParallelDijkstra(G, s):
    d[s] = 0
    d[v] = ∞ for all v ≠ s
    Q = priority queue with all vertices
    
    while Q is not empty:
        u = Q.extract_min()
        
        ParallelFor each neighbor v of u:
            if d[u] + w(u,v) < d[v]:
                d[v] = d[u] + w(u,v)
                Q.decrease_key(v, d[v])
```

### 6.3 并行连通分量 (Parallel Connected Components)

**定义 6.3.1** (并行连通分量算法 / Parallel Connected Components Algorithm)
并行连通分量算法使用并行合并操作。

**Definition 6.3.1** (Parallel Connected Components Algorithm)
Parallel connected components algorithm uses parallel union operations.

**定理 6.3.1** (并行连通分量复杂度 / Parallel Connected Components Complexity)
并行连通分量算法的时间复杂度为 $O(\frac{n \log n}{p} + \log^2 n)$。

**Theorem 6.3.1** (Parallel Connected Components Complexity)
The time complexity of parallel connected components algorithm is $O(\frac{n \log n}{p} + \log^2 n)$.

---

## 7. 实现示例 (Implementation Examples)

### 7.1 并行归并排序实现 (Parallel Merge Sort Implementation)

```rust
use rayon::prelude::*;

pub struct ParallelMergeSort;

impl ParallelMergeSort {
    pub fn sort<T: Ord + Send + Sync>(arr: &[T]) -> Vec<T>
    where
        T: Clone,
    {
        if arr.len() <= 1 {
            return arr.to_vec();
        }
        
        let mid = arr.len() / 2;
        let (left, right) = rayon::join(
            || Self::sort(&arr[..mid]),
            || Self::sort(&arr[mid..])
        );
        
        Self::parallel_merge(left, right)
    }
    
    fn parallel_merge<T: Ord + Send + Sync>(left: Vec<T>, right: Vec<T>) -> Vec<T>
    where
        T: Clone,
    {
        let mut result = Vec::with_capacity(left.len() + right.len());
        let mut i = 0;
        let mut j = 0;
        
        while i < left.len() && j < right.len() {
            if left[i] <= right[j] {
                result.push(left[i].clone());
                i += 1;
            } else {
                result.push(right[j].clone());
                j += 1;
            }
        }
        
        result.extend_from_slice(&left[i..]);
        result.extend_from_slice(&right[j..]);
        result
    }
}
```

### 7.2 并行BFS实现 (Parallel BFS Implementation)

```rust
use std::collections::{HashSet, VecDeque};
use rayon::prelude::*;

pub struct ParallelBFS;

impl ParallelBFS {
    pub fn traverse(graph: &Graph, start: usize) -> Vec<usize> {
        let mut visited = vec![false; graph.vertices];
        let mut result = Vec::new();
        let mut current_level = vec![start];
        
        visited[start] = true;
        result.push(start);
        
        while !current_level.is_empty() {
            let next_level: Vec<usize> = current_level
                .par_iter()
                .flat_map(|&vertex| {
                    graph.neighbors(vertex)
                        .iter()
                        .filter(|&&neighbor| !visited[neighbor])
                        .map(|&neighbor| {
                            visited[neighbor] = true;
                            neighbor
                        })
                        .collect::<Vec<usize>>()
                })
                .collect();
            
            result.extend_from_slice(&next_level);
            current_level = next_level;
        }
        
        result
    }
}
```

### 7.3 并行图算法框架 (Parallel Graph Algorithm Framework)

```rust
use rayon::prelude::*;

pub struct ParallelGraphAlgorithms;

impl ParallelGraphAlgorithms {
    pub fn parallel_dijkstra(graph: &Graph, start: usize) -> Vec<f64> {
        let mut distances = vec![f64::INFINITY; graph.vertices];
        let mut visited = vec![false; graph.vertices];
        
        distances[start] = 0.0;
        
        for _ in 0..graph.vertices {
            let current = (0..graph.vertices)
                .par_iter()
                .filter(|&&i| !visited[i])
                .min_by(|&&a, &&b| distances[a].partial_cmp(&distances[b]).unwrap())
                .unwrap();
            
            visited[*current] = true;
            
            graph.neighbors(*current)
                .par_iter()
                .for_each(|&neighbor| {
                    let new_distance = distances[*current] + graph.weight(*current, neighbor);
                    if new_distance < distances[neighbor] {
                        distances[neighbor] = new_distance;
                    }
                });
        }
        
        distances
    }
    
    pub fn parallel_connected_components(graph: &Graph) -> Vec<Vec<usize>> {
        let mut components = Vec::new();
        let mut visited = vec![false; graph.vertices];
        
        for start in 0..graph.vertices {
            if !visited[start] {
                let mut component = Vec::new();
                let mut stack = vec![start];
                
                while let Some(vertex) = stack.pop() {
                    if !visited[vertex] {
                        visited[vertex] = true;
                        component.push(vertex);
                        
                        for &neighbor in graph.neighbors(vertex) {
                            if !visited[neighbor] {
                                stack.push(neighbor);
                            }
                        }
                    }
                }
                
                components.push(component);
            }
        }
        
        components
    }
}
```

### 7.4 并行性能分析 (Parallel Performance Analysis)

```rust
use std::time::{Duration, Instant};

pub struct ParallelPerformanceAnalyzer;

impl ParallelPerformanceAnalyzer {
    pub fn benchmark_parallel_sort<T: Ord + Clone + Send + Sync>(
        arr: &[T],
        sort_fn: fn(&[T]) -> Vec<T>,
    ) -> Duration {
        let start = Instant::now();
        let _result = sort_fn(arr);
        start.elapsed()
    }
    
    pub fn compare_serial_parallel<T: Ord + Clone + Send + Sync>(
        arr: &[T],
    ) {
        // 串行归并排序
        let serial_time = Self::benchmark_parallel_sort(arr, |arr| {
            let mut arr = arr.to_vec();
            arr.sort();
            arr
        });
        
        // 并行归并排序
        let parallel_time = Self::benchmark_parallel_sort(arr, |arr| {
            ParallelMergeSort::sort(arr)
        });
        
        let speedup = serial_time.as_nanos() as f64 / parallel_time.as_nanos() as f64;
        let efficiency = speedup / num_cpus::get() as f64;
        
        println!("Serial time: {:?}", serial_time);
        println!("Parallel time: {:?}", parallel_time);
        println!("Speedup: {:.2}", speedup);
        println!("Efficiency: {:.2}", efficiency);
    }
}
```

---

## 8. 参考文献 (References)

1. Jaja, J. (1992). An Introduction to Parallel Algorithms.
2. Leighton, F. T. (1992). Introduction to Parallel Algorithms and Architectures.
3. Cormen, T. H., et al. (2009). Introduction to Algorithms.
4. Valiant, L. G. (1990). A Bridging Model for Parallel Computation.
5. Blelloch, G. E. (1990). Vector Models for Data-Parallel Computing.

---

*本文档严格遵循数学形式化规范，所有定义和定理均采用标准数学符号表示。*
*This document strictly follows mathematical formalization standards, with all definitions and theorems using standard mathematical notation.*
