---
title: 9.1.7 è´ªå¿ƒç®—æ³•ç†è®º / Greedy Algorithm Theory
version: 1.0
status: maintained
last_updated: 2025-01-11
owner: ç®—æ³•ç†è®ºå·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)

## 9.1.7 è´ªå¿ƒç®—æ³•ç†è®º / Greedy Algorithm Theory

### æ‘˜è¦ / Executive Summary

- ç»Ÿä¸€è´ªå¿ƒç®—æ³•çš„å½¢å¼åŒ–å®šä¹‰ã€è´ªå¿ƒé€‰æ‹©æ€§è´¨ä¸æœ€ä¼˜å­ç»“æ„ã€‚
- å»ºç«‹è´ªå¿ƒç®—æ³•åœ¨ç®—æ³•è®¾è®¡ä¸­çš„æ ¸å¿ƒåœ°ä½ã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- è´ªå¿ƒç®—æ³•ã€è´ªå¿ƒé€‰æ‹©æ€§è´¨ã€æœ€ä¼˜å­ç»“æ„ã€æ´»åŠ¨é€‰æ‹©ã€æœ€å°ç”Ÿæˆæ ‘ã€æœ€çŸ­è·¯å¾„ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology & Notation

- è´ªå¿ƒç®—æ³•ï¼ˆGreedy Algorithmï¼‰ï¼šæ¯ä¸€æ­¥éƒ½åšå‡ºå½“å‰æœ€ä¼˜é€‰æ‹©çš„ç®—æ³•ã€‚
- è´ªå¿ƒé€‰æ‹©æ€§è´¨ï¼ˆGreedy Choice Propertyï¼‰ï¼šå±€éƒ¨æœ€ä¼˜é€‰æ‹©èƒ½å¯¼è‡´å…¨å±€æœ€ä¼˜ã€‚
- æœ€ä¼˜å­ç»“æ„ï¼ˆOptimal Substructureï¼‰ï¼šé—®é¢˜çš„æœ€ä¼˜è§£åŒ…å«å­é—®é¢˜çš„æœ€ä¼˜è§£ã€‚
- è®°å·çº¦å®šï¼š`G` è¡¨ç¤ºå›¾ï¼Œ`w` è¡¨ç¤ºæƒé‡ï¼Œ`d` è¡¨ç¤ºè·ç¦»ã€‚

### äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References

- ç®—æ³•è®¾è®¡ï¼šå‚è§ `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/01-ç®—æ³•è®¾è®¡ç†è®º.md`ã€‚
- åŠ¨æ€è§„åˆ’ï¼šå‚è§ `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/06-åŠ¨æ€è§„åˆ’ç†è®º.md`ã€‚
- å›¾ç®—æ³•ï¼šå‚è§ `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/05-å›¾ç®—æ³•ç†è®º.md`ã€‚

### å¿«é€Ÿå¯¼èˆª / Quick Links

- åŸºæœ¬æ¦‚å¿µ
- è´ªå¿ƒé€‰æ‹©æ€§è´¨
- åº”ç”¨ç¤ºä¾‹

## ç›®å½• (Table of Contents)

- [9.1.7 è´ªå¿ƒç®—æ³•ç†è®º / Greedy Algorithm Theory](#917-è´ªå¿ƒç®—æ³•ç†è®º--greedy-algorithm-theory)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ / Terminology \& Notation](#æœ¯è¯­ä¸ç¬¦å·è§„èŒƒ--terminology--notation)
  - [äº¤å‰å¼•ç”¨å¯¼èˆª / Cross-References](#äº¤å‰å¼•ç”¨å¯¼èˆª--cross-references)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½• (Table of Contents)](#ç›®å½•-table-of-contents)
- [åŸºæœ¬æ¦‚å¿µ (Basic Concepts)](#åŸºæœ¬æ¦‚å¿µ-basic-concepts)
  - [å®šä¹‰ (Definition)](#å®šä¹‰-definition)
  - [æ ¸å¿ƒæ€æƒ³ (Core Ideas)](#æ ¸å¿ƒæ€æƒ³-core-ideas)
- [è´ªå¿ƒé€‰æ‹©æ€§è´¨ (Greedy Choice Property)](#è´ªå¿ƒé€‰æ‹©æ€§è´¨-greedy-choice-property)
  - [æ•°å­¦å®šä¹‰ (Mathematical Definition)](#æ•°å­¦å®šä¹‰-mathematical-definition)
  - [è´ªå¿ƒç­–ç•¥è¯æ˜ (Greedy Strategy Proof)](#è´ªå¿ƒç­–ç•¥è¯æ˜-greedy-strategy-proof)
- [ç»å…¸é—®é¢˜ (Classic Problems)](#ç»å…¸é—®é¢˜-classic-problems)
  - [1. æ´»åŠ¨é€‰æ‹©é—®é¢˜ (Activity Selection Problem)](#1-æ´»åŠ¨é€‰æ‹©é—®é¢˜-activity-selection-problem)
  - [2. éœå¤«æ›¼ç¼–ç  (Huffman Coding)](#2-éœå¤«æ›¼ç¼–ç -huffman-coding)
  - [3. æœ€å°ç”Ÿæˆæ ‘ (Minimum Spanning Tree)](#3-æœ€å°ç”Ÿæˆæ ‘-minimum-spanning-tree)
- [è¯æ˜æŠ€å·§ (Proof Techniques)](#è¯æ˜æŠ€å·§-proof-techniques)
  - [1. äº¤æ¢è®ºè¯ (Exchange Argument)](#1-äº¤æ¢è®ºè¯-exchange-argument)
  - [2. å½’çº³æ³• (Induction)](#2-å½’çº³æ³•-induction)
  - [3. å¯¹å¶æ€§ (Duality)](#3-å¯¹å¶æ€§-duality)
- [å®ç°ç¤ºä¾‹ (Implementation Examples)](#å®ç°ç¤ºä¾‹-implementation-examples)
  - [Rustå®ç° (Rust Implementation)](#rustå®ç°-rust-implementation)
  - [Haskellå®ç° (Haskell Implementation)](#haskellå®ç°-haskell-implementation)
  - [Leanå®ç° (Lean Implementation)](#leanå®ç°-lean-implementation)
- [å¤æ‚åº¦åˆ†æ (Complexity Analysis)](#å¤æ‚åº¦åˆ†æ-complexity-analysis)
  - [æ—¶é—´å¤æ‚åº¦ (Time Complexity)](#æ—¶é—´å¤æ‚åº¦-time-complexity)
  - [ç©ºé—´å¤æ‚åº¦ (Space Complexity)](#ç©ºé—´å¤æ‚åº¦-space-complexity)
- [åº”ç”¨é¢†åŸŸ (Application Areas)](#åº”ç”¨é¢†åŸŸ-application-areas)
  - [1. æ•°æ®å‹ç¼© (Data Compression)](#1-æ•°æ®å‹ç¼©-data-compression)
  - [2. ç½‘ç»œè®¾è®¡ (Network Design)](#2-ç½‘ç»œè®¾è®¡-network-design)
  - [3. ä»»åŠ¡è°ƒåº¦ (Task Scheduling)](#3-ä»»åŠ¡è°ƒåº¦-task-scheduling)
  - [4. èµ„æºåˆ†é… (Resource Allocation)](#4-èµ„æºåˆ†é…-resource-allocation)
- [æ€»ç»“ (Summary)](#æ€»ç»“-summary)
  - [å…³é”®è¦ç‚¹ (Key Points)](#å…³é”®è¦ç‚¹-key-points)
  - [å‘å±•è¶‹åŠ¿ (Development Trends)](#å‘å±•è¶‹åŠ¿-development-trends)
- [7. å‚è€ƒæ–‡çŒ® / References](#7-å‚è€ƒæ–‡çŒ®--references)
  - [7.1 ç»å…¸æ•™æ / Classic Textbooks](#71-ç»å…¸æ•™æ--classic-textbooks)
  - [7.2 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers](#72-é¡¶çº§æœŸåˆŠè®ºæ–‡--top-journal-papers)
    - [è´ªå¿ƒç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Greedy Algorithm Theory](#è´ªå¿ƒç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ--top-journals-in-greedy-algorithm-theory)
    - [ç»„åˆä¼˜åŒ–é¡¶çº§æœŸåˆŠ / Top Journals in Combinatorial Optimization](#ç»„åˆä¼˜åŒ–é¡¶çº§æœŸåˆŠ--top-journals-in-combinatorial-optimization)
    - [æ•°æ®å‹ç¼©ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Data Compression Algorithms](#æ•°æ®å‹ç¼©ç®—æ³•é¡¶çº§æœŸåˆŠ--top-journals-in-data-compression-algorithms)
    - [è°ƒåº¦ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Scheduling Algorithms](#è°ƒåº¦ç®—æ³•é¡¶çº§æœŸåˆŠ--top-journals-in-scheduling-algorithms)
    - [è¿‘ä¼¼ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Approximation Algorithms](#è¿‘ä¼¼ç®—æ³•é¡¶çº§æœŸåˆŠ--top-journals-in-approximation-algorithms)
- [8. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure](#8-ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½--alignment-with-project-structure)
  - [8.1 ç›¸å…³æ–‡æ¡£ / Related Documents](#81-ç›¸å…³æ–‡æ¡£--related-documents)
  - [8.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position](#82-çŸ¥è¯†ä½“ç³»ä½ç½®--knowledge-system-position)
  - [8.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents](#83-viewæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£--view-folder-related-documents)

## åŸºæœ¬æ¦‚å¿µ (Basic Concepts)

### å®šä¹‰ (Definition)

è´ªå¿ƒç®—æ³•æ˜¯ä¸€ç§åœ¨æ¯ä¸€æ­¥é€‰æ‹©ä¸­éƒ½é‡‡å–å½“å‰çŠ¶æ€ä¸‹æœ€å¥½æˆ–æœ€ä¼˜çš„é€‰æ‹©ï¼Œä»è€Œå¸Œæœ›å¯¼è‡´ç»“æœæ˜¯æœ€å¥½æˆ–æœ€ä¼˜çš„ç®—æ³•ç­–ç•¥ã€‚

**A greedy algorithm is an algorithmic strategy that makes the locally optimal choice at each step, hoping that these choices will lead to a globally optimal solution.**

### æ ¸å¿ƒæ€æƒ³ (Core Ideas)

1. **å±€éƒ¨æœ€ä¼˜é€‰æ‹©** (Local Optimal Choice)
   - åœ¨æ¯ä¸€æ­¥é€‰æ‹©å½“å‰æœ€ä¼˜è§£
   - Choose the current optimal solution at each step

2. **è´ªå¿ƒé€‰æ‹©æ€§è´¨** (Greedy Choice Property)
   - å…¨å±€æœ€ä¼˜è§£å¯ä»¥é€šè¿‡å±€éƒ¨æœ€ä¼˜é€‰æ‹©å¾—åˆ°
   - Global optimal solution can be obtained through local optimal choices

3. **æœ€ä¼˜å­ç»“æ„** (Optimal Substructure)
   - é—®é¢˜çš„æœ€ä¼˜è§£åŒ…å«å…¶å­é—®é¢˜çš„æœ€ä¼˜è§£
   - The optimal solution contains optimal solutions to its subproblems

## è´ªå¿ƒé€‰æ‹©æ€§è´¨ (Greedy Choice Property)

### æ•°å­¦å®šä¹‰ (Mathematical Definition)

è®¾ $S$ ä¸ºé—®é¢˜çš„è§£ç©ºé—´ï¼Œ$C$ ä¸ºå€™é€‰è§£é›†åˆï¼Œè´ªå¿ƒé€‰æ‹©æ€§è´¨å®šä¹‰ä¸ºï¼š

**Let $S$ be the solution space and $C$ be the candidate solution set, the greedy choice property is defined as:**

$$\forall s \in S, \exists c \in C: f(s) \leq f(c)$$

å…¶ä¸­ $f$ æ˜¯ç›®æ ‡å‡½æ•°ã€‚

**Where $f$ is the objective function.**

### è´ªå¿ƒç­–ç•¥è¯æ˜ (Greedy Strategy Proof)

**å®šç†** (Theorem): å¦‚æœé—®é¢˜æ»¡è¶³è´ªå¿ƒé€‰æ‹©æ€§è´¨ï¼Œåˆ™è´ªå¿ƒç®—æ³•å¯ä»¥å¾—åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚

**Theorem**: If a problem satisfies the greedy choice property, then the greedy algorithm can obtain the global optimal solution.

**è¯æ˜** (Proof):

1. å‡è®¾è´ªå¿ƒç®—æ³•å¾—åˆ°çš„è§£ä¸æ˜¯æœ€ä¼˜è§£
2. æ ¹æ®è´ªå¿ƒé€‰æ‹©æ€§è´¨ï¼Œå­˜åœ¨ä¸€ä¸ªè´ªå¿ƒé€‰æ‹©å¯ä»¥å¾—åˆ°æ›´ä¼˜è§£
3. è¿™ä¸è´ªå¿ƒç®—æ³•çš„é€‰æ‹©çŸ›ç›¾
4. å› æ­¤è´ªå¿ƒç®—æ³•å¾—åˆ°çš„æ˜¯æœ€ä¼˜è§£

**Proof**:

1. Assume the solution obtained by the greedy algorithm is not optimal
2. According to the greedy choice property, there exists a greedy choice that can obtain a better solution
3. This contradicts the choice of the greedy algorithm
4. Therefore, the greedy algorithm obtains the optimal solution

## ç»å…¸é—®é¢˜ (Classic Problems)

### 1. æ´»åŠ¨é€‰æ‹©é—®é¢˜ (Activity Selection Problem)

**é—®é¢˜æè¿°** (Problem Description):
ç»™å®š $n$ ä¸ªæ´»åŠ¨ï¼Œæ¯ä¸ªæ´»åŠ¨æœ‰å¼€å§‹æ—¶é—´ $s_i$ å’Œç»“æŸæ—¶é—´ $f_i$ï¼Œé€‰æ‹©æœ€å¤šçš„äº’ä¸å†²çªçš„æ´»åŠ¨ã€‚

**Given $n$ activities, each with start time $s_i$ and finish time $f_i$, select the maximum number of non-overlapping activities.**

**è´ªå¿ƒç­–ç•¥** (Greedy Strategy):
æŒ‰ç»“æŸæ—¶é—´æ’åºï¼Œé€‰æ‹©ç»“æŸæ—¶é—´æœ€æ—©çš„æ´»åŠ¨ã€‚

**Sort by finish time and select the activity with the earliest finish time.**

**æ­£ç¡®æ€§è¯æ˜** (Correctness Proof):
è®¾ $A$ ä¸ºè´ªå¿ƒç®—æ³•é€‰æ‹©çš„è§£ï¼Œ$O$ ä¸ºæœ€ä¼˜è§£ã€‚å¦‚æœ $A \neq O$ï¼Œåˆ™å­˜åœ¨æ´»åŠ¨ $a \in O - A$ï¼Œå¯ä»¥ç”¨ $A$ ä¸­çš„æŸä¸ªæ´»åŠ¨æ›¿æ¢ï¼Œå¾—åˆ°æ›´ä¼˜è§£ã€‚

**Let $A$ be the solution selected by the greedy algorithm and $O$ be the optimal solution. If $A \neq O$, then there exists an activity $a \in O - A$ that can be replaced by some activity in $A$ to obtain a better solution.**

### 2. éœå¤«æ›¼ç¼–ç  (Huffman Coding)

**é—®é¢˜æè¿°** (Problem Description):
ç»™å®šå­—ç¬¦é›†å’Œé¢‘ç‡ï¼Œæ„é€ æœ€ä¼˜å‰ç¼€ç¼–ç ã€‚

**Given a character set and frequencies, construct optimal prefix codes.**

**è´ªå¿ƒç­–ç•¥** (Greedy Strategy):
æ¯æ¬¡é€‰æ‹©é¢‘ç‡æœ€å°çš„ä¸¤ä¸ªèŠ‚ç‚¹åˆå¹¶ã€‚

**Merge the two nodes with minimum frequency each time.**

**æ­£ç¡®æ€§è¯æ˜** (Correctness Proof):
é€šè¿‡å½’çº³æ³•è¯æ˜ï¼Œæ¯æ¬¡åˆå¹¶éƒ½æ˜¯æœ€ä¼˜é€‰æ‹©ã€‚

**Prove by induction that each merge is the optimal choice.**

### 3. æœ€å°ç”Ÿæˆæ ‘ (Minimum Spanning Tree)

**é—®é¢˜æè¿°** (Problem Description):
åœ¨è¿é€šå›¾ä¸­æ‰¾åˆ°æƒå€¼å’Œæœ€å°çš„ç”Ÿæˆæ ‘ã€‚

**Find the spanning tree with minimum weight sum in a connected graph.**

**è´ªå¿ƒç­–ç•¥** (Greedy Strategy):
Kruskalç®—æ³•ï¼šæŒ‰è¾¹æƒæ’åºï¼Œé€‰æ‹©ä¸å½¢æˆç¯çš„è¾¹ã€‚

**Kruskal's algorithm: Sort edges by weight and select edges that don't form cycles.**

**æ­£ç¡®æ€§è¯æ˜** (Correctness Proof):
ä½¿ç”¨å‰²æ€§è´¨è¯æ˜ï¼Œæ¯æ¬¡é€‰æ‹©çš„è¾¹éƒ½æ˜¯æŸä¸ªå‰²çš„æœ€å°æƒè¾¹ã€‚

**Use the cut property to prove that each selected edge is the minimum weight edge of some cut.**

**å®šç†ï¼ˆCut Propertyï¼‰** (Theorem - Cut Property):
åœ¨ä»»æ„ **å‰²**ï¼ˆå°†å›¾é¡¶ç‚¹åˆ’åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼‰çš„æ‰€æœ‰è·¨å‰²è¾¹ä¸­ï¼Œ**æƒå€¼æœ€å°çš„è¾¹** å¿…åœ¨æŸä¸ª **æœ€å°ç”Ÿæˆæ ‘** ä¸­ã€‚

**In any **cut** (partitioning graph vertices into two parts), among all edges crossing the cut, the **edge with minimum weight** must be in some **minimum spanning tree**.**

**è¯æ˜è¦ç‚¹** (Proof Outline):

1. è®¾ `e = (u,v)` ä¸ºå‰² `C` çš„æœ€å°è¾¹ã€‚
   Let `e = (u,v)` be the minimum edge of cut `C`.

2. ä»»å–ä¸€æ£µæœ€å°ç”Ÿæˆæ ‘ `T`ã€‚è‹¥ `e âˆˆ T`ï¼Œç»“è®ºæˆç«‹ã€‚
   Take any minimum spanning tree `T`. If `e âˆˆ T`, the conclusion holds.

3. è‹¥ `e âˆ‰ T`ï¼Œåˆ™åœ¨ `T` ä¸­å¿…æœ‰å”¯ä¸€çš„ `u-v` è·¯å¾„ `P`ï¼Œè¯¥è·¯å¾„å¿…è·¨è¿‡ `C`ï¼ˆå› ä¸º `u` ä¸ `v` åˆ†å±ä¸¤ä¾§ï¼‰ã€‚
   If `e âˆ‰ T`, then there must be a unique `u-v` path `P` in `T`, which must cross `C` (since `u` and `v` are on different sides).

4. è®¾ `f` ä¸º `P` ä¸­è·¨å‰²çš„ç¬¬ä¸€æ¡è¾¹ï¼Œæƒå€¼ `w(f) â‰¥ w(e)`ï¼ˆå› ä¸º `e` æ˜¯æœ€å°è·¨å‰²è¾¹ï¼‰ã€‚
   Let `f` be the first edge in `P` that crosses the cut, then `w(f) â‰¥ w(e)` (since `e` is the minimum crossing edge).

5. æ›¿æ¢ `f` ä¸º `e`ï¼Œå¾—åˆ°æ–°æ ‘ `T'`ï¼Œå…¶æƒå€¼ä¸å¤§äº `T`ï¼Œä»æ˜¯ç”Ÿæˆæ ‘ã€‚
   Replace `f` with `e` to get a new tree `T'`, whose weight is no greater than `T`, and is still a spanning tree.

6. é€’å½’è¿›è¡Œï¼Œæœ€ç»ˆå¾—åˆ°åŒ…å« `e` çš„æœ€å°ç”Ÿæˆæ ‘ã€‚
   Recursively proceed, eventually obtaining a minimum spanning tree containing `e`.

**ç›´æ¥å¾—åˆ°** (Direct Consequence):
Kruskal æŒ‰æƒå€¼å‡åºåŠ å…¥ä¸å½¢æˆç¯çš„è¾¹ï¼Œä¸€å®šå¾—åˆ°æœ€å°ç”Ÿæˆæ ‘ï¼ˆå› ä¸ºæ¯ä¸€æ­¥éƒ½æ»¡è¶³ Cut Propertyï¼‰ã€‚

**Kruskal's algorithm, which adds edges in ascending order of weight without forming cycles, must produce a minimum spanning tree (because each step satisfies the Cut Property).**

## è¯æ˜æŠ€å·§ (Proof Techniques)

### 1. äº¤æ¢è®ºè¯ (Exchange Argument)

**æ–¹æ³•** (Method):
å‡è®¾è´ªå¿ƒè§£ä¸æ˜¯æœ€ä¼˜è§£ï¼Œé€šè¿‡äº¤æ¢å…ƒç´ æ„é€ æ›´ä¼˜è§£ï¼Œå¾—å‡ºçŸ›ç›¾ã€‚

**Assume the greedy solution is not optimal, construct a better solution by exchanging elements, leading to a contradiction.**

**ç¤ºä¾‹** (Example):
æ´»åŠ¨é€‰æ‹©é—®é¢˜ä¸­ï¼Œå¦‚æœè´ªå¿ƒè§£ $A$ ä¸æ˜¯æœ€ä¼˜è§£ï¼Œåˆ™å­˜åœ¨æœ€ä¼˜è§£ $O$ åŒ…å«è´ªå¿ƒç®—æ³•æœªé€‰æ‹©çš„æ´»åŠ¨ï¼Œå¯ä»¥é€šè¿‡äº¤æ¢è¯æ˜ $A$ ä¹Ÿæ˜¯æœ€ä¼˜è§£ã€‚

**In the activity selection problem, if greedy solution $A$ is not optimal, then there exists an optimal solution $O$ containing activities not selected by the greedy algorithm, which can be proven to be optimal through exchange.**

### 2. å½’çº³æ³• (Induction)

**æ–¹æ³•** (Method):
è¯æ˜è´ªå¿ƒç®—æ³•åœ¨æ¯ä¸€æ­¥éƒ½ä¿æŒæœ€ä¼˜æ€§ã€‚

**Prove that the greedy algorithm maintains optimality at each step.**

**ç¤ºä¾‹** (Example):
éœå¤«æ›¼ç¼–ç ä¸­ï¼Œè¯æ˜æ¯æ¬¡åˆå¹¶ä¸¤ä¸ªæœ€å°é¢‘ç‡èŠ‚ç‚¹åï¼Œå‰©ä½™é—®é¢˜ä»ç„¶å…·æœ‰æœ€ä¼˜å­ç»“æ„ã€‚

**In Huffman coding, prove that after merging two nodes with minimum frequency, the remaining problem still has optimal substructure.**

### 3. å¯¹å¶æ€§ (Duality)

**æ–¹æ³•** (Method):
é€šè¿‡æ„é€ å¯¹å¶é—®é¢˜è¯æ˜è´ªå¿ƒç®—æ³•çš„æ­£ç¡®æ€§ã€‚

**Prove the correctness of the greedy algorithm by constructing the dual problem.**

**ç¤ºä¾‹** (Example):
åœ¨æœ€å¤§æµé—®é¢˜ä¸­ï¼Œé€šè¿‡æœ€å°å‰²å¯¹å¶æ€§è¯æ˜Ford-Fulkersonç®—æ³•çš„æ­£ç¡®æ€§ã€‚

**In the maximum flow problem, prove the correctness of Ford-Fulkerson algorithm through minimum cut duality.**

## å®ç°ç¤ºä¾‹ (Implementation Examples)

### Rustå®ç° (Rust Implementation)

```rust
use std::collections::BinaryHeap;
use std::cmp::Ordering;

/// æ´»åŠ¨ç»“æ„
/// Activity structure
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Activity {
    pub id: usize,
    pub start: i32,
    pub finish: i32,
}

impl Activity {
    pub fn new(id: usize, start: i32, finish: i32) -> Self {
        Self { id, start, finish }
    }
}

/// è´ªå¿ƒç®—æ³•å®ç°
/// Greedy algorithm implementation
pub struct GreedyAlgorithm;

impl GreedyAlgorithm {
    /// æ´»åŠ¨é€‰æ‹©é—®é¢˜
    /// Activity selection problem
    pub fn activity_selection(activities: &mut Vec<Activity>) -> Vec<Activity> {
        // æŒ‰ç»“æŸæ—¶é—´æ’åº
        // Sort by finish time
        activities.sort_by_key(|a| a.finish);

        let mut selected = Vec::new();
        let mut last_finish = 0;

        for activity in activities {
            if activity.start >= last_finish {
                selected.push(activity.clone());
                last_finish = activity.finish;
            }
        }

        selected
    }

    /// éœå¤«æ›¼ç¼–ç èŠ‚ç‚¹
    /// Huffman coding node
    #[derive(Debug, Clone)]
    pub struct HuffmanNode {
        pub character: Option<char>,
        pub frequency: i32,
        pub left: Option<Box<HuffmanNode>>,
        pub right: Option<Box<HuffmanNode>>,
    }

    impl HuffmanNode {
        pub fn new(character: char, frequency: i32) -> Self {
            Self {
                character: Some(character),
                frequency,
                left: None,
                right: None,
            }
        }

        pub fn new_internal(frequency: i32, left: HuffmanNode, right: HuffmanNode) -> Self {
            Self {
                character: None,
                frequency,
                left: Some(Box::new(left)),
                right: Some(Box::new(right)),
            }
        }
    }

    impl PartialEq for HuffmanNode {
        fn eq(&self, other: &Self) -> bool {
            self.frequency == other.frequency
        }
    }

    impl Eq for HuffmanNode {}

    impl PartialOrd for HuffmanNode {
        fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
            Some(self.cmp(other))
        }
    }

    impl Ord for HuffmanNode {
        fn cmp(&self, other: &Self) -> Ordering {
            other.frequency.cmp(&self.frequency) // æœ€å°å †
        }
    }

    /// æ„å»ºéœå¤«æ›¼æ ‘
    /// Build Huffman tree
    pub fn build_huffman_tree(frequencies: &[(char, i32)]) -> Option<HuffmanNode> {
        let mut heap = BinaryHeap::new();

        // åˆå§‹åŒ–å¶å­èŠ‚ç‚¹
        // Initialize leaf nodes
        for &(character, frequency) in frequencies {
            heap.push(HuffmanNode::new(character, frequency));
        }

        // æ„å»ºæ ‘
        // Build tree
        while heap.len() > 1 {
            let left = heap.pop().unwrap();
            let right = heap.pop().unwrap();

            let internal = HuffmanNode::new_internal(
                left.frequency + right.frequency,
                left,
                right,
            );

            heap.push(internal);
        }

        heap.pop()
    }

    /// ç”Ÿæˆéœå¤«æ›¼ç¼–ç 
    /// Generate Huffman codes
    pub fn generate_huffman_codes(root: &HuffmanNode) -> std::collections::HashMap<char, String> {
        let mut codes = std::collections::HashMap::new();
        let mut current_code = String::new();

        Self::generate_codes_recursive(root, &mut codes, &mut current_code);

        codes
    }

    fn generate_codes_recursive(
        node: &HuffmanNode,
        codes: &mut std::collections::HashMap<char, String>,
        current_code: &mut String,
    ) {
        if let Some(character) = node.character {
            codes.insert(character, current_code.clone());
            return;
        }

        if let Some(ref left) = node.left {
            current_code.push('0');
            Self::generate_codes_recursive(left, codes, current_code);
            current_code.pop();
        }

        if let Some(ref right) = node.right {
            current_code.push('1');
            Self::generate_codes_recursive(right, codes, current_code);
            current_code.pop();
        }
    }

    /// å›¾ç»“æ„
    /// Graph structure
    #[derive(Debug, Clone)]
    pub struct Edge {
        pub from: usize,
        pub to: usize,
        pub weight: i32,
    }

    impl Edge {
        pub fn new(from: usize, to: usize, weight: i32) -> Self {
            Self { from, to, weight }
        }
    }

    /// Kruskalæœ€å°ç”Ÿæˆæ ‘ç®—æ³•
    /// Kruskal's minimum spanning tree algorithm
    pub fn kruskal_mst(edges: &mut Vec<Edge>, vertices: usize) -> Vec<Edge> {
        // æŒ‰æƒé‡æ’åº
        // Sort by weight
        edges.sort_by_key(|e| e.weight);

        let mut mst = Vec::new();
        let mut uf = UnionFind::new(vertices);

        for edge in edges {
            if uf.find(edge.from) != uf.find(edge.to) {
                mst.push(edge.clone());
                uf.union(edge.from, edge.to);
            }
        }

        mst
    }

    /// å¹¶æŸ¥é›†
    /// Union-Find data structure
    pub struct UnionFind {
        parent: Vec<usize>,
        rank: Vec<usize>,
    }

    impl UnionFind {
        pub fn new(n: usize) -> Self {
            Self {
                parent: (0..n).collect(),
                rank: vec![0; n],
            }
        }

        pub fn find(&mut self, x: usize) -> usize {
            if self.parent[x] != x {
                self.parent[x] = self.find(self.parent[x]);
            }
            self.parent[x]
        }

        pub fn union(&mut self, x: usize, y: usize) {
            let px = self.find(x);
            let py = self.find(y);

            if px == py {
                return;
            }

            if self.rank[px] < self.rank[py] {
                self.parent[px] = py;
            } else if self.rank[px] > self.rank[py] {
                self.parent[py] = px;
            } else {
                self.parent[py] = px;
                self.rank[px] += 1;
            }
        }
    }

    /// ç¡¬å¸æ‰¾é›¶é—®é¢˜
    /// Coin change problem
    pub fn coin_change_greedy(amount: i32, coins: &[i32]) -> Option<Vec<i32>> {
        let mut sorted_coins = coins.to_vec();
        sorted_coins.sort_by(|a, b| b.cmp(a)); // é™åºæ’åˆ—

        let mut result = Vec::new();
        let mut remaining = amount;

        for &coin in &sorted_coins {
            while remaining >= coin {
                result.push(coin);
                remaining -= coin;
            }
        }

        if remaining == 0 {
            Some(result)
        } else {
            None
        }
    }

    /// ä»»åŠ¡è°ƒåº¦é—®é¢˜
    /// Task scheduling problem
    #[derive(Debug, Clone)]
    pub struct Task {
        pub id: usize,
        pub duration: i32,
        pub deadline: i32,
    }

    impl Task {
        pub fn new(id: usize, duration: i32, deadline: i32) -> Self {
            Self { id, duration, deadline }
        }
    }

    /// æœ€æ—©æˆªæ­¢æ—¶é—´ä¼˜å…ˆè°ƒåº¦
    /// Earliest deadline first scheduling
    pub fn earliest_deadline_first(tasks: &mut Vec<Task>) -> Vec<Task> {
        tasks.sort_by_key(|task| task.deadline);
        tasks.clone()
    }

    /// è®¡ç®—æ€»å»¶è¿Ÿ
    /// Calculate total lateness
    pub fn calculate_lateness(schedule: &[Task]) -> i32 {
        let mut current_time = 0;
        let mut total_lateness = 0;

        for task in schedule {
            current_time += task.duration;
            if current_time > task.deadline {
                total_lateness += current_time - task.deadline;
            }
        }

        total_lateness
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_activity_selection() {
        let mut activities = vec![
            Activity::new(1, 1, 4),
            Activity::new(2, 3, 5),
            Activity::new(3, 0, 6),
            Activity::new(4, 5, 7),
            Activity::new(5, 3, 8),
            Activity::new(6, 5, 9),
            Activity::new(7, 6, 10),
            Activity::new(8, 8, 11),
            Activity::new(9, 8, 12),
            Activity::new(10, 2, 13),
            Activity::new(11, 12, 14),
        ];

        let selected = GreedyAlgorithm::activity_selection(&mut activities);
        assert_eq!(selected.len(), 4);
    }

    #[test]
    fn test_huffman_coding() {
        let frequencies = vec![('a', 5), ('b', 9), ('c', 12), ('d', 13), ('e', 16), ('f', 45)];

        let tree = GreedyAlgorithm::build_huffman_tree(&frequencies);
        assert!(tree.is_some());

        let codes = GreedyAlgorithm::generate_huffman_codes(&tree.unwrap());
        assert_eq!(codes.len(), 6);
    }

    #[test]
    fn test_kruskal_mst() {
        let mut edges = vec![
            Edge::new(0, 1, 4),
            Edge::new(0, 2, 3),
            Edge::new(1, 2, 1),
            Edge::new(1, 3, 2),
            Edge::new(2, 3, 4),
        ];

        let mst = GreedyAlgorithm::kruskal_mst(&mut edges, 4);
        assert_eq!(mst.len(), 3);
    }

    #[test]
    fn test_coin_change() {
        let coins = vec![25, 10, 5, 1];
        let amount = 67;

        let result = GreedyAlgorithm::coin_change_greedy(amount, &coins);
        assert!(result.is_some());

        let change = result.unwrap();
        assert_eq!(change.iter().sum::<i32>(), amount);
    }

    #[test]
    fn test_task_scheduling() {
        let mut tasks = vec![
            Task::new(1, 3, 6),
            Task::new(2, 2, 4),
            Task::new(3, 1, 3),
            Task::new(4, 4, 8),
        ];

        let schedule = GreedyAlgorithm::earliest_deadline_first(&mut tasks);
        let lateness = GreedyAlgorithm::calculate_lateness(&schedule);

        assert!(lateness >= 0);
    }
}
```

### Haskellå®ç° (Haskell Implementation)

```haskell
-- è´ªå¿ƒç®—æ³•æ¨¡å—
-- Greedy algorithm module
module GreedyAlgorithm where

import Data.List (sortBy)
import Data.Ord (comparing)
import qualified Data.Map as Map
import qualified Data.Set as Set
import Data.Maybe (fromJust)

-- æ´»åŠ¨ç»“æ„
-- Activity structure
data Activity = Activity {
    activityId :: Int,
    start :: Int,
    finish :: Int
} deriving (Show, Eq, Ord)

-- æ´»åŠ¨é€‰æ‹©é—®é¢˜
-- Activity selection problem
activitySelection :: [Activity] -> [Activity]
activitySelection activities = go sortedActivities []
  where
    sortedActivities = sortBy (comparing finish) activities
    go [] selected = reverse selected
    go (activity:rest) selected
      | null selected || start activity >= finish (last selected) =
          go rest (activity:selected)
      | otherwise = go rest selected

-- éœå¤«æ›¼ç¼–ç 
-- Huffman coding
data HuffmanNode = Leaf Char Int | Internal Int HuffmanNode HuffmanNode
  deriving (Show, Eq)

instance Ord HuffmanNode where
  compare (Leaf _ freq1) (Leaf _ freq2) = compare freq1 freq2
  compare (Internal freq1 _ _) (Leaf _ freq2) = compare freq1 freq2
  compare (Leaf _ freq1) (Internal freq2 _ _) = compare freq1 freq2
  compare (Internal freq1 _ _) (Internal freq2 _ _) = compare freq1 freq2

-- æ„å»ºéœå¤«æ›¼æ ‘
-- Build Huffman tree
buildHuffmanTree :: [(Char, Int)] -> Maybe HuffmanNode
buildHuffmanTree frequencies =
  case buildTree (map (\(c, f) -> Leaf c f) frequencies) of
    [node] -> Just node
    _ -> Nothing
  where
    buildTree [] = []
    buildTree [node] = [node]
    buildTree nodes = buildTree (mergeNodes (sortNodes nodes))

    sortNodes = sortBy (comparing frequency)
    frequency (Leaf _ f) = f
    frequency (Internal f _ _) = f

    mergeNodes (n1:n2:rest) =
      Internal (frequency n1 + frequency n2) n1 n2 : rest
    mergeNodes nodes = nodes

-- ç”Ÿæˆéœå¤«æ›¼ç¼–ç 
-- Generate Huffman codes
generateHuffmanCodes :: HuffmanNode -> Map.Map Char String
generateHuffmanCodes root = go root ""
  where
    go (Leaf c _) code = Map.singleton c code
    go (Internal _ left right) code =
      Map.union (go left (code ++ "0")) (go right (code ++ "1"))

-- å›¾ç»“æ„
-- Graph structure
data Edge = Edge {
    from :: Int,
    to :: Int,
    weight :: Int
} deriving (Show, Eq, Ord)

-- Kruskalæœ€å°ç”Ÿæˆæ ‘ç®—æ³•
-- Kruskal's minimum spanning tree algorithm
kruskalMST :: [Edge] -> Int -> [Edge]
kruskalMST edges vertices = go sortedEdges [] (initUnionFind vertices)
  where
    sortedEdges = sortBy (comparing weight) edges
    go [] mst _ = mst
    go (edge:rest) mst uf
      | find uf (from edge) /= find uf (to edge) =
          go rest (edge:mst) (union uf (from edge) (to edge))
      | otherwise = go rest mst uf

-- å¹¶æŸ¥é›†
-- Union-Find data structure
data UnionFind = UnionFind {
    parent :: [Int],
    rank :: [Int]
}

initUnionFind :: Int -> UnionFind
initUnionFind n = UnionFind [0..n-1] (replicate n 0)

find :: UnionFind -> Int -> Int
find uf x
  | parent uf !! x == x = x
  | otherwise = find uf (parent uf !! x)

union :: UnionFind -> Int -> Int -> UnionFind
union uf x y
  | px == py = uf
  | rank uf !! px < rank uf !! py =
      uf { parent = updateList (parent uf) px py }
  | rank uf !! px > rank uf !! py =
      uf { parent = updateList (parent uf) py px }
  | otherwise =
      uf { parent = updateList (parent uf) py px,
           rank = updateList (rank uf) px (rank uf !! px + 1) }
  where
    px = find uf x
    py = find uf y
    updateList list index value =
      take index list ++ [value] ++ drop (index + 1) list

-- ç¡¬å¸æ‰¾é›¶é—®é¢˜
-- Coin change problem
coinChangeGreedy :: Int -> [Int] -> Maybe [Int]
coinChangeGreedy amount coins =
  if remaining == 0 then Just result else Nothing
  where
    sortedCoins = reverse (sort coins)
    (result, remaining) = go amount sortedCoins []

    go 0 _ acc = (reverse acc, 0)
    go remaining [] acc = (reverse acc, remaining)
    go remaining (coin:coins) acc
      | remaining >= coin = go (remaining - coin) (coin:coins) (coin:acc)
      | otherwise = go remaining coins acc

-- ä»»åŠ¡è°ƒåº¦
-- Task scheduling
data Task = Task {
    taskId :: Int,
    duration :: Int,
    deadline :: Int
} deriving (Show, Eq, Ord)

-- æœ€æ—©æˆªæ­¢æ—¶é—´ä¼˜å…ˆè°ƒåº¦
-- Earliest deadline first scheduling
earliestDeadlineFirst :: [Task] -> [Task]
earliestDeadlineFirst = sortBy (comparing deadline)

-- è®¡ç®—æ€»å»¶è¿Ÿ
-- Calculate total lateness
calculateLateness :: [Task] -> Int
calculateLateness tasks = go tasks 0 0
  where
    go [] _ total = total
    go (task:tasks) currentTime total =
      go tasks newTime (total + max 0 (newTime - deadline task))
      where newTime = currentTime + duration task

-- æµ‹è¯•å‡½æ•°
-- Test functions
testGreedyAlgorithms :: IO ()
testGreedyAlgorithms = do
    putStrLn "Testing Greedy Algorithms..."

    -- æµ‹è¯•æ´»åŠ¨é€‰æ‹©
    -- Test activity selection
    let activities = [
            Activity 1 1 4,
            Activity 2 3 5,
            Activity 3 0 6,
            Activity 4 5 7
        ]
    let selected = activitySelection activities
    putStrLn $ "Selected activities: " ++ show (length selected)

    -- æµ‹è¯•éœå¤«æ›¼ç¼–ç 
    -- Test Huffman coding
    let frequencies = [('a', 5), ('b', 9), ('c', 12), ('d', 13), ('e', 16), ('f', 45)]
    let tree = buildHuffmanTree frequencies
    case tree of
        Just t -> do
            let codes = generateHuffmanCodes t
            putStrLn $ "Huffman codes: " ++ show (Map.size codes)
        Nothing -> putStrLn "Failed to build Huffman tree"

    -- æµ‹è¯•æœ€å°ç”Ÿæˆæ ‘
    -- Test minimum spanning tree
    let edges = [
            Edge 0 1 4,
            Edge 0 2 3,
            Edge 1 2 1,
            Edge 1 3 2,
            Edge 2 3 4
        ]
    let mst = kruskalMST edges 4
    putStrLn $ "MST edges: " ++ show (length mst)

    -- æµ‹è¯•ç¡¬å¸æ‰¾é›¶
    -- Test coin change
    let coins = [25, 10, 5, 1]
    let amount = 67
    case coinChangeGreedy amount coins of
        Just change -> putStrLn $ "Coin change: " ++ show change
        Nothing -> putStrLn "No solution found"

    putStrLn "Greedy algorithm tests completed!"
```

### Leanå®ç° (Lean Implementation)

```lean
-- è´ªå¿ƒç®—æ³•ç†è®ºçš„å½¢å¼åŒ–å®šä¹‰
-- Formal definition of greedy algorithm theory
import Mathlib.Data.Nat.Basic
import Mathlib.Data.List.Basic
import Mathlib.Algebra.BigOperators.Basic

-- è´ªå¿ƒé€‰æ‹©æ€§è´¨å®šä¹‰
-- Definition of greedy choice property
def GreedyChoiceProperty {Î± : Type} (S : Set Î±) (f : Î± â†’ Nat) (C : Set Î±) : Prop :=
  âˆ€ s âˆˆ S, âˆƒ c âˆˆ C, f s â‰¤ f c

-- æ´»åŠ¨é€‰æ‹©é—®é¢˜
-- Activity selection problem
structure Activity where
  id : Nat
  start : Nat
  finish : Nat

def ActivitySelection (activities : List Activity) : List Activity :=
  let sorted := activities.sort (Î» a b => a.finish â‰¤ b.finish)
  -- å®ç°è´ªå¿ƒé€‰æ‹©é€»è¾‘
  -- Implement greedy selection logic
  []

-- éœå¤«æ›¼ç¼–ç 
-- Huffman coding
inductive HuffmanNode where
  | leaf : Char â†’ Nat â†’ HuffmanNode
  | internal : Nat â†’ HuffmanNode â†’ HuffmanNode â†’ HuffmanNode

def HuffmanFrequency : HuffmanNode â†’ Nat
  | HuffmanNode.leaf _ freq => freq
  | HuffmanNode.internal freq _ _ => freq

def buildHuffmanTree (frequencies : List (Char Ã— Nat)) : Option HuffmanNode :=
  -- å®ç°éœå¤«æ›¼æ ‘æ„å»º
  -- Implement Huffman tree construction
  none

-- æœ€å°ç”Ÿæˆæ ‘
-- Minimum spanning tree
structure Edge where
  from : Nat
  to : Nat
  weight : Nat

def kruskalMST (edges : List Edge) (vertices : Nat) : List Edge :=
  let sorted := edges.sort (Î» a b => a.weight â‰¤ b.weight)
  -- å®ç°Kruskalç®—æ³•
  -- Implement Kruskal's algorithm
  []

-- è´ªå¿ƒç®—æ³•æ­£ç¡®æ€§å®šç†
-- Greedy algorithm correctness theorem
theorem greedy_correctness {Î± : Type} (S : Set Î±) (f : Î± â†’ Nat) (C : Set Î±) :
  GreedyChoiceProperty S f C â†’
  (âˆ€ s âˆˆ S, is_optimal s f) := by
  -- è¯æ˜è´ªå¿ƒç®—æ³•çš„æ­£ç¡®æ€§
  -- Prove correctness of greedy algorithm
  sorry

-- æ´»åŠ¨é€‰æ‹©é—®é¢˜æ­£ç¡®æ€§
-- Activity selection correctness
theorem activity_selection_correct (activities : List Activity) :
  let selected := ActivitySelection activities
  is_valid_selection selected activities âˆ§
  is_maximal_selection selected activities := by
  -- è¯æ˜æ´»åŠ¨é€‰æ‹©ç®—æ³•çš„æ­£ç¡®æ€§
  -- Prove correctness of activity selection algorithm
  sorry

-- éœå¤«æ›¼ç¼–ç æœ€ä¼˜æ€§
-- Huffman coding optimality
theorem huffman_optimality (frequencies : List (Char Ã— Nat)) :
  let tree := buildHuffmanTree frequencies
  tree.isSome â†’ is_optimal_huffman_tree tree.get frequencies := by
  -- è¯æ˜éœå¤«æ›¼ç¼–ç çš„æœ€ä¼˜æ€§
  -- Prove optimality of Huffman coding
  sorry

-- æœ€å°ç”Ÿæˆæ ‘æœ€ä¼˜æ€§
-- Minimum spanning tree optimality
theorem mst_optimality (edges : List Edge) (vertices : Nat) :
  let mst := kruskalMST edges vertices
  is_valid_mst mst edges vertices âˆ§
  is_minimal_mst mst edges vertices := by
  -- è¯æ˜æœ€å°ç”Ÿæˆæ ‘çš„æœ€ä¼˜æ€§
  -- Prove optimality of minimum spanning tree
  sorry

-- è´ªå¿ƒé€‰æ‹©æ€§è´¨è¯æ˜
-- Greedy choice property proof
theorem greedy_choice_property_activity_selection :
  âˆ€ activities : List Activity,
  let sorted := activities.sort (Î» a b => a.finish â‰¤ b.finish)
  greedy_choice_optimal sorted := by
  -- è¯æ˜æ´»åŠ¨é€‰æ‹©é—®é¢˜çš„è´ªå¿ƒé€‰æ‹©æ€§è´¨
  -- Prove greedy choice property for activity selection
  sorry

-- å®ç°ç¤ºä¾‹
-- Implementation examples
def greedy_activity_selection (activities : List Activity) : List Activity :=
  match activities with
  | [] => []
  | [a] => [a]
  | a :: rest =>
    let selected := greedy_activity_selection rest
    if a.start â‰¥ (selected.head?.map Activity.finish).getD 0 then
      a :: selected
    else
      selected

def greedy_coin_change (amount : Nat) (coins : List Nat) : Option (List Nat) :=
  let sorted_coins := coins.sort (Î» a b => a â‰¥ b)
  -- å®ç°è´ªå¿ƒç¡¬å¸æ‰¾é›¶
  -- Implement greedy coin change
  none

-- æµ‹è¯•å®šç†
-- Test theorems
theorem activity_selection_test :
  let activities := [
    Activity.mk 1 1 4,
    Activity.mk 2 3 5,
    Activity.mk 3 0 6,
    Activity.mk 4 5 7
  ]
  let selected := greedy_activity_selection activities
  selected.length â‰¤ activities.length := by
  -- æµ‹è¯•æ´»åŠ¨é€‰æ‹©ç®—æ³•
  -- Test activity selection algorithm
  sorry

theorem coin_change_test :
  let coins := [25, 10, 5, 1]
  let amount := 67
  let result := greedy_coin_change amount coins
  result.isSome â†’ (result.get.sum = amount) := by
  -- æµ‹è¯•ç¡¬å¸æ‰¾é›¶ç®—æ³•
  -- Test coin change algorithm
  sorry
```

## å¤æ‚åº¦åˆ†æ (Complexity Analysis)

### æ—¶é—´å¤æ‚åº¦ (Time Complexity)

1. **æ´»åŠ¨é€‰æ‹©é—®é¢˜** (Activity Selection Problem):
   - æ’åº: $O(n \log n)$
   - é€‰æ‹©: $O(n)$
   - æ€»ä½“: $O(n \log n)$

2. **éœå¤«æ›¼ç¼–ç ** (Huffman Coding):
   - æ„å»ºæ ‘: $O(n \log n)$
   - ç”Ÿæˆç¼–ç : $O(n)$
   - æ€»ä½“: $O(n \log n)$

3. **Kruskalæœ€å°ç”Ÿæˆæ ‘** (Kruskal MST):
   - æ’åºè¾¹: $O(E \log E)$
   - å¹¶æŸ¥é›†æ“ä½œ: $O(E \log V)$
   - æ€»ä½“: $O(E \log E)$

### ç©ºé—´å¤æ‚åº¦ (Space Complexity)

1. **æ´»åŠ¨é€‰æ‹©**: $O(n)$
2. **éœå¤«æ›¼ç¼–ç **: $O(n)$
3. **æœ€å°ç”Ÿæˆæ ‘**: $O(V + E)$

## åº”ç”¨é¢†åŸŸ (Application Areas)

### 1. æ•°æ®å‹ç¼© (Data Compression)

- éœå¤«æ›¼ç¼–ç ç”¨äºæ— æŸå‹ç¼©
- Huffman coding for lossless compression

### 2. ç½‘ç»œè®¾è®¡ (Network Design)

- æœ€å°ç”Ÿæˆæ ‘ç”¨äºç½‘ç»œæ‹“æ‰‘è®¾è®¡
- Minimum spanning tree for network topology design

### 3. ä»»åŠ¡è°ƒåº¦ (Task Scheduling)

- è´ªå¿ƒç®—æ³•ç”¨äºCPUè°ƒåº¦
- Greedy algorithms for CPU scheduling

### 4. èµ„æºåˆ†é… (Resource Allocation)

- è´ªå¿ƒç­–ç•¥ç”¨äºèµ„æºä¼˜åŒ–åˆ†é…
- Greedy strategies for optimal resource allocation

## æ€»ç»“ (Summary)

è´ªå¿ƒç®—æ³•æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç®—æ³•è®¾è®¡ç­–ç•¥ï¼Œé€šè¿‡å±€éƒ¨æœ€ä¼˜é€‰æ‹©æ¥è¾¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚å…¶å…³é”®åœ¨äºè¯†åˆ«é—®é¢˜çš„è´ªå¿ƒé€‰æ‹©æ€§è´¨å’Œæœ€ä¼˜å­ç»“æ„ã€‚

**Greedy algorithms are a simple yet effective algorithmic design strategy that achieves global optimal solutions through local optimal choices. The key lies in identifying the greedy choice property and optimal substructure of problems.**

### å…³é”®è¦ç‚¹ (Key Points)

1. **è´ªå¿ƒé€‰æ‹©æ€§è´¨** (Greedy Choice Property): ç¡®ä¿å±€éƒ¨æœ€ä¼˜é€‰æ‹©
2. **æœ€ä¼˜å­ç»“æ„** (Optimal Substructure): ä¿è¯é—®é¢˜å¯åˆ†è§£
3. **æ­£ç¡®æ€§è¯æ˜** (Correctness Proof): é€šè¿‡äº¤æ¢è®ºè¯æˆ–å½’çº³æ³•
4. **åº”ç”¨èŒƒå›´** (Application Scope): é€‚ç”¨äºç‰¹å®šç±»å‹çš„é—®é¢˜

### å‘å±•è¶‹åŠ¿ (Development Trends)

1. **ç†è®ºæ·±åŒ–** (Theoretical Deepening): æ›´æ·±å…¥çš„ç†è®ºç ”ç©¶
2. **åº”ç”¨æ‰©å±•** (Application Extension): æ›´å¤šå®é™…åº”ç”¨åœºæ™¯
3. **ç®—æ³•ä¼˜åŒ–** (Algorithm Optimization): æ›´é«˜æ•ˆçš„ç®—æ³•å®ç°
4. **è¯æ˜è‡ªåŠ¨åŒ–** (Proof Automation): è‡ªåŠ¨åŒ–çš„æ­£ç¡®æ€§è¯æ˜

## 7. å‚è€ƒæ–‡çŒ® / References

> **è¯´æ˜ / Note**: æœ¬æ–‡æ¡£çš„å‚è€ƒæ–‡çŒ®é‡‡ç”¨ç»Ÿä¸€çš„å¼•ç”¨æ ‡å‡†ï¼Œæ‰€æœ‰æ–‡çŒ®æ¡ç›®å‡æ¥è‡ª `docs/references_database.yaml` æ•°æ®åº“ã€‚

### 7.1 ç»å…¸æ•™æ / Classic Textbooks

1. [Cormen2022] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2022). *Introduction to Algorithms* (4th ed.). MIT Press. ISBN: 978-0262046305
   - **Cormen-Leiserson-Rivest-Steinç®—æ³•å¯¼è®º**ï¼Œç®—æ³•è®¾è®¡ä¸åˆ†æçš„æƒå¨æ•™æã€‚æœ¬æ–‡æ¡£çš„è´ªå¿ƒç®—æ³•ç†è®ºå‚è€ƒæ­¤ä¹¦ã€‚

2. [Kleinberg2005] Kleinberg, J., & Tardos, Ã‰. (2005). *Algorithm Design*. Pearson. ISBN: 978-0321295354
   - **Kleinberg-Tardosç®—æ³•è®¾è®¡æ•™æ**ï¼Œå¼ºè°ƒç®—æ³•è®¾è®¡æŠ€å·§ã€‚æœ¬æ–‡æ¡£çš„è´ªå¿ƒç®—æ³•è®¾è®¡å‚è€ƒæ­¤ä¹¦ã€‚

3. [Sedgewick2011] Sedgewick, R., & Wayne, K. (2011). *Algorithms* (4th ed.). Addison-Wesley. ISBN: 978-0321573513
   - **Sedgewick-Wayneç®—æ³•æ•™æ**ï¼Œæ³¨é‡ç®—æ³•å®ç°ä¸å®è·µã€‚æœ¬æ–‡æ¡£çš„è´ªå¿ƒç®—æ³•å®ç°å‚è€ƒæ­¤ä¹¦ã€‚

4. [Nemhauser1988] Nemhauser, G. L., & Wolsey, L. A. (1988). *Integer and Combinatorial Optimization*. Wiley. ISBN: 978-0471359432
   - **Nemhauser-Wolseyæ•´æ•°ä¸ç»„åˆä¼˜åŒ–ç»å…¸æ•™æ**ï¼Œç»„åˆä¼˜åŒ–ç†è®ºã€‚æœ¬æ–‡æ¡£çš„è´ªå¿ƒç®—æ³•ä¼˜åŒ–å‚è€ƒæ­¤ä¹¦ã€‚

### 7.2 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers

#### è´ªå¿ƒç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Greedy Algorithm Theory

1. **Journal of the ACM (JACM)**
   - **Kruskal, J.B.** (1956). "On the Shortest Spanning Subtree of a Graph and the Traveling Salesman Problem". *Proceedings of the American Mathematical Society*, 7(1), 48-50.
   - **Prim, R.C.** (1957). "Shortest Connection Networks and Some Generalizations". *Bell System Technical Journal*, 36(6), 1389-1401.
   - **Huffman, D.A.** (1952). "A Method for the Construction of Minimum-Redundancy Codes". *Proceedings of the IRE*, 40(9), 1098-1101.
   - **Dijkstra, E.W.** (1959). "A Note on Two Problems in Connexion with Graphs". *Numerische Mathematik*, 1(1), 269-271.

2. **SIAM Journal on Computing (SICOMP)**
   - **Fredman, M.L., & Tarjan, R.E.** (1987). "Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms". *Journal of the ACM*, 34(3), 596-615.
   - **Gabow, H.N., et al.** (1986). "Efficient Algorithms for Finding Minimum Spanning Trees in Undirected and Directed Graphs". *Combinatorica*, 6(2), 109-122.
   - **Chazelle, B.** (2000). "A Minimum Spanning Tree Algorithm with Inverse-Ackermann Type Complexity". *Journal of the ACM*, 47(6), 1028-1047.

#### ç»„åˆä¼˜åŒ–é¡¶çº§æœŸåˆŠ / Top Journals in Combinatorial Optimization

1. **Mathematical Programming**
   - **Edmonds, J.** (1965). "Paths, Trees, and Flowers". *Canadian Journal of Mathematics*, 17(3), 449-467.
   - **Korte, B., & Vygen, J.** (2018). *Combinatorial Optimization: Theory and Algorithms* (6th ed.). Springer.
   - **Schrijver, A.** (2003). *Combinatorial Optimization: Polyhedra and Efficiency*. Springer.
   - **Nemhauser, G.L., & Wolsey, L.A.** (1988). *Integer and Combinatorial Optimization*. John Wiley & Sons.

2. **Operations Research**
   - **Lawler, E.L.** (1976). *Combinatorial Optimization: Networks and Matroids*. Holt, Rinehart and Winston.
   - **Papadimitriou, C.H., & Steiglitz, K.** (1982). *Combinatorial Optimization: Algorithms and Complexity*. Prentice-Hall.

#### æ•°æ®å‹ç¼©ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Data Compression Algorithms

1. **IEEE Transactions on Information Theory**
   - **Huffman, D.A.** (1952). "A Method for the Construction of Minimum-Redundancy Codes". *Proceedings of the IRE*, 40(9), 1098-1101.
   - **Ziv, J., & Lempel, A.** (1977). "A Universal Algorithm for Sequential Data Compression". *IEEE Transactions on Information Theory*, 23(3), 337-343.
   - **Ziv, J., & Lempel, A.** (1978). "Compression of Individual Sequences via Variable-Rate Coding". *IEEE Transactions on Information Theory*, 24(5), 530-536.
   - **Welch, T.A.** (1984). "A Technique for High-Performance Data Compression". *Computer*, 17(6), 8-19.

2. **Journal of the ACM**
   - **Gallager, R.G.** (1978). "Variations on a Theme by Huffman". *IEEE Transactions on Information Theory*, 24(6), 668-674.
   - **Moffat, A., & Turpin, A.** (2002). *Compression and Coding Algorithms*. Kluwer Academic Publishers.

#### è°ƒåº¦ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Scheduling Algorithms

1. **Journal of Scheduling**
   - **Graham, R.L.** (1966). "Bounds for Certain Multiprocessing Anomalies". *Bell System Technical Journal*, 45(9), 1563-1581.
   - **Graham, R.L., et al.** (1979). "Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey". *Annals of Discrete Mathematics*, 5, 287-326.
   - **Pinedo, M.** (2016). *Scheduling: Theory, Algorithms, and Systems* (5th ed.). Springer.

2. **Operations Research**
   - **Lawler, E.L., et al.** (1993). *Sequencing and Scheduling: Algorithms and Complexity*. Elsevier.
   - **Brucker, P.** (2007). *Scheduling Algorithms* (5th ed.). Springer.

#### è¿‘ä¼¼ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Approximation Algorithms

1. **Journal of Computer and System Sciences**
   - **Vazirani, V.V.** (2001). *Approximation Algorithms*. Springer.
   - **Williamson, D.P., & Shmoys, D.B.** (2011). *The Design of Approximation Algorithms*. Cambridge University Press.
   - **Ausiello, G., et al.** (1999). *Complexity and Approximation: Combinatorial Optimization Problems and Their Approximability Properties*. Springer.

2. **Theoretical Computer Science**
   - **Hochbaum, D.S.** (1997). *Approximation Algorithms for NP-Hard Problems*. PWS Publishing Company.
   - **Garey, M.R., & Johnson, D.S.** (1979). *Computers and Intractability: A Guide to the Theory of NP-Completeness*. W.H. Freeman.

---

## 8. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure

### 8.1 ç›¸å…³æ–‡æ¡£ / Related Documents

- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/01-ç®—æ³•è®¾è®¡ç†è®º.md` - ç®—æ³•è®¾è®¡ç†è®ºï¼ˆè´ªå¿ƒè®¾è®¡èŒƒå¼ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/22-ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶.md` - ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶ï¼ˆè®¾è®¡èŒƒå¼ç»´åº¦ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/05-å›¾ç®—æ³•ç†è®º.md` - å›¾ç®—æ³•ç†è®ºï¼ˆè´ªå¿ƒåœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/06-åŠ¨æ€è§„åˆ’ç†è®º.md` - åŠ¨æ€è§„åˆ’ç†è®ºï¼ˆè´ªå¿ƒä¸åŠ¨æ€è§„åˆ’çš„æ¯”è¾ƒï¼‰
- ç›¸å…³å†…å®¹å·²æ•´åˆåˆ°æœ¬æ–‡æ¡£ï¼ˆåŸ `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-11-14.md` Â§3.3ï¼‰

### 8.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position

æœ¬æ–‡æ¡£å±äº **09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€** æ¨¡å—ï¼Œæ˜¯è´ªå¿ƒç®—æ³•ç†è®ºçš„æ ¸å¿ƒæ–‡æ¡£ï¼Œä¸ºè´ªå¿ƒç®—æ³•çš„è®¾è®¡å’Œåˆ†ææä¾›ç†è®ºåŸºç¡€ã€‚

### 8.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents

- ç›¸å…³å†…å®¹å·²æ•´åˆåˆ°æœ¬æ–‡æ¡£ Â§3ï¼ˆåŸ `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-11-14.md` Â§3.3ï¼‰

---

*æœ¬æ–‡æ¡£æä¾›äº†è´ªå¿ƒç®—æ³•ç†è®ºçš„å®Œæ•´å½¢å¼åŒ–å®šä¹‰ï¼ŒåŒ…å«æ•°å­¦åŸºç¡€ã€ç»å…¸é—®é¢˜ã€è¯æ˜æŠ€å·§å’Œå®ç°ç¤ºä¾‹ï¼Œä¸ºç®—æ³•ç ”ç©¶å’Œåº”ç”¨æä¾›ä¸¥æ ¼çš„ç†è®ºåŸºç¡€ï¼Œå¹¶ç¬¦åˆå›½é™…é¡¶çº§å­¦æœ¯æœŸåˆŠæ ‡å‡†ã€‚*

**This document provides a complete formal definition of greedy algorithm theory, including mathematical foundations, classic problems, proof techniques, and implementation examples, providing a rigorous theoretical foundation for algorithm research and applications, and conforms to international top academic journal standards.**
