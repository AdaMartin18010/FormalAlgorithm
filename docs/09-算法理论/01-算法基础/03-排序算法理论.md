---
title: 9.1.3 æ’åºç®—æ³•ç†è®º / Sorting Algorithm Theory
version: 1.2
status: maintained
last_updated: 2025-01-12
owner: ç®—æ³•ç†è®ºå·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)
> **é¡¹ç›®å¯¼èˆªä¸å¯¹æ ‡**ï¼š[é¡¹ç›®æ‰©å±•ä¸æŒç»­æ¨è¿›ä»»åŠ¡ç¼–æ’](../../é¡¹ç›®æ‰©å±•ä¸æŒç»­æ¨è¿›ä»»åŠ¡ç¼–æ’.md)ã€[å›½é™…è¯¾ç¨‹å¯¹æ ‡è¡¨](../../å›½é™…è¯¾ç¨‹å¯¹æ ‡è¡¨.md)

## 9.1.3 æ’åºç®—æ³•ç†è®º / Sorting Algorithm Theory

### æ‘˜è¦ / Executive Summary

- å½’çº³æ¯”è¾ƒæ’åºä¸éæ¯”è¾ƒæ’åºçš„å…¸å‹ç®—æ³•ã€ç¨³å®šæ€§ä¸é€‚åº”æ€§åˆ†æï¼Œä»¥åŠä¿¡æ¯è®ºä¸‹ç•Œã€‚
- ç»™å‡ºå®ç°ç¤ºä¾‹ä¸å¯¹æ¯”ç»´åº¦ï¼Œä¾¿äºå·¥ç¨‹é€‰æ‹©ä¸æ•™å­¦å¯¹æ¯”ã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- ç¨³å®šæ€§/é€‚åº”æ€§ï¼šæ’åºæ€§è´¨ä¸é€‚ç”¨åœºæ™¯ã€‚
- æ¯”è¾ƒæ ‘æ¨¡å‹ï¼šæ¯”è¾ƒæ’åºä¸‹ç•Œåˆ†ææ¡†æ¶ã€‚
- çº¿æ€§æ—¶é—´æ’åºï¼šè®¡æ•°/åŸºæ•°/æ¡¶çš„å‰æä¸é™åˆ¶ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### å›½é™…è¯¾ç¨‹å‚è€ƒ / International Course References

æ’åºç®—æ³•å¯ä¸ **MIT 6.006**ã€**CMU 15-451**ã€**Stanford CS 161**ã€**Berkeley CS 170** ç­‰è¯¾ç¨‹å¯¹æ ‡ã€‚è¯¾ç¨‹ä¸æ¨¡å—æ˜ å°„è§ [å›½é™…è¯¾ç¨‹å¯¹æ ‡è¡¨](../../å›½é™…è¯¾ç¨‹å¯¹æ ‡è¡¨.md)ã€‚

### å¿«é€Ÿå¯¼èˆª / Quick Links

- [ç›®å½•](#ç›®å½•--table-of-contents)
- [åŸºæœ¬æ¦‚å¿µ](#1-åŸºæœ¬æ¦‚å¿µ--basic-concepts)
- [æ¯”è¾ƒæ’åº](#2-æ¯”è¾ƒæ’åº--comparison-sorting)
- [3. éæ¯”è¾ƒæ’åº / Non-Comparison Sorting](#3-éæ¯”è¾ƒæ’åº--non-comparison-sorting)
- [4. æ’åºä¸‹ç•Œ / Sorting Lower Bounds](#4-æ’åºä¸‹ç•Œ--sorting-lower-bounds)

## ç›®å½• / Table of Contents

- [9.1.3 æ’åºç®—æ³•ç†è®º / Sorting Algorithm Theory](#913-æ’åºç®—æ³•ç†è®º--sorting-algorithm-theory)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [å›½é™…è¯¾ç¨‹å‚è€ƒ / International Course References](#å›½é™…è¯¾ç¨‹å‚è€ƒ--international-course-references)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½• / Table of Contents](#ç›®å½•--table-of-contents)
- [æ¦‚è¿° / Overview](#æ¦‚è¿°--overview)
- [1. åŸºæœ¬æ¦‚å¿µ / Basic Concepts](#1-åŸºæœ¬æ¦‚å¿µ--basic-concepts)
  - [1.1 æ’åºé—®é¢˜å®šä¹‰ / Sorting Problem Definition](#11-æ’åºé—®é¢˜å®šä¹‰--sorting-problem-definition)
  - [1.2 æ’åºç®—æ³•åˆ†ç±» / Sorting Algorithm Classification](#12-æ’åºç®—æ³•åˆ†ç±»--sorting-algorithm-classification)
  - [1.4 å†…å®¹è¡¥å……ä¸æ€ç»´è¡¨å¾ / Content Supplement and Thinking Representation](#14-å†…å®¹è¡¥å……ä¸æ€ç»´è¡¨å¾--content-supplement-and-thinking-representation)
    - [è§£é‡Šä¸ç›´è§‚ / Explanation and Intuition](#è§£é‡Šä¸ç›´è§‚--explanation-and-intuition)
    - [æ¦‚å¿µå±æ€§è¡¨ / Concept Attribute Table](#æ¦‚å¿µå±æ€§è¡¨--concept-attribute-table)
    - [æ¦‚å¿µå…³ç³» / Concept Relations](#æ¦‚å¿µå…³ç³»--concept-relations)
    - [æ¦‚å¿µä¾èµ–å›¾ / Concept Dependency Graph](#æ¦‚å¿µä¾èµ–å›¾--concept-dependency-graph)
    - [è®ºè¯ä¸è¯æ˜è¡”æ¥ / Argumentation and Proof Link](#è®ºè¯ä¸è¯æ˜è¡”æ¥--argumentation-and-proof-link)
    - [æ€ç»´å¯¼å›¾ï¼šæœ¬ç« æ¦‚å¿µç»“æ„ / Mind Map](#æ€ç»´å¯¼å›¾æœ¬ç« æ¦‚å¿µç»“æ„--mind-map)
    - [å¤šç»´çŸ©é˜µï¼šæ’åºç®—æ³•å¯¹æ¯” / Multi-Dimensional Comparison](#å¤šç»´çŸ©é˜µæ’åºç®—æ³•å¯¹æ¯”--multi-dimensional-comparison)
    - [å†³ç­–æ ‘ï¼šæ’åºç®—æ³•é€‰æ‹© / Decision Tree](#å†³ç­–æ ‘æ’åºç®—æ³•é€‰æ‹©--decision-tree)
    - [å…¬ç†å®šç†æ¨ç†è¯æ˜å†³ç­–æ ‘ / Axiom-Theorem-Proof Tree](#å…¬ç†å®šç†æ¨ç†è¯æ˜å†³ç­–æ ‘--axiom-theorem-proof-tree)
    - [åº”ç”¨å†³ç­–å»ºæ¨¡æ ‘ / Application Decision Modeling Tree](#åº”ç”¨å†³ç­–å»ºæ¨¡æ ‘--application-decision-modeling-tree)
- [2. æ¯”è¾ƒæ’åº / Comparison Sorting](#2-æ¯”è¾ƒæ’åº--comparison-sorting)
  - [2.1 å†’æ³¡æ’åº / Bubble Sort](#21-å†’æ³¡æ’åº--bubble-sort)
  - [2.2 é€‰æ‹©æ’åº / Selection Sort](#22-é€‰æ‹©æ’åº--selection-sort)
  - [2.3 æ’å…¥æ’åº / Insertion Sort](#23-æ’å…¥æ’åº--insertion-sort)
  - [2.4 å½’å¹¶æ’åº / Merge Sort](#24-å½’å¹¶æ’åº--merge-sort)
  - [2.5 å¿«é€Ÿæ’åº / Quick Sort](#25-å¿«é€Ÿæ’åº--quick-sort)
    - [2.5.1 æœ€åæƒ…å†µåˆ†æ / Worst-Case Analysis](#251-æœ€åæƒ…å†µåˆ†æ--worst-case-analysis)
    - [2.5.2 æœ€å¥½æƒ…å†µåˆ†æ / Best-Case Analysis](#252-æœ€å¥½æƒ…å†µåˆ†æ--best-case-analysis)
    - [2.5.3 å¹³å‡æƒ…å†µåˆ†æ / Average-Case Analysis](#253-å¹³å‡æƒ…å†µåˆ†æ--average-case-analysis)
    - [2.5.4 å¿«é€Ÿæ’åºæ­£ç¡®æ€§ï¼ˆå½’çº³æ³•ï¼‰/ QuickSort Correctness (Induction)](#254-å¿«é€Ÿæ’åºæ­£ç¡®æ€§å½’çº³æ³•-quicksort-correctness-induction)
    - [2.5.5 åˆ’åˆ†å‡½æ•°æ­£ç¡®æ€§ï¼ˆå¾ªç¯ä¸å˜å¼ï¼‰/ Partition Correctness (Loop Invariant)](#255-åˆ’åˆ†å‡½æ•°æ­£ç¡®æ€§å¾ªç¯ä¸å˜å¼-partition-correctness-loop-invariant)
  - [2.6 å †æ’åº / Heap Sort](#26-å †æ’åº--heap-sort)
    - [2.6.1 å»ºå †é˜¶æ®µåˆ†æ / Build Heap Phase Analysis](#261-å»ºå †é˜¶æ®µåˆ†æ--build-heap-phase-analysis)
    - [2.6.2 æå–é˜¶æ®µåˆ†æ / Extraction Phase Analysis](#262-æå–é˜¶æ®µåˆ†æ--extraction-phase-analysis)
    - [2.6.3 æ€»æ—¶é—´å¤æ‚åº¦ / Total Time Complexity](#263-æ€»æ—¶é—´å¤æ‚åº¦--total-time-complexity)
- [3. éæ¯”è¾ƒæ’åº / Non-Comparison Sorting](#3-éæ¯”è¾ƒæ’åº--non-comparison-sorting)
  - [3.1 è®¡æ•°æ’åº / Counting Sort](#31-è®¡æ•°æ’åº--counting-sort)
  - [3.2 åŸºæ•°æ’åº / Radix Sort](#32-åŸºæ•°æ’åº--radix-sort)
  - [3.3 æ¡¶æ’åº / Bucket Sort](#33-æ¡¶æ’åº--bucket-sort)
- [4. æ’åºä¸‹ç•Œ / Sorting Lower Bounds](#4-æ’åºä¸‹ç•Œ--sorting-lower-bounds)
  - [4.1 æ¯”è¾ƒæ’åºä¸‹ç•Œ / Comparison Sorting Lower Bound](#41-æ¯”è¾ƒæ’åºä¸‹ç•Œ--comparison-sorting-lower-bound)
  - [4.2 ä¿¡æ¯è®ºä¸‹ç•Œ / Information-Theoretic Lower Bound](#42-ä¿¡æ¯è®ºä¸‹ç•Œ--information-theoretic-lower-bound)
  - [4.3 è‡ªé€‚åº”æ’åº / Adaptive Sorting](#43-è‡ªé€‚åº”æ’åº--adaptive-sorting)
- [5. å¤–éƒ¨æ’åº / External Sorting](#5-å¤–éƒ¨æ’åº--external-sorting)
  - [5.1 å¤–éƒ¨æ’åºæ¨¡å‹ / External Sorting Model](#51-å¤–éƒ¨æ’åºæ¨¡å‹--external-sorting-model)
  - [5.2 å¤šè·¯å½’å¹¶ / Multiway Merge](#52-å¤šè·¯å½’å¹¶--multiway-merge)
  - [5.3 æ›¿æ¢é€‰æ‹© / Replacement Selection](#53-æ›¿æ¢é€‰æ‹©--replacement-selection)
- [6. å®ç°ç¤ºä¾‹](#6-å®ç°ç¤ºä¾‹)
  - [6.1 å¿«é€Ÿæ’åºå®ç°](#61-å¿«é€Ÿæ’åºå®ç°)
  - [6.2 å½’å¹¶æ’åºå®ç°](#62-å½’å¹¶æ’åºå®ç°)
  - [6.3 å †æ’åºå®ç°](#63-å †æ’åºå®ç°)
  - [6.4 è®¡æ•°æ’åºå®ç°](#64-è®¡æ•°æ’åºå®ç°)
  - [6.5 åŸºæ•°æ’åºå®ç°](#65-åŸºæ•°æ’åºå®ç°)
  - [6.6 æ’åºç®—æ³•æ¯”è¾ƒ](#66-æ’åºç®—æ³•æ¯”è¾ƒ)
- [7. å‚è€ƒæ–‡çŒ® / References](#7-å‚è€ƒæ–‡çŒ®--references)
  - [7.1 ç»å…¸æ•™æ / Classic Textbooks](#71-ç»å…¸æ•™æ--classic-textbooks)
  - [7.2 Wikiæ¦‚å¿µå‚è€ƒ / Wiki Concept References](#72-wikiæ¦‚å¿µå‚è€ƒ--wiki-concept-references)
  - [7.3 å¤§å­¦è¯¾ç¨‹å‚è€ƒ / University Course References](#73-å¤§å­¦è¯¾ç¨‹å‚è€ƒ--university-course-references)
  - [7.4 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers](#74-é¡¶çº§æœŸåˆŠè®ºæ–‡--top-journal-papers)
    - [æ’åºç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Sorting Algorithm Theory](#æ’åºç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ--top-journals-in-sorting-algorithm-theory)
    - [æ¯”è¾ƒæ’åºä¸‹ç•Œç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Comparison Sort Lower Bounds](#æ¯”è¾ƒæ’åºä¸‹ç•Œç†è®ºé¡¶çº§æœŸåˆŠ--top-journals-in-comparison-sort-lower-bounds)
    - [çº¿æ€§æ—¶é—´æ’åºé¡¶çº§æœŸåˆŠ / Top Journals in Linear Time Sorting](#çº¿æ€§æ—¶é—´æ’åºé¡¶çº§æœŸåˆŠ--top-journals-in-linear-time-sorting)
    - [å¤–éƒ¨æ’åºé¡¶çº§æœŸåˆŠ / Top Journals in External Sorting](#å¤–éƒ¨æ’åºé¡¶çº§æœŸåˆŠ--top-journals-in-external-sorting)
    - [å¹¶è¡Œæ’åºé¡¶çº§æœŸåˆŠ / Top Journals in Parallel Sorting](#å¹¶è¡Œæ’åºé¡¶çº§æœŸåˆŠ--top-journals-in-parallel-sorting)
- [8. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure](#8-ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½--alignment-with-project-structure)
  - [8.1 ç›¸å…³æ–‡æ¡£ / Related Documents](#81-ç›¸å…³æ–‡æ¡£--related-documents)
  - [8.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position](#82-çŸ¥è¯†ä½“ç³»ä½ç½®--knowledge-system-position)
  - [8.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents](#83-viewæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£--view-folder-related-documents)

---

## æ¦‚è¿° / Overview

æ’åºç®—æ³•æ˜¯è®¡ç®—æœºç§‘å­¦ä¸­æœ€åŸºç¡€å’Œé‡è¦çš„ç®—æ³•ä¹‹ä¸€ã€‚æ ¹æ®[Cormen 2022]çš„å®šä¹‰ï¼Œæ’åºé—®é¢˜æ˜¯å°†åºåˆ—é‡æ–°æ’åˆ—ä¸ºæœ‰åºåºåˆ—çš„é—®é¢˜ã€‚æ ¹æ®[Sedgewick 2011]çš„ç ”ç©¶ï¼Œæ’åºç®—æ³•å¯ä»¥åˆ†ä¸ºæ¯”è¾ƒæ’åºå’Œéæ¯”è¾ƒæ’åºä¸¤å¤§ç±»ï¼Œæ¯ç±»éƒ½æœ‰å…¶ç‰¹å®šçš„åº”ç”¨åœºæ™¯å’Œå¤æ‚åº¦ç‰¹å¾ã€‚æœ¬æ–‡æ¡£æ¶µç›–æ’åºç®—æ³•çš„ç†è®ºåŸºç¡€ã€ç»å…¸ç®—æ³•ã€å¤æ‚åº¦åˆ†æå’Œåº”ç”¨é¢†åŸŸã€‚

Sorting algorithms are among the most fundamental and important algorithms in computer science. According to [Cormen 2022], the sorting problem is to rearrange a sequence into an ordered sequence. According to [Sedgewick 2011], sorting algorithms can be divided into two major categories: comparison-based sorting and non-comparison-based sorting, each with its specific application scenarios and complexity characteristics. This document covers the theoretical foundations, classic algorithms, complexity analysis, and application areas of sorting algorithms.

**å­¦æœ¯å¼•ç”¨ / Academic Citations:**

- [Cormen 2022]: Cormen, T. H., et al. (2022). *Introduction to Algorithms* (4th ed.). MIT Press. ISBN: 978-0262046305
- [Sedgewick 2011]: Sedgewick, R., & Wayne, K. (2011). *Algorithms* (4th ed.). Addison-Wesley. ISBN: 978-0321573513
- [Knuth 1998]: Knuth, D. E. (1998). *The Art of Computer Programming, Volume 3: Sorting and Searching* (2nd ed.). Addison-Wesley. ISBN: 978-0201896855

**Wikiæ¦‚å¿µå¯¹é½ / Wiki Concept Alignment:**

- [Sorting Algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm) - æ’åºç®—æ³•çš„æ ‡å‡†å®šä¹‰
- [Comparison Sort](https://en.wikipedia.org/wiki/Comparison_sort) - æ¯”è¾ƒæ’åº
- [Stable Sort](https://en.wikipedia.org/wiki/Sorting_algorithm#Stability) - ç¨³å®šæ’åº
- [Quicksort](https://en.wikipedia.org/wiki/Quicksort) - å¿«é€Ÿæ’åº

**å¤§å­¦è¯¾ç¨‹å¯¹æ ‡ / University Course Alignment:**

- MIT 6.006: Introduction to Algorithms - æ’åºç®—æ³•åŸºç¡€
- Stanford CS161: Design and Analysis of Algorithms - æ’åºç®—æ³•è®¾è®¡ä¸åˆ†æ
- CMU 15-451: Algorithm Design and Analysis - é«˜çº§æ’åºç®—æ³•æŠ€æœ¯

## 1. åŸºæœ¬æ¦‚å¿µ / Basic Concepts

### 1.1 æ’åºé—®é¢˜å®šä¹‰ / Sorting Problem Definition

**å®šä¹‰ 1.1.1** (æ’åºé—®é¢˜) [Cormen 2022, Wikipedia Sorting Algorithm]
æ’åºé—®é¢˜æ˜¯å°†åºåˆ— $S = (a_1, a_2, \ldots, a_n)$ é‡æ–°æ’åˆ—ä¸ºæœ‰åºåºåˆ— $S' = (a_{i_1}, a_{i_2}, \ldots, a_{i_n})$ï¼Œä½¿å¾—ï¼š
**Definition 1.1.1** (Sorting Problem) [Cormen 2022, Wikipedia Sorting Algorithm]
The sorting problem is to rearrange a sequence $S = (a_1, a_2, \ldots, a_n)$ into an ordered sequence $S' = (a_{i_1}, a_{i_2}, \ldots, a_{i_n})$ such that:
$$a_{i_1} \leq a_{i_2} \leq \ldots \leq a_{i_n}$$

**Wikiæ¦‚å¿µå¯¹é½ / Wiki Concept Alignment:**

| é¡¹ç›®æ¦‚å¿µ | Wikiæ¡ç›® | æ ‡å‡†å®šä¹‰ | å¯¹é½çŠ¶æ€ |
|---------|---------|---------|---------|
| æ’åºç®—æ³• | [Sorting Algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm) | å°†åºåˆ—æ’åˆ—ä¸ºæœ‰åºçš„ç®—æ³• | âœ… å·²å¯¹é½ |
| æ¯”è¾ƒæ’åº | [Comparison Sort](https://en.wikipedia.org/wiki/Comparison_sort) | é€šè¿‡æ¯”è¾ƒå…ƒç´ æ’åºçš„ç®—æ³• | âœ… å·²å¯¹é½ |
| ç¨³å®šæ’åº | [Stable Sort](https://en.wikipedia.org/wiki/Sorting_algorithm#Stability) | ä¿æŒç›¸ç­‰å…ƒç´ ç›¸å¯¹é¡ºåºçš„æ’åº | âœ… å·²å¯¹é½ |
| å¿«é€Ÿæ’åº | [Quicksort](https://en.wikipedia.org/wiki/Quicksort) | åˆ†æ²»æ€æƒ³çš„æ’åºç®—æ³• | âœ… å·²å¯¹é½ |

**æ’åºç®—æ³•çŸ¥è¯†ä½“ç³» / Sorting Algorithm Knowledge System:**

```mermaid
mindmap
  root((æ’åºç®—æ³•<br/>Sorting Algorithm))
    åŸºæœ¬æ¦‚å¿µ
      æ’åºé—®é¢˜å®šä¹‰
        è¾“å…¥è¾“å‡º
        æœ‰åºæ€§
      æ’åºæ€§è´¨
        ç¨³å®šæ€§
        é€‚åº”æ€§
        åŸåœ°æ€§
      ç®—æ³•åˆ†ç±»
        æ¯”è¾ƒæ’åº
        éæ¯”è¾ƒæ’åº
    æ¯”è¾ƒæ’åº
      ç®€å•æ’åº
        å†’æ³¡æ’åº
        é€‰æ‹©æ’åº
        æ’å…¥æ’åº
      é«˜æ•ˆæ’åº
        å½’å¹¶æ’åº
        å¿«é€Ÿæ’åº
        å †æ’åº
      å¤æ‚åº¦
        å¹³å‡æƒ…å†µ
        æœ€åæƒ…å†µ
        æœ€å¥½æƒ…å†µ
    éæ¯”è¾ƒæ’åº
      è®¡æ•°æ’åº
        æ•´æ•°æ’åº
        çº¿æ€§æ—¶é—´
      åŸºæ•°æ’åº
        å¤šå…³é”®å­—
        ç¨³å®šæ’åº
      æ¡¶æ’åº
        å‡åŒ€åˆ†å¸ƒ
        çº¿æ€§æ—¶é—´
    æ’åºä¸‹ç•Œ
      æ¯”è¾ƒæ’åºä¸‹ç•Œ
        å†³ç­–æ ‘æ¨¡å‹
        Î©(n log n)
      ä¿¡æ¯è®ºä¸‹ç•Œ
        ç†µç†è®º
        ä¸‹ç•Œè¯æ˜
      è‡ªé€‚åº”æ’åº
        éƒ¨åˆ†æœ‰åº
        ä¼˜åŒ–ç­–ç•¥
    å¤–éƒ¨æ’åº
      å¤šè·¯å½’å¹¶
        å¤–éƒ¨å­˜å‚¨
        I/Oä¼˜åŒ–
      æ›¿æ¢é€‰æ‹©
        ç¼“å†²åŒºç®¡ç†
        è¿è¡Œç”Ÿæˆ
    åº”ç”¨é¢†åŸŸ
      æ•°æ®åº“
        ç´¢å¼•æ’åº
        æŸ¥è¯¢ä¼˜åŒ–
      æ“ä½œç³»ç»Ÿ
        æ–‡ä»¶ç³»ç»Ÿ
        è¿›ç¨‹è°ƒåº¦
      ç®—æ³•åŸºç¡€
        å…¶ä»–ç®—æ³•
        æ•°æ®ç»“æ„
```

**æ’åºç®—æ³•å¤æ‚åº¦å¯¹æ¯” / Sorting Algorithm Complexity Comparison:**

| ç®—æ³• | å¹³å‡æ—¶é—´å¤æ‚åº¦ | æœ€åæ—¶é—´å¤æ‚åº¦ | æœ€å¥½æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç¨³å®šæ€§ | å‚è€ƒæ–‡çŒ® |
|------|--------------|--------------|--------------|-----------|--------|---------|
| å†’æ³¡æ’åº | $O(n^2)$ | $O(n^2)$ | $O(n)$ | $O(1)$ | âœ… | [Cormen 2022] |
| é€‰æ‹©æ’åº | $O(n^2)$ | $O(n^2)$ | $O(n^2)$ | $O(1)$ | âŒ | [Cormen 2022] |
| æ’å…¥æ’åº | $O(n^2)$ | $O(n^2)$ | $O(n)$ | $O(1)$ | âœ… | [Cormen 2022] |
| å½’å¹¶æ’åº | $O(n \log n)$ | $O(n \log n)$ | $O(n \log n)$ | $O(n)$ | âœ… | [Cormen 2022] |
| å¿«é€Ÿæ’åº | $O(n \log n)$ | $O(n^2)$ | $O(n \log n)$ | $O(\log n)$ | âŒ | [Cormen 2022] |
| å †æ’åº | $O(n \log n)$ | $O(n \log n)$ | $O(n \log n)$ | $O(1)$ | âŒ | [Cormen 2022] |
| è®¡æ•°æ’åº | $O(n + k)$ | $O(n + k)$ | $O(n + k)$ | $O(k)$ | âœ… | [Cormen 2022] |
| åŸºæ•°æ’åº | $O(d(n + k))$ | $O(d(n + k))$ | $O(d(n + k))$ | $O(n + k)$ | âœ… | [Cormen 2022] |
| æ¡¶æ’åº | $O(n + k)$ | $O(n^2)$ | $O(n + k)$ | $O(n + k)$ | âœ… | [Cormen 2022] |

*æ³¨ï¼š$k$ ä¸ºæ•°æ®èŒƒå›´ï¼Œ$d$ ä¸ºä½æ•°*

**å®šä¹‰ 1.1.2** æ’åºç®—æ³•çš„ç¨³å®šæ€§ï¼š
**Definition 1.1.2** Stability of sorting algorithms:
å¦‚æœå¯¹äºç›¸ç­‰çš„å…ƒç´  $a_i = a_j$ï¼Œæ’åºå $a_i$ ä»ç„¶åœ¨ $a_j$ ä¹‹å‰ï¼Œåˆ™ç§°æ’åºç®—æ³•æ˜¯ç¨³å®šçš„ã€‚
If for equal elements $a_i = a_j$, after sorting $a_i$ still comes before $a_j$, then the sorting algorithm is said to be stable.

**å®šä¹‰ 1.1.3** æ’åºç®—æ³•çš„é€‚åº”æ€§ï¼š
**Definition 1.1.3** Adaptivity of sorting algorithms:
å¦‚æœç®—æ³•å¯¹å·²éƒ¨åˆ†æ’åºçš„è¾“å…¥è¡¨ç°æ›´å¥½ï¼Œåˆ™ç§°ç®—æ³•æ˜¯è‡ªé€‚åº”çš„ã€‚
If an algorithm performs better on partially sorted inputs, then the algorithm is said to be adaptive.

### 1.2 æ’åºç®—æ³•åˆ†ç±» / Sorting Algorithm Classification

**å®šä¹‰ 1.2.1** æŒ‰æ¯”è¾ƒæ–¹å¼åˆ†ç±»ï¼š
**Definition 1.2.1** Classification by comparison method:

1. **æ¯”è¾ƒæ’åº / Comparison Sorting**ï¼šé€šè¿‡æ¯”è¾ƒå…ƒç´ ç¡®å®šç›¸å¯¹é¡ºåº / Determine relative order by comparing elements
2. **éæ¯”è¾ƒæ’åº / Non-Comparison Sorting**ï¼šä¸é€šè¿‡æ¯”è¾ƒç¡®å®šé¡ºåº / Determine order without comparison

**å®šä¹‰ 1.2.2** æŒ‰ç©ºé—´å¤æ‚åº¦åˆ†ç±»ï¼š
**Definition 1.2.2** Classification by space complexity:

1. **åŸåœ°æ’åº / In-Place Sorting**ï¼šç©ºé—´å¤æ‚åº¦ä¸º $O(1)$ / Space complexity is $O(1)$
2. **éåŸåœ°æ’åº / Non-In-Place Sorting**ï¼šéœ€è¦é¢å¤–ç©ºé—´ / Requires additional space

**å®šä¹‰ 1.2.3** æŒ‰æ—¶é—´å¤æ‚åº¦åˆ†ç±»ï¼š
**Definition 1.2.3** Classification by time complexity:

1. **$O(n^2)$ æ’åº**ï¼šå†’æ³¡æ’åºã€é€‰æ‹©æ’åºã€æ’å…¥æ’åº / Bubble sort, selection sort, insertion sort
2. **$O(n \log n)$ æ’åº**ï¼šå½’å¹¶æ’åºã€å¿«é€Ÿæ’åºã€å †æ’åº / Merge sort, quick sort, heap sort
3. **$O(n)$ æ’åº**ï¼šè®¡æ•°æ’åºã€åŸºæ•°æ’åºã€æ¡¶æ’åº / Counting sort, radix sort, bucket sort

### 1.4 å†…å®¹è¡¥å……ä¸æ€ç»´è¡¨å¾ / Content Supplement and Thinking Representation

> æœ¬èŠ‚æŒ‰ [å†…å®¹è¡¥å……ä¸æ€ç»´è¡¨å¾å…¨é¢è®¡åˆ’æ–¹æ¡ˆ](../../å†…å®¹è¡¥å……ä¸æ€ç»´è¡¨å¾å…¨é¢è®¡åˆ’æ–¹æ¡ˆ.md) **åªè¡¥å……ã€ä¸åˆ é™¤**ã€‚æ ‡å‡†è§ [å†…å®¹è¡¥å……æ ‡å‡†](../../å†…å®¹è¡¥å……æ ‡å‡†-æ¦‚å¿µå®šä¹‰å±æ€§å…³ç³»è§£é‡Šè®ºè¯å½¢å¼è¯æ˜.md)ã€[æ€ç»´è¡¨å¾æ¨¡æ¿é›†](../../æ€ç»´è¡¨å¾æ¨¡æ¿é›†.md)ã€‚

#### è§£é‡Šä¸ç›´è§‚ / Explanation and Intuition

æ’åºç†è®ºå°†é—®é¢˜å½¢å¼åŒ–ä¸ºåºåˆ—é‡æ’æ»¡è¶³æœ‰åºæ€§ï¼ˆå®šä¹‰ 1.1.1ï¼‰ã€‚æ¯”è¾ƒæ’åºä¸‹ç•Œ $\Omega(n\log n)$ï¼ˆå†³ç­–æ ‘/ä¿¡æ¯è®ºï¼‰ã€ç¨³å®šæ€§ä¸åŸåœ°æ€§ã€æ¯”è¾ƒ vs éæ¯”è¾ƒæ’åºæ„æˆé€‰å‹ç»´åº¦ï¼Œä¸ 04-å¤æ‚åº¦ã€09-01-01 ç®—æ³•è®¾è®¡èŒƒå¼è¡”æ¥ã€‚ç›´è§‚ä¸Šï¼šæ¯”è¾ƒæ’åºä¾èµ–ä¸¤ä¸¤æ¯”è¾ƒï¼Œä¿¡æ¯è®ºç»™å‡ºä¸‹ç•Œï¼›éæ¯”è¾ƒæ’åºåˆ©ç”¨é”®èŒƒå›´æˆ–ä½æ•°ï¼Œåœ¨é™å®šæ¡ä»¶ä¸‹å¯è¾¾ $O(n)$ã€‚

#### æ¦‚å¿µå±æ€§è¡¨ / Concept Attribute Table

| å±æ€§å | ç±»å‹/èŒƒå›´ | å«ä¹‰ | å¤‡æ³¨ |
|--------|-----------|------|------|
| æœ‰åºæ€§ | äºŒå…ƒå…³ç³» | åºåˆ—æ»¡è¶³ $\forall i<j \Rightarrow A[i]\le A[j]$ï¼ˆéé™ï¼‰ | å®šä¹‰ 1.1.1 |
| ç¨³å®šæ€§ | å¸ƒå°” | ç›¸ç­‰é”®ç›¸å¯¹é¡ºåºä¸å˜ | å®šä¹‰ 1.1.2ï¼›å½’å¹¶/æ’å…¥/è®¡æ•°ç¨³å®š |
| é€‚åº”æ€§ | å¸ƒå°” | å¯¹å·²åº/è¿‘ä¼¼åºè¾“å…¥æ—¶é—´æ›´ä¼˜ | å®šä¹‰ 1.1.3ï¼›æ’å…¥æ’åº $O(n)$ |
| æ¯”è¾ƒ/éæ¯”è¾ƒ | åˆ†ç±» | æ˜¯å¦ä»…ç”¨æ¯”è¾ƒè¿ç®— | Â§1.2ï¼›æ¯”è¾ƒä¸‹ç•Œ $\Omega(n\log n)$ |
| åŸåœ°/éåŸåœ° | åˆ†ç±» | é¢å¤–ç©ºé—´ $O(1)$ æˆ– $\Theta(n)$ | å¿«æ’/å †åŸåœ°ï¼Œå½’å¹¶éåŸåœ° |
| æ—¶é—´å¤æ‚åº¦ | æ¸è¿› | å‡æ‘Š/æœ€å/æœ€å¥½ | è§ Â§2 å„ç®—æ³•å®šç† |

#### æ¦‚å¿µå…³ç³» / Concept Relations

| æºæ¦‚å¿µ | ç›®æ ‡æ¦‚å¿µ | å…³ç³»ç±»å‹ | è¯´æ˜ |
|--------|----------|----------|------|
| æ’åºç†è®º | 09-01-01 ç®—æ³•è®¾è®¡ | depends_on | åˆ†æ²»/è´ªå¿ƒç­‰èŒƒå¼ |
| æ’åºç†è®º | 04-ç®—æ³•å¤æ‚åº¦ | depends_on | æ—¶é—´/ç©ºé—´åˆ†æ |
| æ’åºç†è®º | 02-æ•°æ®ç»“æ„ | depends_on | æ•°ç»„/é“¾è¡¨/å †ç­‰ |
| æ¯”è¾ƒæ’åºä¸‹ç•Œ | 04-ä¿¡æ¯è®º | applies_to | å†³ç­–æ ‘é«˜åº¦ $\ge n!\Rightarrow \Omega(n\log n)$ |
| æ’åºç†è®º | 09-03-02 å¹¶è¡Œç®—æ³• | applies_to | å¹¶è¡Œæ’åºã€å¤šè·¯å½’å¹¶ |

#### æ¦‚å¿µä¾èµ–å›¾ / Concept Dependency Graph

```mermaid
graph LR
  Def[æ’åºé—®é¢˜å®šä¹‰ 1.1.1]
  Stable[ç¨³å®šæ€§/é€‚åº”æ€§ 1.1.2-1.1.3]
  Class[æ¯”è¾ƒ/éæ¯”è¾ƒåˆ†ç±»]
  LB[æ¯”è¾ƒä¸‹ç•Œ Î©nlog n]
  Linear[çº¿æ€§éæ¯”è¾ƒ Â§2]
  Def --> Stable
  Def --> Class
  Class --> LB
  Class --> Linear
```

#### è®ºè¯ä¸è¯æ˜è¡”æ¥ / Argumentation and Proof Link

å®šä¹‰ 1.1.1â€“1.2.3 å½¢å¼åŒ–æœ‰åºæ€§ã€ç¨³å®šæ€§ä¸åˆ†ç±»ï¼›æ¯”è¾ƒæ’åºä¸‹ç•Œï¼ˆå†³ç­–æ ‘å¶å­ $\ge n!$ï¼Œé«˜åº¦ $\ge \log_2(n!)=\Omega(n\log n)$ï¼‰è§ 04-ä¿¡æ¯è®ºä¸‹ç•Œï¼›å„ç®—æ³•æ­£ç¡®æ€§ï¼ˆå¾ªç¯ä¸å˜å¼/å½’çº³ï¼‰ä¸å¤æ‚åº¦è§ Â§2 å®šç†ä¸è¯æ˜æ®µè½ã€‚

#### æ€ç»´å¯¼å›¾ï¼šæœ¬ç« æ¦‚å¿µç»“æ„ / Mind Map

```mermaid
graph TD
  Sort[æ’åºç†è®º]
  Sort --> Comp[æ¯”è¾ƒæ’åº]
  Sort --> NonComp[éæ¯”è¾ƒæ’åº]
  Sort --> LB[ä¸‹ç•Œä¸è‡ªé€‚åº”]
  Sort --> Ext[å¤–éƒ¨æ’åº]
  Sort --> App[åº”ç”¨]
  Comp --> Simple[ç®€å• O(nÂ²)]
  Comp --> Fast[é«˜æ•ˆ O(n log n)]
  NonComp --> Count[è®¡æ•°/åŸºæ•°/æ¡¶]
  App --> DB[æ•°æ®åº“/OS]
```

#### å¤šç»´çŸ©é˜µï¼šæ’åºç®—æ³•å¯¹æ¯” / Multi-Dimensional Comparison

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦(å‡/æœ€å) | ç©ºé—´å¤æ‚åº¦ | ç¨³å®šæ€§ | é€‚ç”¨åœºæ™¯ |
|------|---------------------|------------|--------|----------|
| å†’æ³¡/é€‰æ‹©/æ’å…¥ | $\Theta(n^2)$ | $O(1)$ | æ’å…¥ç¨³å®š | å°è§„æ¨¡ã€æ•™å­¦ |
| å½’å¹¶æ’åº | $\Theta(n\log n)$ | $\Theta(n)$ | ç¨³å®š | é€šç”¨ã€å¤–éƒ¨ |
| å¿«é€Ÿæ’åº | æœŸæœ› $\Theta(n\log n)$ / $O(n^2)$ | $\Theta(\log n)$ | ä¸ç¨³å®š | å†…æ’åºã€å¹³å‡æœ€å¿« |
| å †æ’åº | $\Theta(n\log n)$ | $O(1)$ | ä¸ç¨³å®š | ä¼˜å…ˆé˜Ÿåˆ—ã€åŸåœ° |
| è®¡æ•°/åŸºæ•°/æ¡¶ | $O(n+k)$ ç­‰ | $O(n+k)$ ç­‰ | å¯ç¨³å®š | æ•´æ•°/å¤šå…³é”®å­—ã€èŒƒå›´å° |

#### å†³ç­–æ ‘ï¼šæ’åºç®—æ³•é€‰æ‹© / Decision Tree

```mermaid
flowchart TD
  S([éœ€è¦æ’åº])
  S --> Stable{æ˜¯å¦è¦æ±‚ç¨³å®š?}
  Stable -->|æ˜¯| Large1{æ•°æ®è§„æ¨¡å¤§?}
  Stable -->|å¦| Perf{å¹³å‡æ€§èƒ½ä¼˜å…ˆ?}
  Large1 -->|æ˜¯| M[å½’å¹¶æ’åº]
  Large1 -->|å¦| I[æ’å…¥/å½’å¹¶]
  Perf -->|æ˜¯| Q[å¿«é€Ÿæ’åº]
  Perf -->|å¦| H[å †æ’åº]
  S --> Int{æ•´æ•°/èŒƒå›´å°?}
  Int -->|æ˜¯| C[è®¡æ•°/åŸºæ•°/æ¡¶]
```

#### å…¬ç†å®šç†æ¨ç†è¯æ˜å†³ç­–æ ‘ / Axiom-Theorem-Proof Tree

```mermaid
graph LR
  D111[å®šä¹‰ 1.1.1 æœ‰åºæ€§]
  D112[å®šä¹‰ 1.1.2 ç¨³å®šæ€§]
  D113[å®šä¹‰ 1.1.3 é€‚åº”æ€§]
  D111 --> T[æ¯”è¾ƒä¸‹ç•Œ Î©nlog n]
  Info[ä¿¡æ¯è®º/å†³ç­–æ ‘]
  Info --> T
  D112 --> Correct[å„ç®—æ³•æ­£ç¡®æ€§ Â§2]
  D113 --> Correct
```

#### åº”ç”¨å†³ç­–å»ºæ¨¡æ ‘ / Application Decision Modeling Tree

```mermaid
flowchart TD
  Need([éœ€æ±‚ï¼šæ’åº])
  Need --> Gen{é€šç”¨å†…æ’åº?}
  Gen -->|æ˜¯| QM[å¿«æ’/å½’å¹¶/å †]
  Need --> Small{å°è§„æ¨¡/è¿‘ä¼¼æœ‰åº?}
  Small -->|æ˜¯| Ins[æ’å…¥æ’åº]
  Need --> Int{æ•´æ•°/å¤šå…³é”®å­—?}
  Int -->|æ˜¯| Count[è®¡æ•°/åŸºæ•°/æ¡¶]
  Need --> Ext{å¤–éƒ¨?}
  Ext -->|æ˜¯| Merge[å¤šè·¯å½’å¹¶]
```

---

## 2. æ¯”è¾ƒæ’åº / Comparison Sorting

### 2.1 å†’æ³¡æ’åº / Bubble Sort

**å®šä¹‰ 2.1.1** å†’æ³¡æ’åºé€šè¿‡é‡å¤éå†åºåˆ—ï¼Œæ¯”è¾ƒç›¸é‚»å…ƒç´ å¹¶äº¤æ¢ã€‚
**Definition 2.1.1** Bubble sort repeatedly traverses the sequence, comparing adjacent elements and swapping them.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
BubbleSort(A):
    for i = 1 to n-1:
        for j = 1 to n-i:
            if A[j] > A[j+1]:
                swap(A[j], A[j+1])
```

**å®šç† 2.1.1** å†’æ³¡æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ã€‚
**Theorem 2.1.1** The time complexity of bubble sort is $O(n^2)$.

**è¯æ˜ / Proof:**

- å¤–å±‚å¾ªç¯æ‰§è¡Œ $n-1$ æ¬¡ / Outer loop executes $n-1$ times
- å†…å±‚å¾ªç¯æ‰§è¡Œ $n-i$ æ¬¡ / Inner loop executes $n-i$ times
- æ€»æ¯”è¾ƒæ¬¡æ•°ï¼š$\sum_{i=1}^{n-1} (n-i) = \frac{n(n-1)}{2} = O(n^2)$ / Total comparisons: $\sum_{i=1}^{n-1} (n-i) = \frac{n(n-1)}{2} = O(n^2)$

### 2.2 é€‰æ‹©æ’åº / Selection Sort

**å®šä¹‰ 2.2.1** é€‰æ‹©æ’åºæ¯æ¬¡é€‰æ‹©æœªæ’åºéƒ¨åˆ†çš„æœ€å°å…ƒç´ æ”¾åˆ°å·²æ’åºéƒ¨åˆ†çš„æœ«å°¾ã€‚
**Definition 2.2.1** Selection sort selects the minimum element from the unsorted part and places it at the end of the sorted part each time.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
SelectionSort(A):
    for i = 1 to n-1:
        min_idx = i
        for j = i+1 to n:
            if A[j] < A[min_idx]:
                min_idx = j
        swap(A[i], A[min_idx])
```

**å®šç† 2.2.1** é€‰æ‹©æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(1)$ã€‚
**Theorem 2.2.1** The time complexity of selection sort is $O(n^2)$ and space complexity is $O(1)$.

### 2.3 æ’å…¥æ’åº / Insertion Sort

**å®šä¹‰ 2.3.1** æ’å…¥æ’åºå°†æ¯ä¸ªå…ƒç´ æ’å…¥åˆ°å·²æ’åºéƒ¨åˆ†çš„æ­£ç¡®ä½ç½®ã€‚
**Definition 2.3.1** Insertion sort inserts each element into the correct position in the sorted part.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
InsertionSort(A):
    for i = 2 to n:
        key = A[i]
        j = i - 1
        while j > 0 and A[j] > key:
            A[j+1] = A[j]
            j = j - 1
        A[j+1] = key
```

**å®šç† 2.3.1** æ’å…¥æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œä½†å¯¹äºå·²æ’åºçš„è¾“å…¥ä¸º $O(n)$ã€‚
**Theorem 2.3.1** The time complexity of insertion sort is $O(n^2)$, but for sorted input it is $O(n)$.

### 2.4 å½’å¹¶æ’åº / Merge Sort

**å®šä¹‰ 2.4.1** å½’å¹¶æ’åºä½¿ç”¨åˆ†æ²»ç­–ç•¥ï¼Œå°†åºåˆ—åˆ†æˆä¸¤åŠï¼Œåˆ†åˆ«æ’åºååˆå¹¶ã€‚
**Definition 2.4.1** Merge sort uses the divide-and-conquer strategy, dividing the sequence into two halves, sorting them separately, and then merging.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
MergeSort(A, left, right):
    if left < right:
        mid = (left + right) / 2
        MergeSort(A, left, mid)
        MergeSort(A, mid+1, right)
        Merge(A, left, mid, right)
```

**å®šç† 2.4.1** å½’å¹¶æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n \log n)$ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(n)$ã€‚
**Theorem 2.4.1** The time complexity of merge sort is $O(n \log n)$ and space complexity is $O(n)$.

**ä¸¥æ ¼æ•°å­¦æ¨å¯¼ / Rigorous Mathematical Derivation:**

è®¾ $T(n)$ ä¸ºå½’å¹¶æ’åºé•¿åº¦ä¸º $n$ çš„æ•°ç»„çš„æ—¶é—´å¤æ‚åº¦ã€‚
Let $T(n)$ be the time complexity of merge sort for an array of length $n$.

**é€’å½’å…³ç³» / Recurrence Relation:**
$$
T(n) = \begin{cases}
\Theta(1) & \text{if } n \leq 1 \\
2T(n/2) + \Theta(n) & \text{if } n > 1
\end{cases}
$$

**æ–¹æ³•1ï¼šé€’å½’æ ‘æ³• / Method 1: Recursion Tree Method**

é€’å½’æ ‘çš„é«˜åº¦ä¸º $\log_2 n$ï¼ˆå‡è®¾ $n$ æ˜¯2çš„å¹‚ï¼‰ã€‚
The height of the recursion tree is $\log_2 n$ (assuming $n$ is a power of 2).

- **ç¬¬0å±‚**ï¼š1ä¸ªå­é—®é¢˜ï¼Œå¤§å°ä¸º $n$ï¼Œåˆå¹¶æ—¶é—´ $\Theta(n)$
- **ç¬¬1å±‚**ï¼š2ä¸ªå­é—®é¢˜ï¼Œæ¯ä¸ªå¤§å°ä¸º $n/2$ï¼Œåˆå¹¶æ—¶é—´ $\Theta(n)$
- **ç¬¬2å±‚**ï¼š4ä¸ªå­é—®é¢˜ï¼Œæ¯ä¸ªå¤§å°ä¸º $n/4$ï¼Œåˆå¹¶æ—¶é—´ $\Theta(n)$
- ...
- **ç¬¬ $\log_2 n$ å±‚**ï¼š$n$ ä¸ªå­é—®é¢˜ï¼Œæ¯ä¸ªå¤§å°ä¸º 1ï¼Œåˆå¹¶æ—¶é—´ $\Theta(n)$

**Level 0**: 1 subproblem of size $n$, merge time $\Theta(n)$
**Level 1**: 2 subproblems of size $n/2$, merge time $\Theta(n)$
**Level 2**: 4 subproblems of size $n/4$, merge time $\Theta(n)$
...
**Level $\log_2 n$**: $n$ subproblems of size 1, merge time $\Theta(n)$

æ¯å±‚çš„æ€»åˆå¹¶æ—¶é—´éƒ½æ˜¯ $\Theta(n)$ï¼Œå…±æœ‰ $\log_2 n + 1$ å±‚ã€‚
The total merge time at each level is $\Theta(n)$, and there are $\log_2 n + 1$ levels.

å› æ­¤ï¼š$T(n) = \Theta(n \log n)$
Therefore: $T(n) = \Theta(n \log n)$

**æ–¹æ³•2ï¼šä¸»å®šç†æ³• / Method 2: Master Theorem**

å¯¹äºé€’å½’å…³ç³» $T(n) = aT(n/b) + f(n)$ï¼Œå…¶ä¸­ï¼š
For the recurrence $T(n) = aT(n/b) + f(n)$, where:

- $a = 2$ï¼ˆå­é—®é¢˜æ•°é‡ / number of subproblemsï¼‰
- $b = 2$ï¼ˆå­é—®é¢˜å¤§å°æ¯”ä¾‹ / subproblem size ratioï¼‰
- $f(n) = \Theta(n)$ï¼ˆåˆå¹¶æ—¶é—´ / merge timeï¼‰

è®¡ç®— $n^{\log_b a} = n^{\log_2 2} = n$
Compute $n^{\log_b a} = n^{\log_2 2} = n$

ç”±äº $f(n) = \Theta(n) = \Theta(n^{\log_b a})$ï¼Œå±äºä¸»å®šç†æƒ…å†µ2ã€‚
Since $f(n) = \Theta(n) = \Theta(n^{\log_b a})$, this is case 2 of the master theorem.

å› æ­¤ï¼š$T(n) = \Theta(n^{\log_b a} \log n) = \Theta(n \log n)$
Therefore: $T(n) = \Theta(n^{\log_b a} \log n) = \Theta(n \log n)$

**æ–¹æ³•3ï¼šå±•å¼€æ³• / Method 3: Substitution Method**

å‡è®¾ $T(n) = cn \log n$ï¼ˆå…¶ä¸­ $c$ ä¸ºå¸¸æ•°ï¼‰ã€‚
Assume $T(n) = cn \log n$ (where $c$ is a constant).

**å½’çº³è¯æ˜ / Inductive Proof:**

**åŸºç¡€æƒ…å†µ / Base Case**: $T(1) = c \cdot 1 \cdot \log 1 = 0 = \Theta(1)$ âœ“

**å½’çº³å‡è®¾ / Inductive Hypothesis**: å‡è®¾å¯¹äºæ‰€æœ‰ $k < n$ï¼Œ$T(k) \leq ck \log k$
Assume for all $k < n$, $T(k) \leq ck \log k$

**å½’çº³æ­¥éª¤ / Inductive Step**:
$$T(n) = 2T(n/2) + \Theta(n)$$
$$\leq 2c(n/2)\log(n/2) + dn$$
$$= cn(\log n - 1) + dn$$
$$= cn \log n - cn + dn$$
$$= cn \log n + n(d - c)$$

é€‰æ‹© $c \geq d$ï¼Œåˆ™ $T(n) \leq cn \log n$ã€‚
Choose $c \geq d$, then $T(n) \leq cn \log n$.

å› æ­¤ $T(n) = O(n \log n)$ã€‚ç±»ä¼¼å¯è¯ $T(n) = \Omega(n \log n)$ã€‚
Therefore $T(n) = O(n \log n)$. Similarly, we can prove $T(n) = \Omega(n \log n)$.

**ç©ºé—´å¤æ‚åº¦åˆ†æ / Space Complexity Analysis:**

å½’å¹¶æ’åºéœ€è¦é¢å¤–çš„è¾…åŠ©æ•°ç»„æ¥å­˜å‚¨åˆå¹¶ç»“æœã€‚
Merge sort requires an additional auxiliary array to store merge results.

- **é€’å½’è°ƒç”¨æ ˆæ·±åº¦**ï¼š$\Theta(\log n)$
- **è¾…åŠ©æ•°ç»„å¤§å°**ï¼š$\Theta(n)$
- **æ€»ç©ºé—´å¤æ‚åº¦**ï¼š$\Theta(n)$

**Recursion stack depth**: $\Theta(\log n)$
**Auxiliary array size**: $\Theta(n)$
**Total space complexity**: $\Theta(n)$

**å®šç† 2.4.2** (å½’å¹¶æ’åºæ­£ç¡®æ€§å®šç†) å½’å¹¶æ’åºç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ’åºä»»æ„è¾“å…¥æ•°ç»„ã€‚
**Theorem 2.4.2** (Merge Sort Correctness Theorem) The merge sort algorithm correctly sorts any input array.

**å½¢å¼åŒ–æ­£ç¡®æ€§è¯æ˜ / Formal Correctness Proof:**

**å‰ç½®æ¡ä»¶ / Precondition**: è¾“å…¥æ•°ç»„ $A[1..n]$
**Input array**: $A[1..n]$

**åç½®æ¡ä»¶ / Postcondition**: è¾“å‡ºæ•°ç»„ $A'[1..n]$ æ»¡è¶³ï¼š
**Output array**: $A'[1..n]$ satisfies:

1. **æœ‰åºæ€§ / Ordering**: $\forall i \in [1, n-1]: A'[i] \leq A'[i+1]$
2. **æ’åˆ—æ€§ / Permutation**: $A'$ æ˜¯ $A$ çš„ä¸€ä¸ªæ’åˆ—

**è¯æ˜æ–¹æ³•ï¼šå¼ºå½’çº³æ³• / Proof Method: Strong Induction**

**åŸºç¡€æƒ…å†µ / Base Case**: $n \leq 1$

- æ•°ç»„å·²æœ‰åºï¼Œç®—æ³•ç›´æ¥è¿”å›ï¼Œæ­£ç¡®æ€§æ˜¾ç„¶ã€‚
- Array is already sorted, algorithm returns directly, correctness is obvious.

**å½’çº³å‡è®¾ / Inductive Hypothesis**:
å‡è®¾å¯¹äºæ‰€æœ‰ $k < n$ï¼Œå½’å¹¶æ’åºèƒ½å¤Ÿæ­£ç¡®æ’åºé•¿åº¦ä¸º $k$ çš„æ•°ç»„ã€‚
Assume for all $k < n$, merge sort correctly sorts arrays of length $k$.

**å½’çº³æ­¥éª¤ / Inductive Step**: $n > 1$

1. **åˆ†è§£ / Divide**: å°†æ•°ç»„åˆ†ä¸ºä¸¤åŠ $A[1..\lfloor n/2 \rfloor]$ å’Œ $A[\lfloor n/2 \rfloor+1..n]$
   Divide array into two halves $A[1..\lfloor n/2 \rfloor]$ and $A[\lfloor n/2 \rfloor+1..n]$

2. **è§£å†³ / Conquer**:
   - æ ¹æ®å½’çº³å‡è®¾ï¼Œé€’å½’æ’åºå·¦åŠéƒ¨åˆ†å¾—åˆ° $L[1..\lfloor n/2 \rfloor]$ï¼ˆæœ‰åºï¼‰
   - æ ¹æ®å½’çº³å‡è®¾ï¼Œé€’å½’æ’åºå³åŠéƒ¨åˆ†å¾—åˆ° $R[1..\lceil n/2 \rceil]$ï¼ˆæœ‰åºï¼‰

   By inductive hypothesis, recursively sort left half to get $L[1..\lfloor n/2 \rfloor]$ (sorted)
   By inductive hypothesis, recursively sort right half to get $R[1..\lceil n/2 \rceil]$ (sorted)

3. **åˆå¹¶ / Combine**:
   åˆå¹¶ä¸¤ä¸ªæœ‰åºæ•°ç»„ $L$ å’Œ $R$ å¾—åˆ° $A'[1..n]$
   Merge two sorted arrays $L$ and $R$ to get $A'[1..n]$

**åˆå¹¶è¿‡ç¨‹æ­£ç¡®æ€§ / Merge Process Correctness:**

è®¾åˆå¹¶å‡½æ•° $Merge(L, R)$ çš„æ­£ç¡®æ€§å·²è¯æ˜ï¼ˆå¯é€šè¿‡å¾ªç¯ä¸å˜å¼è¯æ˜ï¼‰ã€‚
Assume the correctness of merge function $Merge(L, R)$ is proven (can be proven using loop invariant).

**å¾ªç¯ä¸å˜å¼ / Loop Invariant**:
åœ¨åˆå¹¶è¿‡ç¨‹çš„æ¯ä¸€æ­¥ï¼Œè¾“å‡ºæ•°ç»„çš„å‰ $k$ ä¸ªå…ƒç´ æ˜¯æœ‰åºçš„ï¼Œä¸”åŒ…å« $L$ å’Œ $R$ ä¸­æœ€å°çš„ $k$ ä¸ªå…ƒç´ ã€‚
At each step of the merge process, the first $k$ elements of the output array are sorted and contain the smallest $k$ elements from $L$ and $R$.

**ç»ˆæ­¢æ¡ä»¶ / Termination**:
å½“ $L$ å’Œ $R$ çš„æ‰€æœ‰å…ƒç´ éƒ½è¢«å¤„ç†å®Œæ—¶ï¼Œè¾“å‡ºæ•°ç»„åŒ…å«æ‰€æœ‰å…ƒç´ ä¸”æœ‰åºã€‚
When all elements of $L$ and $R$ are processed, the output array contains all elements and is sorted.

å› æ­¤ï¼Œ$A'[1..n]$ æ˜¯æœ‰åºçš„ï¼Œä¸”æ˜¯ $A$ çš„ä¸€ä¸ªæ’åˆ—ã€‚
Therefore, $A'[1..n]$ is sorted and is a permutation of $A$.

**å®šç† 2.4.3** (å½’å¹¶æ’åºç¨³å®šæ€§å®šç†) å½’å¹¶æ’åºæ˜¯ç¨³å®šçš„æ’åºç®—æ³•ã€‚
**Theorem 2.4.3** (Merge Sort Stability Theorem) Merge sort is a stable sorting algorithm.

**è¯æ˜ / Proof:**

å½’å¹¶æ’åºçš„ç¨³å®šæ€§ä¾èµ–äºåˆå¹¶è¿‡ç¨‹çš„ç¨³å®šæ€§ã€‚
The stability of merge sort depends on the stability of the merge process.

åœ¨åˆå¹¶ä¸¤ä¸ªæœ‰åºæ•°ç»„æ—¶ï¼Œå¦‚æœé‡åˆ°ç›¸ç­‰å…ƒç´ ï¼Œæˆ‘ä»¬æ€»æ˜¯å…ˆé€‰æ‹©å·¦æ•°ç»„ä¸­çš„å…ƒç´ ã€‚
When merging two sorted arrays, if equal elements are encountered, we always choose the element from the left array first.

è¿™ä¿è¯äº†ç›¸ç­‰å…ƒç´ çš„ç›¸å¯¹é¡ºåºä¸å˜ã€‚
This ensures that the relative order of equal elements is preserved.

**2024å¹´æœ€æ–°å½¢å¼åŒ–è¯æ˜æ–¹æ³• / Latest Formal Proof Method (2024):**

æ ¹æ® [Barbosa et al. 2024] çš„ç ”ç©¶ï¼Œå¯ä»¥ä½¿ç”¨**å…³ç³»å‚æ•°åŒ–ï¼ˆRelational Parametricityï¼‰**æ–¹æ³•ç»Ÿä¸€è¯æ˜å¤šç§å½’å¹¶æ’åºå˜ä½“çš„æ­£ç¡®æ€§å’Œç¨³å®šæ€§ã€‚
According to [Barbosa et al. 2024], we can use **Relational Parametricity** to uniformly prove the correctness and stability of multiple mergesort variants.

**æ ¸å¿ƒæ€æƒ³ / Core Idea:**
å¦‚æœå½’å¹¶å‡½æ•°æ»¡è¶³å…³ç³»å‚æ•°åŒ–æ€§è´¨ï¼Œåˆ™ç”¨è¿æ¥ï¼ˆconcatenationï¼‰æ›¿æ¢å½’å¹¶å‡½æ•°åå¾—åˆ°æ’ç­‰å‡½æ•°ï¼Œè¿™ç­‰ä»·äºå½’å¹¶æ’åºçš„æ­£ç¡®æ€§å’Œç¨³å®šæ€§ã€‚
If the merge function satisfies relational parametricity, replacing the merge function with concatenation yields the identity function, which is equivalent to the correctness and stability of merge sort.

**å½¢å¼åŒ–è¡¨è¿° / Formal Statement:**
$$\forall xs, \text{merge}(\text{sort}(xs_1), \text{sort}(xs_2)) = \text{sort}(xs_1 \mathbin{+\!\!+} xs_2)$$
å…¶ä¸­ $xs = xs_1 \mathbin{+\!\!+} xs_2$ ä¸” $\text{sort}(xs) = xs$ï¼ˆå½“ $xs$ å·²æ’åºæ—¶ï¼‰
where $xs = xs_1 \mathbin{+\!\!+} xs_2$ and $\text{sort}(xs) = xs$ (when $xs$ is sorted)

è¯¥æ–¹æ³•å·²åœ¨ Rocq Prover ä¸­éªŒè¯ï¼Œå¯ç»Ÿä¸€è¯æ˜å¤šç§å½’å¹¶æ’åºå˜ä½“ï¼ˆè‡ªä¸Šè€Œä¸‹ã€è‡ªä¸‹è€Œä¸Šã€å°¾é€’å½’ç­‰ï¼‰ã€‚
This method has been verified in Rocq Prover and can uniformly prove multiple mergesort variants (top-down, bottom-up, tail-recursive, etc.).

**å­¦æœ¯å¼•ç”¨ / Academic Citations:**

- [Barbosa et al. 2024]: Barbosa, M., et al. (2024). "A bargain for mergesorts -- How to prove your mergesort correct and stable, almost for free." arXiv:2403.08173

### 2.5 å¿«é€Ÿæ’åº / Quick Sort

**å®šä¹‰ 2.5.1** å¿«é€Ÿæ’åºé€‰æ‹©åŸºå‡†å…ƒç´ ï¼Œå°†åºåˆ—åˆ†ä¸ºå°äºå’Œå¤§äºåŸºå‡†çš„ä¸¤éƒ¨åˆ†ã€‚
**Definition 2.5.1** Quick sort selects a pivot element and divides the sequence into two parts: less than and greater than the pivot.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
QuickSort(A, left, right):
    if left < right:
        pivot = Partition(A, left, right)
        QuickSort(A, left, pivot-1)
        QuickSort(A, pivot+1, right)

Partition(A, left, right):
    pivot = A[right]
    i = left - 1
    for j = left to right - 1:
        if A[j] <= pivot:
            i = i + 1
            swap(A[i], A[j])
    swap(A[i+1], A[right])
    return i + 1
```

**å®šç† 2.5.1** å¿«é€Ÿæ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸º $O(n \log n)$ï¼Œæœ€åæƒ…å†µä¸º $O(n^2)$ã€‚
**Theorem 2.5.1** The average time complexity of quick sort is $O(n \log n)$, but the worst case is $O(n^2)$.

**ä¸¥æ ¼æ•°å­¦æ¨å¯¼ / Rigorous Mathematical Derivation:**

#### 2.5.1 æœ€åæƒ…å†µåˆ†æ / Worst-Case Analysis

**æœ€åæƒ…å†µ / Worst Case**: æ¯æ¬¡åˆ’åˆ†éƒ½äº§ç”Ÿå¤§å°ä¸º $n-1$ å’Œ $0$ çš„å­é—®é¢˜ã€‚
**Worst case**: Each partition produces subproblems of size $n-1$ and $0$.

**é€’å½’å…³ç³» / Recurrence Relation:**
$$T(n) = T(n-1) + T(0) + \Theta(n) = T(n-1) + \Theta(n)$$

**å±•å¼€æ³• / Substitution Method:**
$$T(n) = T(n-1) + \Theta(n)$$
$$= T(n-2) + \Theta(n-1) + \Theta(n)$$
$$= T(n-3) + \Theta(n-2) + \Theta(n-1) + \Theta(n)$$
$$= \ldots$$
$$= T(0) + \sum_{i=1}^{n} \Theta(i)$$
$$= \Theta(1) + \Theta\left(\frac{n(n+1)}{2}\right)$$
$$= \Theta(n^2)$$

å› æ­¤æœ€åæƒ…å†µæ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ã€‚
Therefore, the worst-case time complexity is $O(n^2)$.

#### 2.5.2 æœ€å¥½æƒ…å†µåˆ†æ / Best-Case Analysis

**æœ€å¥½æƒ…å†µ / Best Case**: æ¯æ¬¡åˆ’åˆ†éƒ½äº§ç”Ÿå¤§å°ç›¸ç­‰çš„ä¸¤ä¸ªå­é—®é¢˜ã€‚
**Best case**: Each partition produces two subproblems of equal size.

**é€’å½’å…³ç³» / Recurrence Relation:**
$$T(n) = 2T(n/2) + \Theta(n)$$

è¿™ä¸å½’å¹¶æ’åºç›¸åŒï¼Œå› æ­¤ $T(n) = \Theta(n \log n)$ã€‚
This is the same as merge sort, so $T(n) = \Theta(n \log n)$.

#### 2.5.3 å¹³å‡æƒ…å†µåˆ†æ / Average-Case Analysis

**éšæœºåŒ–å¿«é€Ÿæ’åº / Randomized Quick Sort**: å‡è®¾åŸºå‡†å…ƒç´ éšæœºé€‰æ‹©ã€‚
**Randomized Quick Sort**: Assume the pivot is chosen uniformly at random.

è®¾ $T(n)$ ä¸ºéšæœºåŒ–å¿«é€Ÿæ’åºåœ¨é•¿åº¦ä¸º $n$ çš„æ•°ç»„ä¸Šçš„æœŸæœ›è¿è¡Œæ—¶é—´ã€‚
Let $T(n)$ be the expected running time of randomized quicksort on an array of length $n$.

**é€’å½’å…³ç³» / Recurrence Relation:**

å½“åŸºå‡†å…ƒç´ éšæœºé€‰æ‹©æ—¶ï¼Œå®ƒå¯èƒ½ä½äºä½ç½® $k$ï¼ˆ$k = 1, 2, \ldots, n$ï¼‰ï¼Œæ¯ä¸ªä½ç½®çš„æ¦‚ç‡ä¸º $1/n$ã€‚
When the pivot is randomly selected, it may be at position $k$ ($k = 1, 2, \ldots, n$), with probability $1/n$ for each position.

$$T(n) = \Theta(n) + \frac{1}{n}\sum_{k=1}^{n} \left[T(k-1) + T(n-k)\right]$$

å…¶ä¸­ $\Theta(n)$ æ˜¯åˆ’åˆ†çš„æ—¶é—´ï¼Œ$T(k-1)$ å’Œ $T(n-k)$ æ˜¯é€’å½’è°ƒç”¨çš„æœŸæœ›æ—¶é—´ã€‚
where $\Theta(n)$ is the partition time, and $T(k-1)$ and $T(n-k)$ are the expected times of recursive calls.

ç”±äº $T(k-1) = T(n-k)$ï¼ˆå¯¹ç§°æ€§ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ç®€åŒ–ï¼š
Since $T(k-1) = T(n-k)$ (by symmetry), we can simplify:

$$T(n) = \Theta(n) + \frac{2}{n}\sum_{k=1}^{n} T(k-1)$$
$$= \Theta(n) + \frac{2}{n}\sum_{k=0}^{n-1} T(k)$$

**è¯æ˜ $T(n) = O(n \log n)$ / Prove $T(n) = O(n \log n)$:**

ä½¿ç”¨å½’çº³æ³•è¯æ˜ $T(n) \leq cn \log n$ï¼ˆå…¶ä¸­ $c$ ä¸ºå¸¸æ•°ï¼‰ã€‚
Use induction to prove $T(n) \leq cn \log n$ (where $c$ is a constant).

**åŸºç¡€æƒ…å†µ / Base Case**: $T(0) = 0$, $T(1) = \Theta(1) \leq c \cdot 1 \cdot \log 1 = 0$ï¼ˆéœ€è¦è°ƒæ•´å¸¸æ•°ï¼‰

**å½’çº³å‡è®¾ / Inductive Hypothesis**: å‡è®¾å¯¹äºæ‰€æœ‰ $k < n$ï¼Œ$T(k) \leq ck \log k$
Assume for all $k < n$, $T(k) \leq ck \log k$

**å½’çº³æ­¥éª¤ / Inductive Step**:
$$T(n) = \Theta(n) + \frac{2}{n}\sum_{k=0}^{n-1} T(k)$$
$$\leq dn + \frac{2}{n}\sum_{k=1}^{n-1} ck \log k$$

å…¶ä¸­ $d$ æ˜¯åˆ’åˆ†çš„å¸¸æ•°å› å­ã€‚
where $d$ is the constant factor for partitioning.

**å…³é”®æ­¥éª¤ï¼šå°†æ±‚å’Œè½¬æ¢ä¸ºç§¯åˆ† / Key Step: Convert Sum to Integral**

ç”±äº $x \log x$ åœ¨ $[1, n-1]$ ä¸Šå•è°ƒé€’å¢ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ç§¯åˆ†ä¸Šç•Œï¼š
Since $x \log x$ is monotonically increasing on $[1, n-1]$, we can use an integral upper bound:

$$\sum_{k=1}^{n-1} k \log k \leq \int_{1}^{n} x \log x \, dx$$

**è®¡ç®—ç§¯åˆ† / Compute Integral**:
$$\int_{1}^{n} x \log x \, dx = \left[\frac{x^2}{2}\log x - \frac{x^2}{4}\right]_{1}^{n}$$
$$= \frac{n^2}{2}\log n - \frac{n^2}{4} + \frac{1}{4}$$
$$\leq \frac{n^2}{2}\log n$$

å› æ­¤ï¼š
Therefore:

$$T(n) \leq dn + \frac{2c}{n} \cdot \frac{n^2}{2}\log n$$
$$= dn + cn \log n$$
$$= cn \log n + n(d - c \log n + c)$$

é€‰æ‹©è¶³å¤Ÿå¤§çš„ $c$ï¼Œä½¿å¾— $c \geq 2d$ï¼Œåˆ™ï¼š
Choose $c$ large enough such that $c \geq 2d$, then:

$$T(n) \leq cn \log n$$

å› æ­¤ $T(n) = O(n \log n)$ã€‚
Therefore $T(n) = O(n \log n)$.

**æ›´ç²¾ç¡®çš„ç•Œé™ / Tighter Bound:**

é€šè¿‡æ›´ç²¾ç»†çš„åˆ†æï¼Œå¯ä»¥è¯æ˜æœŸæœ›æ¯”è¾ƒæ¬¡æ•°ä¸ºï¼š
Through more refined analysis, we can prove the expected number of comparisons is:

$$E[\text{comparisons}] \leq 2n \ln n \approx 1.386n \log_2 n$$

è¿™æ¯”å½’å¹¶æ’åºçš„ $n \log_2 n$ ç•¥å·®ï¼Œä½†å¸¸æ•°å› å­å¾ˆå°ã€‚
This is slightly worse than merge sort's $n \log_2 n$, but the constant factor is small.

**å®šç† 2.5.2** (å¿«é€Ÿæ’åºæ­£ç¡®æ€§å®šç†) å¿«é€Ÿæ’åºç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ’åºä»»æ„è¾“å…¥æ•°ç»„ã€‚
**Theorem 2.5.2** (Quick Sort Correctness Theorem) The quick sort algorithm correctly sorts any input array.

**å½¢å¼åŒ–æ­£ç¡®æ€§è¯æ˜ / Formal Correctness Proof:**

å¿«é€Ÿæ’åºçš„æ­£ç¡®æ€§ä¾èµ–äºåˆ’åˆ†ï¼ˆPartitionï¼‰å‡½æ•°çš„æ­£ç¡®æ€§ã€‚
The correctness of quick sort depends on the correctness of the Partition function.

**è¯æ˜ç»“æ„ / Proof Structure:**

1. **è¯æ˜å¿«é€Ÿæ’åºæ­£ç¡®æ€§**ï¼ˆå‡è®¾åˆ’åˆ†å‡½æ•°æ­£ç¡®ï¼‰
   Prove QuickSort correctness (assuming Partition is correct)

2. **è¯æ˜åˆ’åˆ†å‡½æ•°æ­£ç¡®æ€§**ï¼ˆä½¿ç”¨å¾ªç¯ä¸å˜å¼ï¼‰
   Prove Partition correctness (using loop invariant)

#### 2.5.4 å¿«é€Ÿæ’åºæ­£ç¡®æ€§ï¼ˆå½’çº³æ³•ï¼‰/ QuickSort Correctness (Induction)

**å‰ç½®æ¡ä»¶ / Precondition**: è¾“å…¥æ•°ç»„ $A[left..right]$
**Input array**: $A[left..right]$

**åç½®æ¡ä»¶ / Postcondition**: è¾“å‡ºæ•°ç»„ $A'[left..right]$ æ»¡è¶³ï¼š
**Output array**: $A'[left..right]$ satisfies:

1. **æœ‰åºæ€§ / Ordering**: $\forall i \in [left, right-1]: A'[i] \leq A'[i+1]$
2. **æ’åˆ—æ€§ / Permutation**: $A'$ æ˜¯ $A$ çš„ä¸€ä¸ªæ’åˆ—

**è¯æ˜æ–¹æ³•ï¼šå¼ºå½’çº³æ³• / Proof Method: Strong Induction**

**åŸºç¡€æƒ…å†µ / Base Case**: $left \geq right$

- æ•°ç»„ä¸ºç©ºæˆ–åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œå·²æœ‰åºï¼Œç®—æ³•ç›´æ¥è¿”å›ï¼Œæ­£ç¡®æ€§æ˜¾ç„¶ã€‚
- Array is empty or has one element, already sorted, algorithm returns directly, correctness is obvious.

**å½’çº³å‡è®¾ / Inductive Hypothesis**:
å‡è®¾å¯¹äºæ‰€æœ‰ $k < n$ï¼Œå¿«é€Ÿæ’åºèƒ½å¤Ÿæ­£ç¡®æ’åºé•¿åº¦ä¸º $k$ çš„æ•°ç»„ã€‚
Assume for all $k < n$, quick sort correctly sorts arrays of length $k$.

**å½’çº³æ­¥éª¤ / Inductive Step**: $left < right$

1. **åˆ’åˆ† / Partition**:
   è°ƒç”¨ $Partition(A, left, right)$ è¿”å›ä½ç½® $p$ï¼Œä½¿å¾—ï¼š
   Call $Partition(A, left, right)$ returns position $p$ such that:
   - $A[left..p-1] \leq A[p]$
   - $A[p+1..right] > A[p]$

2. **é€’å½’ / Recursion**:
   - æ ¹æ®å½’çº³å‡è®¾ï¼Œ$QuickSort(A, left, p-1)$ æ­£ç¡®æ’åº $A[left..p-1]$
   - æ ¹æ®å½’çº³å‡è®¾ï¼Œ$QuickSort(A, p+1, right)$ æ­£ç¡®æ’åº $A[p+1..right]$

   By inductive hypothesis, $QuickSort(A, left, p-1)$ correctly sorts $A[left..p-1]$
   By inductive hypothesis, $QuickSort(A, p+1, right)$ correctly sorts $A[p+1..right]$

3. **ç»“æœ / Result**:
   ç”±äºåˆ’åˆ†ä¿è¯ $A[left..p-1] \leq A[p] < A[p+1..right]$ï¼Œä¸”ä¸¤ä¸ªå­æ•°ç»„éƒ½å·²æ’åºï¼Œå› æ­¤æ•´ä¸ªæ•°ç»„æœ‰åºã€‚
   Since partition ensures $A[left..p-1] \leq A[p] < A[p+1..right]$ and both subarrays are sorted, the entire array is sorted.

#### 2.5.5 åˆ’åˆ†å‡½æ•°æ­£ç¡®æ€§ï¼ˆå¾ªç¯ä¸å˜å¼ï¼‰/ Partition Correctness (Loop Invariant)

**å¾ªç¯ä¸å˜å¼ / Loop Invariant**: åœ¨ $Partition$ å‡½æ•°çš„å¾ªç¯ä¸­ï¼Œä»¥ä¸‹æ¡ä»¶å§‹ç»ˆæˆç«‹ï¼š
**Loop Invariant**: In the loop of the $Partition$ function, the following conditions always hold:

1. **$A[left..i] \leq pivot$**: æ‰€æœ‰å·²æ£€æŸ¥ä¸”å°äºç­‰äºåŸºå‡†çš„å…ƒç´ éƒ½åœ¨ä½ç½® $left$ åˆ° $i$
   All examined elements $\leq$ pivot are in positions $left$ to $i$

2. **$A[i+1..j-1] > pivot$**: æ‰€æœ‰å·²æ£€æŸ¥ä¸”å¤§äºåŸºå‡†çš„å…ƒç´ éƒ½åœ¨ä½ç½® $i+1$ åˆ° $j-1$
   All examined elements $>$ pivot are in positions $i+1$ to $j-1$

3. **$A[right] = pivot$**: åŸºå‡†å…ƒç´ å§‹ç»ˆåœ¨ä½ç½® $right$
   Pivot element is always at position $right$

**è¯æ˜å¾ªç¯ä¸å˜å¼ / Prove Loop Invariant:**

**åˆå§‹åŒ– / Initialization**:

- $i = left - 1$, $j = left$
- $A[left..i]$ å’Œ $A[i+1..j-1]$ éƒ½ä¸ºç©ºï¼Œä¸å˜å¼æˆç«‹ã€‚
- $A[left..i]$ and $A[i+1..j-1]$ are both empty, invariant holds.

**ä¿æŒ / Maintenance**:
åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼š
In each iteration:

- å¦‚æœ $A[j] \leq pivot$ï¼š
  - äº¤æ¢ $A[j]$ å’Œ $A[i+1]$
  - $i$ å¢åŠ  1
  - $A[left..i]$ ä»ç„¶åŒ…å«æ‰€æœ‰ $\leq pivot$ çš„å…ƒç´ 
  - $A[i+1..j-1]$ ä»ç„¶åŒ…å«æ‰€æœ‰ $> pivot$ çš„å…ƒç´ 

  If $A[j] \leq pivot$:
  - Swap $A[j]$ and $A[i+1]$
  - Increment $i$
  - $A[left..i]$ still contains all elements $\leq pivot$
  - $A[i+1..j-1]$ still contains all elements $> pivot$

- å¦‚æœ $A[j] > pivot$ï¼š
  - åªå¢åŠ  $j$
  - $A[left..i]$ ä¸å˜
  - $A[i+1..j-1]$ æ‰©å±•åŒ…å« $A[j]$

  If $A[j] > pivot$:
  - Only increment $j$
  - $A[left..i]$ unchanged
  - $A[i+1..j-1]$ extended to include $A[j]$

**ç»ˆæ­¢ / Termination**:
å½“ $j = right$ æ—¶ï¼š
When $j = right$:

- æ‰€æœ‰å…ƒç´ éƒ½å·²æ£€æŸ¥
- $A[left..i] \leq pivot$
- $A[i+1..right-1] > pivot$
- $A[right] = pivot$

æœ€åäº¤æ¢ $A[i+1]$ å’Œ $A[right]$ï¼Œå¾—åˆ°ï¼š
Finally swap $A[i+1]$ and $A[right]$, we get:

- $A[left..i] \leq pivot$
- $A[i+1] = pivot$
- $A[i+2..right] > pivot$

å› æ­¤åˆ’åˆ†æ­£ç¡®ã€‚
Therefore, the partition is correct.

**ç©ºé—´å¤æ‚åº¦åˆ†æ / Space Complexity Analysis:**

å¿«é€Ÿæ’åºæ˜¯åŸåœ°æ’åºç®—æ³•ï¼Œä½†éœ€è¦é€’å½’è°ƒç”¨æ ˆã€‚
Quick sort is an in-place sorting algorithm, but requires a recursion call stack.

- **æœ€å¥½æƒ…å†µ**ï¼šé€’å½’æ·±åº¦ $\Theta(\log n)$ï¼Œç©ºé—´å¤æ‚åº¦ $\Theta(\log n)$
- **æœ€åæƒ…å†µ**ï¼šé€’å½’æ·±åº¦ $\Theta(n)$ï¼Œç©ºé—´å¤æ‚åº¦ $\Theta(n)$
- **å¹³å‡æƒ…å†µ**ï¼šé€’å½’æ·±åº¦ $\Theta(\log n)$ï¼Œç©ºé—´å¤æ‚åº¦ $\Theta(\log n)$

**Best case**: Recursion depth $\Theta(\log n)$, space complexity $\Theta(\log n)$
**Worst case**: Recursion depth $\Theta(n)$, space complexity $\Theta(n)$
**Average case**: Recursion depth $\Theta(\log n)$, space complexity $\Theta(\log n)$

**å­¦æœ¯å¼•ç”¨ / Academic Citations:**

- [Cormen 2022]: Cormen, T. H., et al. (2022). *Introduction to Algorithms* (4th ed.). MIT Press.
- [Hoare 1962]: Hoare, C. A. R. (1962). "Quicksort." *The Computer Journal*, 5(1), 10-16.

### 2.6 å †æ’åº / Heap Sort

**å®šä¹‰ 2.6.1** å †æ’åºä½¿ç”¨å †æ•°æ®ç»“æ„è¿›è¡Œæ’åºã€‚
**Definition 2.6.1** Heap sort uses the heap data structure for sorting.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
HeapSort(A):
    BuildMaxHeap(A)
    for i = n downto 2:
        swap(A[1], A[i])
        heap_size = heap_size - 1
        MaxHeapify(A, 1)

BuildMaxHeap(A):
    heap_size = length(A)
    for i = floor(heap_size/2) downto 1:
        MaxHeapify(A, i)

MaxHeapify(A, i):
    left = 2*i
    right = 2*i + 1
    largest = i
    if left <= heap_size and A[left] > A[largest]:
        largest = left
    if right <= heap_size and A[right] > A[largest]:
        largest = right
    if largest != i:
        swap(A[i], A[largest])
        MaxHeapify(A, largest)
```

**å®šç† 2.6.1** å †æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n \log n)$ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(1)$ã€‚
**Theorem 2.6.1** The time complexity of heap sort is $O(n \log n)$ and space complexity is $O(1)$.

**ä¸¥æ ¼æ•°å­¦æ¨å¯¼ / Rigorous Mathematical Derivation:**

å †æ’åºåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š
Heap sort consists of two phases:

#### 2.6.1 å»ºå †é˜¶æ®µåˆ†æ / Build Heap Phase Analysis

**å®šç† 2.6.2** å»ºå †çš„æ—¶é—´å¤æ‚åº¦ä¸º $\Theta(n)$ï¼Œè€Œä¸æ˜¯ $O(n \log n)$ã€‚
**Theorem 2.6.2** The time complexity of building heap is $\Theta(n)$, not $O(n \log n)$.

**è¯æ˜ / Proof:**

è®¾å †çš„é«˜åº¦ä¸º $h = \lfloor \log_2 n \rfloor$ã€‚
Let heap height be $h = \lfloor \log_2 n \rfloor$.

åœ¨é«˜åº¦ $j$ï¼ˆä»åº•éƒ¨å¼€å§‹è®¡æ•°ï¼‰çš„èŠ‚ç‚¹æ•°ä¸º $\leq \lceil n/2^{j+1} \rceil$ã€‚
Number of nodes at height $j$ (counting from bottom) is $\leq \lceil n/2^{j+1} \rceil$.

åœ¨é«˜åº¦ $j$ çš„èŠ‚ç‚¹æœ€å¤šéœ€è¦ä¸‹æ²‰ $j$ å±‚ã€‚
Nodes at height $j$ need to sink at most $j$ levels.

**æ€»æ“ä½œæ•° / Total Operations:**
$$T(n) = \sum_{j=0}^{h} j \cdot \left\lceil \frac{n}{2^{j+1}} \right\rceil$$

**ä¸Šç•Œåˆ†æ / Upper Bound Analysis:**
$$T(n) \leq \sum_{j=0}^{h} j \cdot \frac{n}{2^j}$$
$$= n \sum_{j=0}^{h} \frac{j}{2^j}$$

**å…³é”®æ±‚å’Œ / Key Sum:**
$$\sum_{j=0}^{\infty} \frac{j}{2^j} = 2$$

å› æ­¤ï¼š
Therefore:

$$T(n) \leq 2n = O(n)$$

**ä¸‹ç•Œåˆ†æ / Lower Bound Analysis:**

å¯¹äºå®Œå…¨äºŒå‰æ ‘ï¼Œå»ºå †éœ€è¦ $\Omega(n)$ æ¬¡æ“ä½œã€‚
For complete binary trees, building heap requires $\Omega(n)$ operations.

å› æ­¤å»ºå †æ—¶é—´ä¸º $\Theta(n)$ã€‚
Therefore, build heap time is $\Theta(n)$.

#### 2.6.2 æå–é˜¶æ®µåˆ†æ / Extraction Phase Analysis

**å®šç† 2.6.3** æå– $n$ ä¸ªå…ƒç´ çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n \log n)$ã€‚
**Theorem 2.6.3** Extracting $n$ elements takes $O(n \log n)$ time.

**è¯æ˜ / Proof:**

æ¯æ¬¡æå–æœ€å¤§å…ƒç´ éœ€è¦ï¼š
Each extraction of maximum element requires:

1. **äº¤æ¢**: $O(1)$
2. **MaxHeapify**: $O(\log n)$ï¼ˆå †é«˜åº¦ä¸º $\log n$ï¼‰

**æ€»æ—¶é—´**: $n \times O(\log n) = O(n \log n)$
**Total time**: $n \times O(\log n) = O(n \log n)$

#### 2.6.3 æ€»æ—¶é—´å¤æ‚åº¦ / Total Time Complexity

$$T(n) = \Theta(n) + O(n \log n) = O(n \log n)$$

**å®šç† 2.6.4** (å †æ’åºæ­£ç¡®æ€§å®šç†) å †æ’åºèƒ½å¤Ÿæ­£ç¡®æ’åºä»»æ„è¾“å…¥æ•°ç»„ã€‚
**Theorem 2.6.4** (Heap Sort Correctness Theorem) Heap sort correctly sorts any input array.

**å½¢å¼åŒ–æ­£ç¡®æ€§è¯æ˜ / Formal Correctness Proof:**

**å¾ªç¯ä¸å˜å¼ / Loop Invariant:**

åœ¨æå–é˜¶æ®µçš„æ¯æ¬¡è¿­ä»£å¼€å§‹æ—¶ï¼š
At the start of each iteration in extraction phase:

1. **$A[1..i]$**: åŒ…å«æ•°ç»„çš„ $n-i+1$ ä¸ªæœ€å¤§å…ƒç´ ï¼Œä¸”å·²æ’åº
   **$A[1..i]$**: Contains $n-i+1$ largest elements of array, sorted

2. **$A[i+1..n]$**: åŒ…å«æ•°ç»„çš„ $i-1$ ä¸ªæœ€å°å…ƒç´ ï¼Œä¸”å·²æ’åº
   **$A[i+1..n]$**: Contains $i-1$ smallest elements of array, sorted

3. **$A[1..i]$**: æ„æˆæœ€å¤§å †
   **$A[1..i]$**: Forms a max-heap

**è¯æ˜ / Proof:**

**åˆå§‹åŒ–**: $i = n$

- $A[1..n]$ æ˜¯æœ€å¤§å †ï¼ˆå»ºå †åï¼‰
- $A[1..n]$ is a max-heap (after building)

**ä¿æŒ**:

- äº¤æ¢ $A[1]$ å’Œ $A[i]$ï¼Œ$A[i]$ æ˜¯å½“å‰æœ€å¤§å€¼
- MaxHeapify æ¢å¤ $A[1..i-1]$ çš„å †æ€§è´¨
- $A[i]$ æ˜¯å·²æ’åºéƒ¨åˆ†çš„æœ€å¤§å…ƒç´ 
- Swap $A[1]$ and $A[i]$, $A[i]$ is current maximum
- MaxHeapify restores heap property of $A[1..i-1]$
- $A[i]$ is the maximum element of sorted part

**ç»ˆæ­¢**: $i = 1$

- $A[1]$ æ˜¯æœ€å°å…ƒç´ 
- æ•´ä¸ªæ•°ç»„å·²æ’åº
- $A[1]$ is the minimum element
- Entire array is sorted

**ç©ºé—´å¤æ‚åº¦åˆ†æ / Space Complexity Analysis:**

å †æ’åºæ˜¯åŸåœ°æ’åºç®—æ³•ï¼Œåªéœ€è¦å¸¸æ•°ä¸ªé¢å¤–å˜é‡ã€‚
Heap sort is an in-place sorting algorithm, requiring only a constant number of extra variables.

- **ç©ºé—´å¤æ‚åº¦**: $O(1)$
- **Space Complexity**: $O(1)$

**å­¦æœ¯å¼•ç”¨ / Academic Citations:**

- [Cormen 2022]: Cormen, T. H., et al. (2022). *Introduction to Algorithms* (4th ed.). MIT Press.
- [Williams 1964]: Williams, J. W. J. (1964). "Algorithm 232: Heapsort." *Communications of the ACM*, 7(6), 347-348.
- [Suchenek 2015]: Suchenek, M. A. (2015). "A complete worst-case analysis of heapsort with experimental verification of its results." arXiv:1504.01459

---

## 3. éæ¯”è¾ƒæ’åº / Non-Comparison Sorting

### 3.1 è®¡æ•°æ’åº / Counting Sort

**å®šä¹‰ 3.1.1** è®¡æ•°æ’åºç»Ÿè®¡æ¯ä¸ªå…ƒç´ å‡ºç°çš„æ¬¡æ•°ï¼Œç„¶åé‡å»ºåºåˆ—ã€‚
**Definition 3.1.1** Counting sort counts the occurrences of each element and then reconstructs the sequence.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
CountingSort(A, k):
    C = array of size k+1
    B = array of size n

    for i = 0 to k:
        C[i] = 0

    for j = 1 to n:
        C[A[j]] = C[A[j]] + 1

    for i = 1 to k:
        C[i] = C[i] + C[i-1]

    for j = n downto 1:
        B[C[A[j]]] = A[j]
        C[A[j]] = C[A[j]] - 1

    return B
```

**å®šç† 3.1.1** è®¡æ•°æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(n + k)$ï¼Œå…¶ä¸­ $k$ æ˜¯å…ƒç´ èŒƒå›´ã€‚
**Theorem 3.1.1** The time complexity of counting sort is $O(n + k)$, where $k$ is the range of elements.

### 3.2 åŸºæ•°æ’åº / Radix Sort

**å®šä¹‰ 3.2.1** åŸºæ•°æ’åºæŒ‰ä½æ’åºï¼Œä»æœ€ä½ä½åˆ°æœ€é«˜ä½ã€‚
**Definition 3.2.1** Radix sort sorts by digits, from the least significant digit to the most significant digit.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
RadixSort(A, d):
    for i = 1 to d:
        A = CountingSort(A, 9) // æŒ‰ç¬¬iä½æ’åº / Sort by i-th digit
    return A
```

**å®šç† 3.2.1** åŸºæ•°æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(d(n + k))$ï¼Œå…¶ä¸­ $d$ æ˜¯ä½æ•°ï¼Œ$k$ æ˜¯åŸºæ•°ã€‚
**Theorem 3.2.1** The time complexity of radix sort is $O(d(n + k))$, where $d$ is the number of digits and $k$ is the radix.

### 3.3 æ¡¶æ’åº / Bucket Sort

**å®šä¹‰ 3.3.1** æ¡¶æ’åºå°†å…ƒç´ åˆ†é…åˆ°ä¸åŒçš„æ¡¶ä¸­ï¼Œç„¶åå¯¹æ¯ä¸ªæ¡¶æ’åºã€‚
**Definition 3.3.1** Bucket sort distributes elements into different buckets and then sorts each bucket.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
BucketSort(A):
    n = length(A)
    B = array of n empty lists

    for i = 1 to n:
        insert A[i] into B[floor(n*A[i])]

    for i = 0 to n-1:
        sort B[i] with insertion sort

    concatenate B[0], B[1], ..., B[n-1]
```

**å®šç† 3.3.1** æ¡¶æ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸º $O(n)$ï¼Œå‡è®¾å…ƒç´ å‡åŒ€åˆ†å¸ƒã€‚
**Theorem 3.3.1** The average time complexity of bucket sort is $O(n)$, assuming elements are uniformly distributed.

---

## 4. æ’åºä¸‹ç•Œ / Sorting Lower Bounds

### 4.1 æ¯”è¾ƒæ’åºä¸‹ç•Œ / Comparison Sorting Lower Bound

**å®šç† 4.1.1** (æ’åºä¸‹ç•Œå®šç†) ä»»ä½•åŸºäºæ¯”è¾ƒçš„æ’åºç®—æ³•çš„æœ€åæƒ…å†µæ—¶é—´å¤æ‚åº¦ä¸º $\Omega(n \log n)$ã€‚
**Theorem 4.1.1** (Sorting Lower Bound Theorem) Any comparison-based sorting algorithm has a worst-case time complexity of $\Omega(n \log n)$.

**è¯æ˜ / Proof:**

1. **å†³ç­–æ ‘æ¨¡å‹ / Decision Tree Model**ï¼šæ¯”è¾ƒæ’åºå¯ä»¥ç”¨å†³ç­–æ ‘è¡¨ç¤º / Comparison sorting can be represented by a decision tree
2. **å¶å­èŠ‚ç‚¹æ•° / Number of Leaf Nodes**ï¼š$n!$ ä¸ªä¸åŒçš„æ’åˆ— / $n!$ different permutations
3. **æ ‘é«˜åº¦ / Tree Height**ï¼šè‡³å°‘ $\log(n!)$ / At least $\log(n!)$
4. **æ–¯ç‰¹æ—å…¬å¼ / Stirling's Formula**ï¼š$\log(n!) = \Theta(n \log n)$ / $\log(n!) = \Theta(n \log n)$

**æ¨è®º 4.1.1** å½’å¹¶æ’åºå’Œå †æ’åºæ˜¯æœ€ä¼˜çš„æ¯”è¾ƒæ’åºç®—æ³•ã€‚
**Corollary 4.1.1** Merge sort and heap sort are optimal comparison-based sorting algorithms.

### 4.2 ä¿¡æ¯è®ºä¸‹ç•Œ / Information-Theoretic Lower Bound

**å®šä¹‰ 4.2.1** æ’åºé—®é¢˜çš„ä¿¡æ¯è®ºä¸‹ç•Œï¼š
**Definition 4.2.1** Information-theoretic lower bound for the sorting problem:
$$H(\pi) = \log(n!) = \Theta(n \log n)$$

å…¶ä¸­ $H(\pi)$ æ˜¯æ’åˆ— $\pi$ çš„ç†µã€‚
where $H(\pi)$ is the entropy of permutation $\pi$.

**å®šç† 4.2.1** ä»»ä½•æ’åºç®—æ³•è‡³å°‘éœ€è¦ $\Omega(n \log n)$ æ¬¡æ¯”è¾ƒã€‚
**Theorem 4.2.1** Any sorting algorithm requires at least $\Omega(n \log n)$ comparisons.

### 4.3 è‡ªé€‚åº”æ’åº / Adaptive Sorting

**å®šä¹‰ 4.3.1** è‡ªé€‚åº”æ’åºç®—æ³•å¯¹å·²éƒ¨åˆ†æ’åºçš„è¾“å…¥è¡¨ç°æ›´å¥½ã€‚
**Definition 4.3.1** Adaptive sorting algorithms perform better on partially sorted inputs.

**å®šç† 4.3.1** æ’å…¥æ’åºçš„è‡ªé€‚åº”å¤æ‚åº¦ä¸º $O(n + d)$ï¼Œå…¶ä¸­ $d$ æ˜¯é€†åºå¯¹æ•°é‡ã€‚
**Theorem 4.3.1** The adaptive complexity of insertion sort is $O(n + d)$, where $d$ is the number of inversions.

---

## 5. å¤–éƒ¨æ’åº / External Sorting

### 5.1 å¤–éƒ¨æ’åºæ¨¡å‹ / External Sorting Model

**å®šä¹‰ 5.1.1** å¤–éƒ¨æ’åºå¤„ç†æ— æ³•å®Œå…¨è£…å…¥å†…å­˜çš„å¤§æ•°æ®é›†ã€‚
**Definition 5.1.1** External sorting handles large datasets that cannot fit entirely in memory.

**æ¨¡å‹å‡è®¾ / Model Assumptions:**

- å†…å­˜å¤§å°ï¼š$M$ ä¸ªå…ƒç´  / Memory size: $M$ elements
- ç£ç›˜å—å¤§å°ï¼š$B$ ä¸ªå…ƒç´  / Disk block size: $B$ elements
- æ•°æ®å¤§å°ï¼š$N$ ä¸ªå…ƒç´  / Data size: $N$ elements

### 5.2 å¤šè·¯å½’å¹¶ / Multiway Merge

**å®šä¹‰ 5.2.1** å¤šè·¯å½’å¹¶åŒæ—¶å½’å¹¶å¤šä¸ªæœ‰åºåºåˆ—ã€‚
**Definition 5.2.1** Multiway merge merges multiple sorted sequences simultaneously.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
MultiwayMerge(input_files, output_file):
    while not all files empty:
        min_element = find_minimum_from_all_files()
        write min_element to output_file
        advance pointer in file containing min_element
```

**å®šç† 5.2.1** å¤šè·¯å½’å¹¶çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(N \log k)$ï¼Œå…¶ä¸­ $k$ æ˜¯å½’å¹¶çš„è·¯æ•°ã€‚
**Theorem 5.2.1** The time complexity of multiway merge is $O(N \log k)$, where $k$ is the number of merge ways.

### 5.3 æ›¿æ¢é€‰æ‹© / Replacement Selection

**å®šä¹‰ 5.3.1** æ›¿æ¢é€‰æ‹©ä½¿ç”¨å †ç»“æ„ç”Ÿæˆåˆå§‹æœ‰åºæ®µã€‚
**Definition 5.3.1** Replacement selection uses a heap structure to generate initial sorted runs.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
ReplacementSelection(input, M):
    heap = min_heap of size M
    output = []

    // åˆå§‹å¡«å……å † / Initially fill the heap
    for i = 1 to M:
        insert input.next() into heap

    while not input.empty():
        min_element = heap.extract_min()
        output.append(min_element)

        if not input.empty():
            next_element = input.next()
            if next_element >= min_element:
                heap.insert(next_element)
            else:
                // å¼€å§‹æ–°çš„æœ‰åºæ®µ / Start a new sorted run
                start_new_run()
```

**å®šç† 5.3.1** æ›¿æ¢é€‰æ‹©ç”Ÿæˆçš„æœ‰åºæ®µå¹³å‡é•¿åº¦ä¸º $2M$ã€‚
**Theorem 5.3.1** The average length of sorted runs generated by replacement selection is $2M$.

---

## 6. å®ç°ç¤ºä¾‹

### 6.1 å¿«é€Ÿæ’åºå®ç°

```rust
pub struct QuickSort;

impl QuickSort {
    pub fn sort<T: Ord + Clone>(arr: &mut [T]) {
        Self::quick_sort(arr, 0, arr.len().saturating_sub(1));
    }

    fn quick_sort<T: Ord + Clone>(arr: &mut [T], low: usize, high: usize) {
        if low < high {
            let pivot_index = Self::partition(arr, low, high);
            if pivot_index > 0 {
                Self::quick_sort(arr, low, pivot_index - 1);
            }
            Self::quick_sort(arr, pivot_index + 1, high);
        }
    }

    fn partition<T: Ord + Clone>(arr: &mut [T], low: usize, high: usize) -> usize {
        let pivot = arr[high].clone();
        let mut i = low;

        for j in low..high {
            if arr[j] <= pivot {
                arr.swap(i, j);
                i += 1;
            }
        }

        arr.swap(i, high);
        i
    }
}
```

### 6.2 å½’å¹¶æ’åºå®ç°

```rust
pub struct MergeSort;

impl MergeSort {
    pub fn sort<T: Ord + Clone>(arr: &mut [T]) {
        if arr.len() <= 1 {
            return;
        }

        let mid = arr.len() / 2;
        let (left, right) = arr.split_at_mut(mid);

        Self::sort(left);
        Self::sort(right);

        Self::merge(arr, mid);
    }

    fn merge<T: Ord + Clone>(arr: &mut [T], mid: usize) {
        let mut left = arr[..mid].to_vec();
        let mut right = arr[mid..].to_vec();

        let mut i = 0;
        let mut j = 0;
        let mut k = 0;

        while i < left.len() && j < right.len() {
            if left[i] <= right[j] {
                arr[k] = left[i].clone();
                i += 1;
            } else {
                arr[k] = right[j].clone();
                j += 1;
            }
            k += 1;
        }

        while i < left.len() {
            arr[k] = left[i].clone();
            i += 1;
            k += 1;
        }

        while j < right.len() {
            arr[k] = right[j].clone();
            j += 1;
            k += 1;
        }
    }
}
```

### 6.3 å †æ’åºå®ç°

```rust
pub struct HeapSort;

impl HeapSort {
    pub fn sort<T: Ord>(arr: &mut [T]) {
        let n = arr.len();

        // æ„å»ºæœ€å¤§å †
        for i in (0..n/2).rev() {
            Self::heapify(arr, n, i);
        }

        // é€ä¸ªæå–æœ€å¤§å…ƒç´ 
        for i in (1..n).rev() {
            arr.swap(0, i);
            Self::heapify(arr, i, 0);
        }
    }

    fn heapify<T: Ord>(arr: &mut [T], n: usize, i: usize) {
        let mut largest = i;
        let left = 2 * i + 1;
        let right = 2 * i + 2;

        if left < n && arr[left] > arr[largest] {
            largest = left;
        }

        if right < n && arr[right] > arr[largest] {
            largest = right;
        }

        if largest != i {
            arr.swap(i, largest);
            Self::heapify(arr, n, largest);
        }
    }
}
```

### 6.4 è®¡æ•°æ’åºå®ç°

```rust
pub struct CountingSort;

impl CountingSort {
    pub fn sort(arr: &[usize], max_value: usize) -> Vec<usize> {
        let mut count = vec![0; max_value + 1];
        let mut output = vec![0; arr.len()];

        // è®¡æ•°
        for &num in arr {
            count[num] += 1;
        }

        // ç´¯ç§¯è®¡æ•°
        for i in 1..=max_value {
            count[i] += count[i - 1];
        }

        // æ„å»ºè¾“å‡ºæ•°ç»„
        for &num in arr.iter().rev() {
            let index = count[num] - 1;
            output[index] = num;
            count[num] -= 1;
        }

        output
    }
}
```

### 6.5 åŸºæ•°æ’åºå®ç°

```rust
pub struct RadixSort;

impl RadixSort {
    pub fn sort(arr: &mut [usize]) {
        if arr.is_empty() {
            return;
        }

        let max_value = *arr.iter().max().unwrap();
        let mut exp = 1;

        while max_value / exp > 0 {
            Self::counting_sort_by_digit(arr, exp);
            exp *= 10;
        }
    }

    fn counting_sort_by_digit(arr: &mut [usize], exp: usize) {
        let mut count = vec![0; 10];
        let mut output = vec![0; arr.len()];

        // è®¡æ•°
        for &num in arr.iter() {
            let digit = (num / exp) % 10;
            count[digit] += 1;
        }

        // ç´¯ç§¯è®¡æ•°
        for i in 1..10 {
            count[i] += count[i - 1];
        }

        // æ„å»ºè¾“å‡ºæ•°ç»„
        for &num in arr.iter().rev() {
            let digit = (num / exp) % 10;
            let index = count[digit] - 1;
            output[index] = num;
            count[digit] -= 1;
        }

        // å¤åˆ¶å›åŸæ•°ç»„
        arr.copy_from_slice(&output);
    }
}
```

### 6.6 æ’åºç®—æ³•æ¯”è¾ƒ

```rust
use std::time::{Duration, Instant};

pub struct SortBenchmark;

impl SortBenchmark {
    pub fn benchmark<T: Ord + Clone>(arr: &[T], sort_fn: fn(&mut [T])) -> Duration {
        let mut arr_copy = arr.to_vec();
        let start = Instant::now();
        sort_fn(&mut arr_copy);
        start.elapsed()
    }

    pub fn compare_algorithms(arr: &[usize]) {
        let mut arr_copy = arr.to_vec();

        // å¿«é€Ÿæ’åº
        let quick_time = Self::benchmark(arr, |arr| {
            QuickSort::sort(arr);
        });

        // å½’å¹¶æ’åº
        let merge_time = Self::benchmark(arr, |arr| {
            MergeSort::sort(arr);
        });

        // å †æ’åº
        let heap_time = Self::benchmark(arr, |arr| {
            HeapSort::sort(arr);
        });

        println!("å¿«é€Ÿæ’åºæ—¶é—´: {:?}", quick_time);
        println!("å½’å¹¶æ’åºæ—¶é—´: {:?}", merge_time);
        println!("å †æ’åºæ—¶é—´: {:?}", heap_time);
    }
}
```

---

## 7. å‚è€ƒæ–‡çŒ® / References

> **è¯´æ˜ / Note**: æœ¬æ–‡æ¡£çš„å‚è€ƒæ–‡çŒ®é‡‡ç”¨ç»Ÿä¸€çš„å¼•ç”¨æ ‡å‡†ï¼Œæ‰€æœ‰æ–‡çŒ®æ¡ç›®å‡æ¥è‡ª `docs/references_database.yaml` æ•°æ®åº“ã€‚

### 7.1 ç»å…¸æ•™æ / Classic Textbooks

1. [Cormen2022] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2022). *Introduction to Algorithms* (4th ed.). MIT Press. ISBN: 978-0262046305
   - **Cormen-Leiserson-Rivest-Steinç®—æ³•å¯¼è®º**ï¼Œç®—æ³•è®¾è®¡ä¸åˆ†æçš„æƒå¨æ•™æã€‚æœ¬æ–‡æ¡£çš„æ’åºç®—æ³•ç†è®ºå‚è€ƒæ­¤ä¹¦ã€‚

2. [Knuth1997] Knuth, D. E. (1997). *The Art of Computer Programming, Volume 3: Sorting and Searching* (2nd ed.). Addison-Wesley. ISBN: 978-0201896855
   - **Knuthè®¡ç®—æœºç¨‹åºè®¾è®¡è‰ºæœ¯ç¬¬3å·**ï¼Œæ’åºä¸æŸ¥æ‰¾çš„ç»å…¸è‘—ä½œã€‚æœ¬æ–‡æ¡£çš„æ’åºç®—æ³•åˆ†æå‚è€ƒæ­¤ä¹¦ã€‚

3. [Sedgewick2011] Sedgewick, R., & Wayne, K. (2011). *Algorithms* (4th ed.). Addison-Wesley. ISBN: 978-0321573513
   - **Sedgewick-Wayneç®—æ³•æ•™æ**ï¼Œæ³¨é‡ç®—æ³•å®ç°ä¸å®è·µã€‚æœ¬æ–‡æ¡£çš„æ’åºç®—æ³•å®ç°å‚è€ƒæ­¤ä¹¦ã€‚

### 7.2 Wikiæ¦‚å¿µå‚è€ƒ / Wiki Concept References

- [Sorting Algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm) - æ’åºç®—æ³•çš„æ ‡å‡†å®šä¹‰
- [Comparison Sort](https://en.wikipedia.org/wiki/Comparison_sort) - æ¯”è¾ƒæ’åº
- [Stable Sort](https://en.wikipedia.org/wiki/Sorting_algorithm#Stability) - ç¨³å®šæ’åº
- [Quicksort](https://en.wikipedia.org/wiki/Quicksort) - å¿«é€Ÿæ’åº
- [Merge Sort](https://en.wikipedia.org/wiki/Merge_sort) - å½’å¹¶æ’åº
- [Heap Sort](https://en.wikipedia.org/wiki/Heapsort) - å †æ’åº
- [Counting Sort](https://en.wikipedia.org/wiki/Counting_sort) - è®¡æ•°æ’åº
- [Radix Sort](https://en.wikipedia.org/wiki/Radix_sort) - åŸºæ•°æ’åº
- [Bucket Sort](https://en.wikipedia.org/wiki/Bucket_sort) - æ¡¶æ’åº
- [Sorting Lower Bound](https://en.wikipedia.org/wiki/Comparison_sort#Number_of_comparisons_required_to_sort_a_list) - æ’åºä¸‹ç•Œ

### 7.3 å¤§å­¦è¯¾ç¨‹å‚è€ƒ / University Course References

- **MIT 6.006**: Introduction to Algorithms. MIT OpenCourseWare. URL: <https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/>
- **Stanford CS161**: Design and Analysis of Algorithms. Stanford University. URL: <https://web.stanford.edu/class/cs161/>
- **CMU 15-451**: Algorithm Design and Analysis. Carnegie Mellon University. URL: <https://www.cs.cmu.edu/~15451/>

### 7.4 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers

#### æ’åºç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Sorting Algorithm Theory

1. **Journal of the ACM (JACM)**
   - **Hoare, C.A.R.** (1962). "Quicksort". *The Computer Journal*, 5(1), 10-16.
   - **Floyd, R.W.** (1964). "Algorithm 245: Treesort 3". *Communications of the ACM*, 7(12), 701.
   - **Williams, J.W.J.** (1964). "Algorithm 232: Heapsort". *Communications of the ACM*, 7(6), 347-348.
   - **Shell, D.L.** (1959). "A High-Speed Sorting Procedure". *Communications of the ACM*, 2(7), 30-32.

2. **SIAM Journal on Computing (SICOMP)**
   - **Ajtai, M., et al.** (1983). "An O(n log n) Sorting Network". *Proceedings of the 15th Annual ACM Symposium on Theory of Computing*, 1-9.
   - **Paterson, M.S.** (1990). "Improved Sorting Networks with O(log n) Depth". *Algorithmica*, 5(1-4), 75-92.
   - **Batcher, K.E.** (1968). "Sorting Networks and Their Applications". *Proceedings of the AFIPS Spring Joint Computer Conference*, 307-314.

#### æ¯”è¾ƒæ’åºä¸‹ç•Œç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Comparison Sort Lower Bounds

1. **Theoretical Computer Science**
   - **Ford, L.R., & Johnson, S.M.** (1959). "A Tournament Problem". *The American Mathematical Monthly*, 66(5), 387-389.
   - **Knuth, D.E.** (1973). *The Art of Computer Programming, Volume 3: Sorting and Searching*. Addison-Wesley.
   - **Manacher, G.K.** (1979). "The Ford-Johnson Algorithm is Not Optimal". *Journal of the ACM*, 26(3), 441-456.

2. **Information and Computation**
   - **Kahn, J., & Kim, J.H.** (1995). "Entropy and Sorting". *Journal of Computer and System Sciences*, 51(3), 390-399.
   - **Cormen, T.H., et al.** (2009). *Introduction to Algorithms* (3rd ed.). MIT Press.

#### çº¿æ€§æ—¶é—´æ’åºé¡¶çº§æœŸåˆŠ / Top Journals in Linear Time Sorting

1. **Journal of Computer and System Sciences**
   - **Thorup, M.** (2002). "Randomized Sorting in O(n log log n) Time and Linear Space Using Addition, Shift, and Bit-wise Boolean Operations". *Journal of Algorithms*, 42(2), 205-230.
   - **Han, Y.** (2004). "Deterministic Sorting in O(n log log n) Time and Linear Space". *Journal of Algorithms*, 50(1), 96-105.
   - **Kirkpatrick, D.G., & Reisch, S.** (1984). "Upper Bounds for Sorting Integers on Random Access Machines". *Theoretical Computer Science*, 28(3), 263-276.

2. **Computational Complexity**
   - **Beame, P., et al.** (1998). "Sorting and Selection in Rounds". *SIAM Journal on Computing*, 28(3), 1030-1048.
   - **Albers, S., & Hagerup, T.** (1997). "Improved Parallel Integer Sorting without Concurrent Writing". *Information and Computation*, 136(1), 25-51.

#### å¤–éƒ¨æ’åºé¡¶çº§æœŸåˆŠ / Top Journals in External Sorting

1. **ACM Transactions on Database Systems**
   - **Aggarwal, A., & Vitter, J.S.** (1988). "The Input/Output Complexity of Sorting and Related Problems". *Communications of the ACM*, 31(9), 1116-1127.
   - **Chiang, Y.J., et al.** (1995). "External Memory Graph Algorithms". *Proceedings of the 6th Annual ACM-SIAM Symposium on Discrete Algorithms*, 139-149.
   - **Arge, L.** (2003). "External Memory Data Structures". *Handbook of Massive Data Sets*, 313-358.

2. **Journal of Algorithms**
   - **Vitter, J.S.** (2001). "External Memory Algorithms and Data Structures: Dealing with Massive Data". *ACM Computing Surveys*, 33(2), 209-271.
   - **Arge, L., et al.** (1999). "I/O-Efficient Algorithms for Problems on Grid-Based Terrains". *Journal of Experimental Algorithmics*, 4, 1-23.

#### å¹¶è¡Œæ’åºé¡¶çº§æœŸåˆŠ / Top Journals in Parallel Sorting

1. **Journal of Parallel and Distributed Computing**
   - **Leighton, T.** (1985). "Tight Bounds on the Complexity of Parallel Sorting". *IEEE Transactions on Computers*, 34(4), 344-354.
   - **Cole, R.** (1988). "Parallel Merge Sort". *SIAM Journal on Computing*, 17(4), 770-785.
   - **Blelloch, G.E.** (1990). "Prefix Sums and Their Applications". *Synthesis of Parallel Algorithms*, 35-60.

2. **Parallel Computing**
   - **Akl, S.G.** (1985). *Parallel Sorting Algorithms*. Academic Press.
   - **JaJa, J.** (1992). *An Introduction to Parallel Algorithms*. Addison-Wesley.

**åœ¨çº¿èµ„æº / Online Resources**:

1. **Wikipedia - Sorting Algorithm**: <https://en.wikipedia.org/wiki/Sorting_algorithm>
   - æ’åºç®—æ³•çš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«æ¯”è¾ƒæ’åºå’Œéæ¯”è¾ƒæ’åºï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

2. **Wikipedia - Comparison Sort**: <https://en.wikipedia.org/wiki/Comparison_sort>
   - æ¯”è¾ƒæ’åºçš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»æ¯”è¾ƒæ’åºçš„ä¸‹ç•Œï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

3. **Wikipedia - Quicksort**: <https://en.wikipedia.org/wiki/Quicksort>
   - å¿«é€Ÿæ’åºçš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«ç®—æ³•æè¿°å’Œå¤æ‚åº¦åˆ†æï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

4. **Wikipedia - Heapsort**: <https://en.wikipedia.org/wiki/Heapsort>
   - å †æ’åºçš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»å †æ•°æ®ç»“æ„å’Œæ’åºè¿‡ç¨‹ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

5. **Wikipedia - Merge Sort**: <https://en.wikipedia.org/wiki/Merge_sort>
   - å½’å¹¶æ’åºçš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«åˆ†æ²»ç­–ç•¥å’Œç¨³å®šæ€§åˆ†æï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

**å¼•ç”¨è§„èŒƒè¯´æ˜ / Citation Guidelines**:

æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®å¼•ç”¨è§„èŒƒï¼ˆè§ `docs/å¼•ç”¨è§„èŒƒä¸æ•°æ®åº“.md`ï¼‰ã€‚æ‰€æœ‰å¼•ç”¨æ¡ç›®åœ¨ `docs/references_database.yaml` ä¸­æœ‰å®Œæ•´è®°å½•ã€‚

æœ¬æ–‡æ¡£å†…å®¹å·²å¯¹ç…§Wikipediaç›¸å…³æ¡ç›®ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æœ¯è¯­å®šä¹‰å’Œç†è®ºæ¡†æ¶ä¸å½“å‰å­¦æœ¯æ ‡å‡†ä¸€è‡´ã€‚

---

## 8. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure

### 8.1 ç›¸å…³æ–‡æ¡£ / Related Documents

- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/01-ç®—æ³•è®¾è®¡ç†è®º.md` - ç®—æ³•è®¾è®¡ç†è®ºï¼ˆåˆ†æ²»ã€åŠ¨æ€è§„åˆ’ç­‰è®¾è®¡èŒƒå¼ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/22-ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶.md` - ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶ï¼ˆé—®é¢˜ç±»å‹ç»´åº¦ï¼‰
- `04-ç®—æ³•å¤æ‚åº¦/06-ä¿¡æ¯è®ºä¸‹ç•Œ.md` - ä¿¡æ¯è®ºä¸‹ç•Œï¼ˆåŒ…å«æ’åºç®—æ³•çš„ä¿¡æ¯è®ºä¸‹ç•Œï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/02-æ•°æ®ç»“æ„ç†è®º.md` - æ•°æ®ç»“æ„ç†è®ºï¼ˆå †ã€æ•°ç»„ç­‰ï¼‰
- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` - ç®—æ³•å…¨æ™¯æ¢³ç†ï¼ˆåŒ…å«æ’åºç®—æ³•æ¦‚è¿°ï¼‰
- `view/VIEWå†…å®¹æ€»ç´¢å¼•-2025-01-11.md` - VIEWæ–‡ä»¶å¤¹å®Œæ•´ç´¢å¼•

### 8.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position

æœ¬æ–‡æ¡£å±äº **09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€** æ¨¡å—ï¼Œæ˜¯æ’åºç®—æ³•ç†è®ºçš„æ ¸å¿ƒæ–‡æ¡£ï¼Œä¸ºæ’åºç®—æ³•çš„è®¾è®¡å’Œåˆ†ææä¾›ç†è®ºåŸºç¡€ã€‚

### 8.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents

- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` Â§3.2 - Masterå®šç†ï¼ˆåˆ†æ²»æ’åºçš„å¤æ‚åº¦åˆ†æï¼‰
- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` Â§3.8 - ä¿¡æ¯è®ºä¸‹ç•Œï¼ˆæ’åºç®—æ³•çš„ä¸‹ç•Œï¼‰
- `view/VIEWå†…å®¹æ€»ç´¢å¼•-2025-01-11.md` - VIEWæ–‡ä»¶å¤¹å®Œæ•´ç´¢å¼•

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.1
****æœ€åæ›´æ–° / Last Updated**: 2025-01-11
**çŠ¶æ€ / Status**: å·²å¯¹ç…§Wikipediaæ›´æ–° / Updated with Wikipedia references (as of 2025-01-11)

---

*æœ¬æ–‡æ¡£ä¸¥æ ¼éµå¾ªæ•°å­¦å½¢å¼åŒ–è§„èŒƒï¼Œæ‰€æœ‰å®šä¹‰å’Œå®šç†å‡é‡‡ç”¨æ ‡å‡†æ•°å­¦ç¬¦å·è¡¨ç¤ºï¼Œå¹¶ç¬¦åˆå›½é™…é¡¶çº§å­¦æœ¯æœŸåˆŠæ ‡å‡†ã€‚*
