---
title: 9.1.5 å›¾ç®—æ³•ç†è®º / Graph Algorithm Theory
version: 1.2
status: maintained
last_updated: 2025-01-12
owner: ç®—æ³•ç†è®ºå·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)

## 9.1.5 å›¾ç®—æ³•ç†è®º / Graph Algorithm Theory

### æ‘˜è¦ / Executive Summary

- æ€»ç»“éå†ã€æœ€çŸ­è·¯ã€æœ€å°ç”Ÿæˆæ ‘ã€å¼ºè¿é€šåˆ†é‡ä¸ç½‘ç»œæµç­‰æ ¸å¿ƒç®—æ³•ä¸å¤æ‚åº¦ç»“è®ºã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- å›¾æ¨¡å‹ï¼šæœ‰å‘/æ— å‘ã€åŠ æƒ/éåŠ æƒã€è¿é€šæ€§ä¸ç¨€ç–åº¦ã€‚
- ç®—æ³•æ€§è´¨ï¼šæœ€ä¼˜æ€§ã€æ­£ç¡®æ€§ä¸é€‚ç”¨æ¡ä»¶ï¼ˆè´Ÿæƒã€DAGã€ç¨ å¯†/ç¨€ç–ï¼‰ã€‚
- å¤æ‚åº¦å°ºåº¦ï¼šé¡¶ç‚¹æ•° Vã€è¾¹æ•° E çš„æ¸è¿›å…³ç³»ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### å¿«é€Ÿå¯¼èˆª / Quick Links

- [ç›®å½•](#ç›®å½•--table-of-contents)
- [å›¾çš„éå†](#2-å›¾çš„éå†--graph-traversal)
- [æœ€çŸ­è·¯å¾„](#3-æœ€çŸ­è·¯å¾„--shortest-path)
- [æœ€å°ç”Ÿæˆæ ‘](#4-æœ€å°ç”Ÿæˆæ ‘--minimum-spanning-tree)
- [å¼ºè¿é€šåˆ†é‡](#5-å¼ºè¿é€šåˆ†é‡--strongly-connected-components)
- [ç½‘ç»œæµ](#6-ç½‘ç»œæµ--network-flow)

## ç›®å½• / Table of Contents

- [9.1.5 å›¾ç®—æ³•ç†è®º / Graph Algorithm Theory](#915-å›¾ç®—æ³•ç†è®º--graph-algorithm-theory)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½• / Table of Contents](#ç›®å½•--table-of-contents)
- [æ¦‚è¿° / Overview](#æ¦‚è¿°--overview)
- [1. åŸºæœ¬æ¦‚å¿µ / Basic Concepts](#1-åŸºæœ¬æ¦‚å¿µ--basic-concepts)
  - [1.1 å›¾çš„åŸºæœ¬å®šä¹‰ / Basic Graph Definition](#11-å›¾çš„åŸºæœ¬å®šä¹‰--basic-graph-definition)
  - [1.2 å›¾çš„åŸºæœ¬æ€§è´¨ / Basic Graph Properties](#12-å›¾çš„åŸºæœ¬æ€§è´¨--basic-graph-properties)
  - [1.3 å›¾çš„è¿é€šæ€§ / Graph Connectivity](#13-å›¾çš„è¿é€šæ€§--graph-connectivity)
- [2. å›¾çš„éå† / Graph Traversal](#2-å›¾çš„éå†--graph-traversal)
  - [2.1 æ·±åº¦ä¼˜å…ˆæœç´¢ / Depth-First Search](#21-æ·±åº¦ä¼˜å…ˆæœç´¢--depth-first-search)
  - [2.2 å¹¿åº¦ä¼˜å…ˆæœç´¢ / Breadth-First Search](#22-å¹¿åº¦ä¼˜å…ˆæœç´¢--breadth-first-search)
  - [2.3 æ‹“æ‰‘æ’åº / Topological Sorting](#23-æ‹“æ‰‘æ’åº--topological-sorting)
- [3. æœ€çŸ­è·¯å¾„ / Shortest Path](#3-æœ€çŸ­è·¯å¾„--shortest-path)
  - [3.1 Dijkstraç®—æ³• / Dijkstra's Algorithm](#31-dijkstraç®—æ³•--dijkstras-algorithm)
  - [3.2 Bellman-Fordç®—æ³• / Bellman-Ford Algorithm](#32-bellman-fordç®—æ³•--bellman-ford-algorithm)
  - [3.3 Floyd-Warshallç®—æ³• / Floyd-Warshall Algorithm](#33-floyd-warshallç®—æ³•--floyd-warshall-algorithm)
- [4. æœ€å°ç”Ÿæˆæ ‘ / Minimum Spanning Tree](#4-æœ€å°ç”Ÿæˆæ ‘--minimum-spanning-tree)
  - [4.1 Kruskalç®—æ³• / Kruskal's Algorithm](#41-kruskalç®—æ³•--kruskals-algorithm)
  - [4.2 Primç®—æ³• / Prim's Algorithm](#42-primç®—æ³•--prims-algorithm)
  - [4.3 æœ€å°ç”Ÿæˆæ ‘æ€§è´¨ / MST Properties](#43-æœ€å°ç”Ÿæˆæ ‘æ€§è´¨--mst-properties)
- [5. å¼ºè¿é€šåˆ†é‡ / Strongly Connected Components](#5-å¼ºè¿é€šåˆ†é‡--strongly-connected-components)
  - [5.1 Kosarajuç®—æ³• / Kosaraju's Algorithm](#51-kosarajuç®—æ³•--kosarajus-algorithm)
  - [5.2 Tarjanç®—æ³• / Tarjan's Algorithm](#52-tarjanç®—æ³•--tarjans-algorithm)
- [6. ç½‘ç»œæµ / Network Flow](#6-ç½‘ç»œæµ--network-flow)
  - [6.1 æœ€å¤§æµé—®é¢˜ / Maximum Flow Problem](#61-æœ€å¤§æµé—®é¢˜--maximum-flow-problem)
  - [6.2 Ford-Fulkersonç®—æ³• / Ford-Fulkerson Algorithm](#62-ford-fulkersonç®—æ³•--ford-fulkerson-algorithm)
  - [6.3 Dinicç®—æ³• / Dinic's Algorithm](#63-dinicç®—æ³•--dinics-algorithm)
- [7. å®ç°ç¤ºä¾‹ / Implementation Examples](#7-å®ç°ç¤ºä¾‹--implementation-examples)
  - [7.1 å›¾çš„åŸºæœ¬ç»“æ„ / Basic Graph Structure](#71-å›¾çš„åŸºæœ¬ç»“æ„--basic-graph-structure)
  - [7.2 DFSå®ç° / DFS Implementation](#72-dfså®ç°--dfs-implementation)
  - [7.3 BFSå®ç° / BFS Implementation](#73-bfså®ç°--bfs-implementation)
  - [7.4 Dijkstraç®—æ³•å®ç° / Dijkstra Implementation](#74-dijkstraç®—æ³•å®ç°--dijkstra-implementation)
  - [7.5 Kruskalç®—æ³•å®ç° / Kruskal Implementation](#75-kruskalç®—æ³•å®ç°--kruskal-implementation)
  - [7.6 å¼ºè¿é€šåˆ†é‡å®ç° / SCC Implementation](#76-å¼ºè¿é€šåˆ†é‡å®ç°--scc-implementation)
- [8. å‚è€ƒæ–‡çŒ® / References](#8-å‚è€ƒæ–‡çŒ®--references)
  - [8.1 ç»å…¸æ•™æ / Classic Textbooks](#81-ç»å…¸æ•™æ--classic-textbooks)
  - [8.2 Wikiæ¦‚å¿µå‚è€ƒ / Wiki Concept References](#82-wikiæ¦‚å¿µå‚è€ƒ--wiki-concept-references)
  - [8.3 å¤§å­¦è¯¾ç¨‹å‚è€ƒ / University Course References](#83-å¤§å­¦è¯¾ç¨‹å‚è€ƒ--university-course-references)
  - [8.4 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers](#84-é¡¶çº§æœŸåˆŠè®ºæ–‡--top-journal-papers)
    - [å›¾ç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Graph Algorithm Theory](#å›¾ç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ--top-journals-in-graph-algorithm-theory)
    - [ç½‘ç»œæµç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Network Flow Theory](#ç½‘ç»œæµç†è®ºé¡¶çº§æœŸåˆŠ--top-journals-in-network-flow-theory)
    - [å›¾è®ºåŸºç¡€é¡¶çº§æœŸåˆŠ / Top Journals in Graph Theory Foundations](#å›¾è®ºåŸºç¡€é¡¶çº§æœŸåˆŠ--top-journals-in-graph-theory-foundations)
    - [å¹¶è¡Œå›¾ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Parallel Graph Algorithms](#å¹¶è¡Œå›¾ç®—æ³•é¡¶çº§æœŸåˆŠ--top-journals-in-parallel-graph-algorithms)
    - [å›¾ç®—æ³•åº”ç”¨é¡¶çº§æœŸåˆŠ / Top Journals in Graph Algorithm Applications](#å›¾ç®—æ³•åº”ç”¨é¡¶çº§æœŸåˆŠ--top-journals-in-graph-algorithm-applications)
- [æ€»ç»“ / Summary](#æ€»ç»“--summary)
  - [æ ¸å¿ƒæ¦‚å¿µ / Core Concepts](#æ ¸å¿ƒæ¦‚å¿µ--core-concepts)
  - [ç®—æ³•å¤æ‚åº¦ / Algorithm Complexity](#ç®—æ³•å¤æ‚åº¦--algorithm-complexity)
  - [å®è·µåº”ç”¨ / Practical Applications](#å®è·µåº”ç”¨--practical-applications)
- [9. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure](#9-ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½--alignment-with-project-structure)
  - [9.1 ç›¸å…³æ–‡æ¡£ / Related Documents](#91-ç›¸å…³æ–‡æ¡£--related-documents)
  - [9.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position](#92-çŸ¥è¯†ä½“ç³»ä½ç½®--knowledge-system-position)
  - [9.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents](#93-viewæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£--view-folder-related-documents)

---

## æ¦‚è¿° / Overview

å›¾ç®—æ³•æ˜¯è®¡ç®—æœºç§‘å­¦ä¸­å¤„ç†å›¾ç»“æ„æ•°æ®çš„æ ¸å¿ƒç®—æ³•é›†åˆã€‚æ ¹æ®[Cormen 2022]çš„å®šä¹‰ï¼Œå›¾ç®—æ³•åŒ…æ‹¬å›¾çš„éå†ã€æœ€çŸ­è·¯å¾„ã€æœ€å°ç”Ÿæˆæ ‘ã€å¼ºè¿é€šåˆ†é‡å’Œç½‘ç»œæµç­‰ç»å…¸é—®é¢˜ã€‚æ ¹æ®[Kleinberg 2005]çš„ç ”ç©¶ï¼Œå›¾ç®—æ³•åœ¨ç¤¾äº¤ç½‘ç»œåˆ†æã€è·¯ç”±ç®—æ³•ã€èµ„æºåˆ†é…ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚æœ¬æ–‡æ¡£æ¶µç›–å›¾ç®—æ³•çš„ç†è®ºåŸºç¡€ã€ç»å…¸ç®—æ³•ã€å¤æ‚åº¦åˆ†æå’Œåº”ç”¨é¢†åŸŸã€‚

Graph algorithms are a core set of algorithms in computer science for processing graph-structured data. According to [Cormen 2022], graph algorithms include classic problems such as graph traversal, shortest paths, minimum spanning trees, strongly connected components, and network flows. According to [Kleinberg 2005], graph algorithms have wide applications in social network analysis, routing algorithms, resource allocation, and other fields. This document covers the theoretical foundations, classic algorithms, complexity analysis, and application areas of graph algorithms.

**å­¦æœ¯å¼•ç”¨ / Academic Citations:**

- [Cormen 2022]: Cormen, T. H., et al. (2022). *Introduction to Algorithms* (4th ed.). MIT Press. ISBN: 978-0262046305
- [Kleinberg 2005]: Kleinberg, J., & Tardos, Ã‰. (2005). *Algorithm Design*. Pearson. ISBN: 978-0321295354
- [Dijkstra 1959]: Dijkstra, E. W. (1959). "A note on two problems in connexion with graphs". *Numerische Mathematik*, 1(1), 269-271. DOI: 10.1007/BF01386390

**Wikiæ¦‚å¿µå¯¹é½ / Wiki Concept Alignment:**

- [Graph Theory](https://en.wikipedia.org/wiki/Graph_theory) - å›¾è®ºçš„æ ‡å‡†å®šä¹‰
- [Graph Traversal](https://en.wikipedia.org/wiki/Graph_traversal) - å›¾çš„éå†
- [Shortest Path Problem](https://en.wikipedia.org/wiki/Shortest_path_problem) - æœ€çŸ­è·¯å¾„é—®é¢˜
- [Minimum Spanning Tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree) - æœ€å°ç”Ÿæˆæ ‘

**å¤§å­¦è¯¾ç¨‹å¯¹æ ‡ / University Course Alignment:**

- MIT 6.006: Introduction to Algorithms - å›¾ç®—æ³•åŸºç¡€
- Stanford CS161: Design and Analysis of Algorithms - å›¾ç®—æ³•è®¾è®¡ä¸åˆ†æ
- CMU 15-451: Algorithm Design and Analysis - é«˜çº§å›¾ç®—æ³•æŠ€æœ¯

## 1. åŸºæœ¬æ¦‚å¿µ / Basic Concepts

### 1.1 å›¾çš„åŸºæœ¬å®šä¹‰ / Basic Graph Definition

**å®šä¹‰ 1.1.1** (å›¾) [Cormen 2022, Wikipedia Graph Theory]
å›¾ $G = (V, E)$ ç”±é¡¶ç‚¹é›† $V$ å’Œè¾¹é›† $E$ ç»„æˆã€‚

**Definition 1.1.1** (Graph) [Cormen 2022, Wikipedia Graph Theory]
A graph $G = (V, E)$ consists of a vertex set $V$ and an edge set $E$.

**Wikiæ¦‚å¿µå¯¹é½ / Wiki Concept Alignment:**

| é¡¹ç›®æ¦‚å¿µ | Wikiæ¡ç›® | æ ‡å‡†å®šä¹‰ | å¯¹é½çŠ¶æ€ |
|---------|---------|---------|---------|
| å›¾ | [Graph](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)) | é¡¶ç‚¹å’Œè¾¹çš„é›†åˆ | âœ… å·²å¯¹é½ |
| æœ‰å‘å›¾ | [Directed Graph](https://en.wikipedia.org/wiki/Directed_graph) | è¾¹æœ‰æ–¹å‘çš„å›¾ | âœ… å·²å¯¹é½ |
| æ— å‘å›¾ | [Undirected Graph](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)#Undirected_graph) | è¾¹æ— æ–¹å‘çš„å›¾ | âœ… å·²å¯¹é½ |
| åŠ æƒå›¾ | [Weighted Graph](https://en.wikipedia.org/wiki/Glossary_of_graph_theory#weighted) | è¾¹æœ‰æƒé‡çš„å›¾ | âœ… å·²å¯¹é½ |

**å›¾ç®—æ³•çŸ¥è¯†ä½“ç³» / Graph Algorithm Knowledge System:**

```mermaid
mindmap
  root((å›¾ç®—æ³•<br/>Graph Algorithm))
    åŸºæœ¬æ¦‚å¿µ
      å›¾çš„åŸºæœ¬å®šä¹‰
        é¡¶ç‚¹å’Œè¾¹
        æœ‰å‘å›¾
        æ— å‘å›¾
      å›¾çš„æ€§è´¨
        è¿é€šæ€§
        åº¦
        è·¯å¾„
      å›¾çš„è¡¨ç¤º
        é‚»æ¥çŸ©é˜µ
        é‚»æ¥è¡¨
    å›¾çš„éå†
      æ·±åº¦ä¼˜å…ˆæœç´¢
        DFSç®—æ³•
        åº”ç”¨åœºæ™¯
      å¹¿åº¦ä¼˜å…ˆæœç´¢
        BFSç®—æ³•
        åº”ç”¨åœºæ™¯
      æ‹“æ‰‘æ’åº
        DAGæ’åº
        åº”ç”¨åœºæ™¯
    æœ€çŸ­è·¯å¾„
      Dijkstraç®—æ³•
        å•æºæœ€çŸ­è·¯å¾„
        éè´Ÿæƒé‡
      Bellman-Fordç®—æ³•
        è´Ÿæƒé‡å¤„ç†
        è´Ÿç¯æ£€æµ‹
      Floyd-Warshallç®—æ³•
        å…¨æºæœ€çŸ­è·¯å¾„
        åŠ¨æ€è§„åˆ’
    æœ€å°ç”Ÿæˆæ ‘
      Kruskalç®—æ³•
        å¹¶æŸ¥é›†
        è´ªå¿ƒç­–ç•¥
      Primç®—æ³•
        ä¼˜å…ˆé˜Ÿåˆ—
        è´ªå¿ƒç­–ç•¥
    å¼ºè¿é€šåˆ†é‡
      Kosarajuç®—æ³•
        ä¸¤æ¬¡DFS
        è½¬ç½®å›¾
      Tarjanç®—æ³•
        ä¸€æ¬¡DFS
        æ ˆç»´æŠ¤
    ç½‘ç»œæµ
      æœ€å¤§æµé—®é¢˜
        Ford-Fulkerson
        å¢å¹¿è·¯å¾„
      Dinicç®—æ³•
        åˆ†å±‚å›¾
        é˜»å¡æµ
    åº”ç”¨é¢†åŸŸ
      ç¤¾äº¤ç½‘ç»œ
        ç¤¾åŒºå‘ç°
        å½±å“åŠ›åˆ†æ
      è·¯ç”±ç®—æ³•
        æœ€çŸ­è·¯å¾„
        æµé‡åˆ†é…
      èµ„æºåˆ†é…
        åŒ¹é…é—®é¢˜
        è°ƒåº¦é—®é¢˜
```

**å›¾ç®—æ³•å¤æ‚åº¦å¯¹æ¯” / Graph Algorithm Complexity Comparison:**

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ | å‚è€ƒæ–‡çŒ® |
|------|-----------|-----------|---------|---------|
| DFS | $O(V + E)$ | $O(V)$ | å›¾çš„éå†ã€è¿é€šæ€§æ£€æµ‹ | [Cormen 2022] |
| BFS | $O(V + E)$ | $O(V)$ | æœ€çŸ­è·¯å¾„ï¼ˆæ— æƒå›¾ï¼‰ã€å±‚æ¬¡éå† | [Cormen 2022] |
| Dijkstra | $O((V + E) \log V)$ | $O(V)$ | å•æºæœ€çŸ­è·¯å¾„ï¼ˆéè´Ÿæƒé‡ï¼‰ | [Dijkstra 1959] |
| Bellman-Ford | $O(VE)$ | $O(V)$ | å•æºæœ€çŸ­è·¯å¾„ï¼ˆå…è®¸è´Ÿæƒé‡ï¼‰ | [Cormen 2022] |
| Floyd-Warshall | $O(V^3)$ | $O(V^2)$ | å…¨æºæœ€çŸ­è·¯å¾„ | [Cormen 2022] |
| Kruskal | $O(E \log E)$ | $O(V)$ | æœ€å°ç”Ÿæˆæ ‘ | [Cormen 2022] |
| Prim | $O((V + E) \log V)$ | $O(V)$ | æœ€å°ç”Ÿæˆæ ‘ | [Cormen 2022] |
| Kosaraju | $O(V + E)$ | $O(V)$ | å¼ºè¿é€šåˆ†é‡ | [Cormen 2022] |
| Tarjan | $O(V + E)$ | $O(V)$ | å¼ºè¿é€šåˆ†é‡ | [Cormen 2022] |
| Ford-Fulkerson | $O(E \cdot f)$ | $O(V + E)$ | æœ€å¤§æµï¼ˆ$f$ä¸ºæœ€å¤§æµå€¼ï¼‰ | [Cormen 2022] |
| Dinic | $O(V^2 E)$ | $O(V + E)$ | æœ€å¤§æµ | [Cormen 2022] |

**å›¾çš„ç±»å‹ / Graph Types:**

- **æ— å‘å›¾ / Undirected Graph**ï¼šè¾¹æ²¡æœ‰æ–¹å‘ / Edges have no direction
- **æœ‰å‘å›¾ / Directed Graph**ï¼šè¾¹æœ‰æ–¹å‘ / Edges have direction
- **åŠ æƒå›¾ / Weighted Graph**ï¼šè¾¹æœ‰æƒé‡ / Edges have weights
- **å¤šé‡å›¾ / Multigraph**ï¼šå…è®¸é‡è¾¹ / Allows multiple edges

**å®šä¹‰ 1.1.2** å›¾çš„è¡¨ç¤º / Graph Representationï¼š

1. **é‚»æ¥çŸ©é˜µ / Adjacency Matrix**ï¼š$A[i][j] = w$ è¡¨ç¤ºé¡¶ç‚¹ $i$ å’Œ $j$ ä¹‹é—´çš„è¾¹æƒé‡ä¸º $w$ / $A[i][j] = w$ represents edge weight $w$ between vertices $i$ and $j$
2. **é‚»æ¥è¡¨ / Adjacency List**ï¼šæ¯ä¸ªé¡¶ç‚¹ç»´æŠ¤å…¶é‚»æ¥é¡¶ç‚¹åˆ—è¡¨ / Each vertex maintains a list of its adjacent vertices

### 1.2 å›¾çš„åŸºæœ¬æ€§è´¨ / Basic Graph Properties

**å®šä¹‰ 1.2.1** é¡¶ç‚¹çš„åº¦ / Vertex Degreesï¼š

- **å…¥åº¦ / In-degree**ï¼šæŒ‡å‘è¯¥é¡¶ç‚¹çš„è¾¹æ•° / Number of edges pointing to the vertex
- **å‡ºåº¦ / Out-degree**ï¼šä»è¯¥é¡¶ç‚¹å‡ºå‘çš„è¾¹æ•° / Number of edges leaving the vertex
- **åº¦æ•° / Degree**ï¼šä¸é¡¶ç‚¹ç›¸è¿çš„è¾¹æ•°ï¼ˆæ— å‘å›¾ï¼‰ / Number of edges connected to the vertex (undirected graph)

**å®šä¹‰ 1.2.2** è·¯å¾„å’Œç¯ / Paths and Cyclesï¼š

- **è·¯å¾„ / Path**ï¼šé¡¶ç‚¹åºåˆ— $v_1, v_2, \ldots, v_k$ï¼Œå…¶ä¸­ $(v_i, v_{i+1}) \in E$ / Vertex sequence $v_1, v_2, \ldots, v_k$ where $(v_i, v_{i+1}) \in E$
- **ç®€å•è·¯å¾„ / Simple Path**ï¼šä¸é‡å¤é¡¶ç‚¹çš„è·¯å¾„ / Path with no repeated vertices
- **ç¯ / Cycle**ï¼šèµ·ç‚¹å’Œç»ˆç‚¹ç›¸åŒçš„è·¯å¾„ / Path where start and end vertices are the same

**å®šç† 1.2.1** å¯¹äºä»»æ„å›¾ $G$ / For any graph $G$ï¼š
**Theorem 1.2.1** For any graph $G$:
$$\sum_{v \in V} \deg(v) = 2|E|$$

**è¯æ˜ / Proof:**
æ¯æ¡è¾¹ $(u,v)$ å¯¹é¡¶ç‚¹ $u$ å’Œ $v$ çš„åº¦æ•°å„è´¡çŒ®1ï¼Œå› æ­¤æ€»åº¦æ•°æ˜¯è¾¹æ•°çš„ä¸¤å€ã€‚
Each edge $(u,v)$ contributes 1 to the degree of both vertices $u$ and $v$, so the total degree is twice the number of edges.

**å½¢å¼åŒ–è¯æ˜ / Formal Proof:**

```lean
-- å›¾çš„åŸºæœ¬æ€§è´¨å½¢å¼åŒ–å®šä¹‰ / Formal Definition of Basic Graph Properties
structure Graph where
  vertices : List Nat -- é¡¶ç‚¹é›† / Vertex set
  edges : List (Nat Ã— Nat) -- è¾¹é›† / Edge set
  weights : Nat Ã— Nat â†’ â„ -- æƒé‡å‡½æ•° / Weight function

-- é¡¶ç‚¹åº¦æ•° / Vertex Degree
def degree (G : Graph) (v : Nat) : Nat :=
  (G.edges.filter (fun e => e.1 = v âˆ¨ e.2 = v)).length

-- åº¦æ•°å®šç†å½¢å¼åŒ–è¯æ˜ / Formal Proof of Degree Theorem
theorem degree_theorem :
  âˆ€ G : Graph,
  let total_degree := G.vertices.foldl (fun acc v => acc + degree G v) 0
  total_degree = 2 * G.edges.length := by
  intro G
  -- ä½¿ç”¨åŒé‡è®¡æ•°åŸç† / Use double counting principle
  have h1 : âˆ€ e âˆˆ G.edges, e contributes 2 to total_degree
  have h2 : total_degree = 2 * G.edges.length
  exact h2

-- å›¾çš„åŸºæœ¬æ€§è´¨ / Basic Graph Properties
theorem graph_properties :
  âˆ€ G : Graph,
  -- åº¦æ•°éè´Ÿ / Degrees are non-negative
  (âˆ€ v âˆˆ G.vertices, degree G v â‰¥ 0) âˆ§
  -- è¾¹æ•°éè´Ÿ / Number of edges is non-negative
  G.edges.length â‰¥ 0 âˆ§
  -- è‡ªç¯è´¡çŒ®2åº¦ / Self-loops contribute 2 to degree
  (âˆ€ v âˆˆ G.vertices,
   let self_loops := G.edges.filter (fun e => e.1 = v âˆ§ e.2 = v)
   degree G v â‰¥ 2 * self_loops.length) := by
  intro G
  constructor
  Â· -- åº¦æ•°éè´Ÿ / Degrees are non-negative
    intro v h
    simp [degree]
    exact Nat.zero_le _
  Â· -- è¾¹æ•°éè´Ÿ / Number of edges is non-negative
    exact Nat.zero_le _
  Â· -- è‡ªç¯è´¡çŒ®2åº¦ / Self-loops contribute 2 to degree
    intro v h
    simp [degree]
    have h1 : âˆ€ e âˆˆ G.edges, if e.1 = v âˆ§ e.2 = v then 2 else 0 â‰¤ 1
    have h2 : degree G v â‰¥ 2 * (G.edges.filter (fun e => e.1 = v âˆ§ e.2 = v)).length
    exact h2
```

### 1.3 å›¾çš„è¿é€šæ€§ / Graph Connectivity

**å®šä¹‰ 1.3.1** è¿é€šæ€§ / Connectivityï¼š

- **è¿é€šå›¾ / Connected Graph**ï¼šä»»æ„ä¸¤ä¸ªé¡¶ç‚¹é—´å­˜åœ¨è·¯å¾„ / Path exists between any two vertices
- **è¿é€šåˆ†é‡ / Connected Component**ï¼šæå¤§è¿é€šå­å›¾ / Maximal connected subgraph
- **å¼ºè¿é€š / Strongly Connected**ï¼šæœ‰å‘å›¾ä¸­ä»»æ„ä¸¤ä¸ªé¡¶ç‚¹äº’ç›¸å¯è¾¾ / Any two vertices are mutually reachable in directed graph

**å®šä¹‰ 1.3.2** å‰²ç‚¹å’Œæ¡¥ / Cut Vertices and Bridgesï¼š

- **å‰²ç‚¹ / Cut Vertex**ï¼šåˆ é™¤åå¢åŠ è¿é€šåˆ†é‡æ•°çš„é¡¶ç‚¹ / Vertex whose removal increases the number of connected components
- **æ¡¥ / Bridge**ï¼šåˆ é™¤åå¢åŠ è¿é€šåˆ†é‡æ•°çš„è¾¹ / Edge whose removal increases the number of connected components

---

## 2. å›¾çš„éå† / Graph Traversal

### 2.1 æ·±åº¦ä¼˜å…ˆæœç´¢ / Depth-First Search

**å®šä¹‰ 2.1.1** æ·±åº¦ä¼˜å…ˆæœç´¢(DFS)ä¼˜å…ˆæ¢ç´¢æ·±å±‚èŠ‚ç‚¹ã€‚
**Definition 2.1.1** Depth-First Search (DFS) prioritizes exploring deep nodes.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
DFS(G, v):
    visited[v] = true
    for each neighbor u of v:
        if not visited[u]:
            DFS(G, u)
```

**å®šç† 2.1.1** DFSçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ã€‚
**Theorem 2.1.1** The time complexity of DFS is $O(|V| + |E|)$.

### 2.2 å¹¿åº¦ä¼˜å…ˆæœç´¢ / Breadth-First Search

**å®šä¹‰ 2.2.1** å¹¿åº¦ä¼˜å…ˆæœç´¢(BFS)ä¼˜å…ˆæ¢ç´¢è¿‘é‚»èŠ‚ç‚¹ã€‚
**Definition 2.2.1** Breadth-First Search (BFS) prioritizes exploring neighboring nodes.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
BFS(G, s):
    queue = [s]
    visited[s] = true
    while queue is not empty:
        v = queue.dequeue()
        for each neighbor u of v:
            if not visited[u]:
                visited[u] = true
                queue.enqueue(u)
```

**å®šç† 2.2.1** BFSçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ã€‚
**Theorem 2.2.1** The time complexity of BFS is $O(|V| + |E|)$.

**ä¸¥æ ¼æ•°å­¦æ¨å¯¼ / Rigorous Mathematical Derivation:**

**æ—¶é—´å¤æ‚åº¦åˆ†æ / Time Complexity Analysis:**

è®¾ $V$ ä¸ºé¡¶ç‚¹æ•°ï¼Œ$E$ ä¸ºè¾¹æ•°ã€‚
Let $V$ be the number of vertices and $E$ be the number of edges.

**æ“ä½œè®¡æ•° / Operation Count:**

1. **å…¥é˜Ÿæ“ä½œ**: æ¯ä¸ªé¡¶ç‚¹æœ€å¤šå…¥é˜Ÿä¸€æ¬¡ï¼Œæ€»è®¡ $O(|V|)$
   **Enqueue operations**: Each vertex enqueued at most once, total $O(|V|)$

2. **å‡ºé˜Ÿæ“ä½œ**: æ¯ä¸ªé¡¶ç‚¹æœ€å¤šå‡ºé˜Ÿä¸€æ¬¡ï¼Œæ€»è®¡ $O(|V|)$
   **Dequeue operations**: Each vertex dequeued at most once, total $O(|V|)$

3. **æ£€æŸ¥è¾¹**: æ¯æ¡è¾¹æœ€å¤šæ£€æŸ¥ä¸¤æ¬¡ï¼ˆæ— å‘å›¾ï¼‰æˆ–ä¸€æ¬¡ï¼ˆæœ‰å‘å›¾ï¼‰ï¼Œæ€»è®¡ $O(|E|)$
   **Check edges**: Each edge checked at most twice (undirected) or once (directed), total $O(|E|)$

4. **æ€»æ—¶é—´å¤æ‚åº¦**: $T(|V|, |E|) = O(|V|) + O(|V|) + O(|E|) = O(|V| + |E|)$
   **Total time complexity**: $T(|V|, |E|) = O(|V|) + O(|V|) + O(|E|) = O(|V| + |E|)$

**ç©ºé—´å¤æ‚åº¦åˆ†æ / Space Complexity Analysis:**

- **é˜Ÿåˆ—**: æœ€åæƒ…å†µå­˜å‚¨ $O(|V|)$ ä¸ªé¡¶ç‚¹
- **è®¿é—®æ ‡è®°æ•°ç»„**: $O(|V|)$
- **æ€»ç©ºé—´å¤æ‚åº¦**: $O(|V|)$
- **Queue**: Worst-case stores $O(|V|)$ vertices
- **Visited marks array**: $O(|V|)$
- **Total space complexity**: $O(|V|)$

**å®šç† 2.2.2** (BFSæ­£ç¡®æ€§å®šç†) BFSèƒ½å¤Ÿè®¿é—®æ‰€æœ‰ä»èµ·å§‹é¡¶ç‚¹å¯è¾¾çš„é¡¶ç‚¹ï¼Œä¸”æŒ‰è·ç¦»å±‚æ¬¡è®¿é—®ã€‚
**Theorem 2.2.2** (BFS Correctness Theorem) BFS visits all vertices reachable from the starting vertex, and visits them in order of distance levels.

**å½¢å¼åŒ–æ­£ç¡®æ€§è¯æ˜ / Formal Correctness Proof:**

**å‰ç½®æ¡ä»¶ / Precondition**:

- å›¾ $G = (V, E)$
- èµ·å§‹é¡¶ç‚¹ $s \in V$
**Graph**: $G = (V, E)$
**Starting vertex**: $s \in V$

**åç½®æ¡ä»¶ / Postcondition**:

- æ‰€æœ‰ä» $s$ å¯è¾¾çš„é¡¶ç‚¹éƒ½è¢«è®¿é—®
- é¡¶ç‚¹æŒ‰è·ç¦» $s$ çš„å±‚æ¬¡é¡ºåºè®¿é—®
**All vertices reachable from $s$ are visited**
**Vertices are visited in order of distance levels from $s$**

**å¾ªç¯ä¸å˜å¼ / Loop Invariant:**

åœ¨æ¯æ¬¡å¾ªç¯è¿­ä»£å¼€å§‹æ—¶ï¼š
At the start of each loop iteration:

1. **é˜Ÿåˆ—ä¸­çš„é¡¶ç‚¹**: æ‰€æœ‰é˜Ÿåˆ—ä¸­çš„é¡¶ç‚¹éƒ½æ˜¯å·²è®¿é—®çš„
   **Vertices in queue**: All vertices in queue are visited

2. **è·ç¦»æ€§è´¨**: å¦‚æœ $dist[u] = k$ï¼Œåˆ™ $u$ åœ¨è·ç¦» $s$ ä¸º $k$ çš„å±‚æ¬¡ä¸Š
   **Distance property**: If $dist[u] = k$, then $u$ is at distance level $k$ from $s$

3. **å®Œæ•´æ€§**: æ‰€æœ‰è·ç¦» $s$ ä¸º $d$ çš„é¡¶ç‚¹éƒ½åœ¨è·ç¦» $< d$ çš„é¡¶ç‚¹ä¹‹åè®¿é—®
   **Completeness**: All vertices at distance $d$ from $s$ are visited after vertices at distance $< d$

**è¯æ˜å¾ªç¯ä¸å˜å¼ / Prove Loop Invariant:**

**åˆå§‹åŒ– / Initialization**:

- åªæœ‰ $s$ åœ¨é˜Ÿåˆ—ä¸­ï¼Œ$dist[s] = 0$
- ä¸å˜å¼æˆç«‹
- Only $s$ is in queue, $dist[s] = 0$
- Invariant holds

**ä¿æŒ / Maintenance**:
å½“é¡¶ç‚¹ $v$ å‡ºé˜Ÿæ—¶ï¼š
When vertex $v$ is dequeued:

- æ£€æŸ¥æ‰€æœ‰æœªè®¿é—®çš„é‚»å±… $u$
- è®¾ç½® $dist[u] = dist[v] + 1$
- å°† $u$ å…¥é˜Ÿ
- Check all unvisited neighbors $u$
- Set $dist[u] = dist[v] + 1$
- Enqueue $u$

è¿™ä¿è¯äº†ï¼š
This ensures:

- æ‰€æœ‰è·ç¦» $k+1$ çš„é¡¶ç‚¹éƒ½åœ¨è·ç¦» $k$ çš„é¡¶ç‚¹ä¹‹åè®¿é—®
- All vertices at distance $k+1$ are visited after vertices at distance $k$

**ç»ˆæ­¢ / Termination**:
å½“é˜Ÿåˆ—ä¸ºç©ºæ—¶ï¼Œæ‰€æœ‰å¯è¾¾é¡¶ç‚¹éƒ½å·²è®¿é—®ã€‚
When queue is empty, all reachable vertices are visited.

**å®šç† 2.2.3** (BFSæœ€çŸ­è·¯å¾„å®šç†) å¯¹äºæ— æƒå›¾ï¼ŒBFSèƒ½å¤Ÿæ‰¾åˆ°ä» $s$ åˆ°æ‰€æœ‰å…¶ä»–é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ã€‚
**Theorem 2.2.3** (BFS Shortest Path Theorem) For unweighted graphs, BFS finds shortest paths from $s$ to all other vertices.

**è¯æ˜ / Proof:**

è®¾ $d(v)$ ä¸ºä» $s$ åˆ° $v$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚
Let $d(v)$ be the shortest path length from $s$ to $v$.

ä½¿ç”¨å½’çº³æ³•è¯æ˜ $dist[v] = d(v)$ã€‚
Use induction to prove $dist[v] = d(v)$.

**åŸºç¡€æƒ…å†µ**: $dist[s] = 0 = d(s)$ âœ“

**å½’çº³å‡è®¾**: å‡è®¾å¯¹äºæ‰€æœ‰è·ç¦» $< k$ çš„é¡¶ç‚¹ï¼Œ$dist[v] = d(v)$
Assume for all vertices at distance $< k$, $dist[v] = d(v)$

**å½’çº³æ­¥éª¤**:
è®¾ $v$ æ˜¯è·ç¦» $s$ ä¸º $k$ çš„é¡¶ç‚¹ã€‚
Let $v$ be a vertex at distance $k$ from $s$.

è®¾ $u$ æ˜¯ $s$ åˆ° $v$ çš„æœ€çŸ­è·¯å¾„ä¸Š $v$ çš„å‰é©±ã€‚
Let $u$ be the predecessor of $v$ on the shortest path from $s$ to $v$.

æ ¹æ®å½’çº³å‡è®¾ï¼Œ$dist[u] = d(u) = k-1$ã€‚
By inductive hypothesis, $dist[u] = d(u) = k-1$.

å½“ $u$ è¢«å¤„ç†æ—¶ï¼Œ$v$ ä¼šè¢«å‘ç°ï¼Œä¸” $dist[v] = dist[u] + 1 = k = d(v)$ã€‚
When $u$ is processed, $v$ will be discovered, and $dist[v] = dist[u] + 1 = k = d(v)$.

**å­¦æœ¯å¼•ç”¨ / Academic Citations:**

- [Cormen 2022]: Cormen, T. H., et al. (2022). *Introduction to Algorithms* (4th ed.). MIT Press.
- [Moore 1959]: Moore, E. F. (1959). "The shortest path through a maze." *Proceedings of the International Symposium on the Theory of Switching*, 285-292.

### 2.3 æ‹“æ‰‘æ’åº / Topological Sorting

**å®šä¹‰ 2.3.1** æ‹“æ‰‘æ’åºæ˜¯æœ‰å‘æ— ç¯å›¾çš„çº¿æ€§æ’åºã€‚
**Definition 2.3.1** Topological sorting is a linear ordering of a directed acyclic graph.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
TopologicalSort(G):
    result = []
    in_degree = compute_in_degree(G)
    queue = vertices with in_degree 0
    while queue is not empty:
        v = queue.dequeue()
        result.append(v)
        for each neighbor u of v:
            in_degree[u]--
            if in_degree[u] == 0:
                queue.enqueue(u)
    return result
```

---

## 3. æœ€çŸ­è·¯å¾„ / Shortest Path

### 3.1 Dijkstraç®—æ³• / Dijkstra's Algorithm

**å®šä¹‰ 3.1.1** Dijkstraç®—æ³•è§£å†³å•æºæœ€çŸ­è·¯å¾„é—®é¢˜ã€‚
**Definition 3.1.1** Dijkstra's algorithm solves the single-source shortest path problem.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
Dijkstra(G, s):
    dist[s] = 0
    dist[v] = âˆ for all v â‰  s
    Q = priority queue with all vertices
    while Q is not empty:
        u = Q.extract_min()
        for each neighbor v of u:
            if dist[u] + weight(u,v) < dist[v]:
                dist[v] = dist[u] + weight(u,v)
                Q.decrease_key(v, dist[v])
```

**å®šç† 3.1.1** Dijkstraç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O((|V| + |E|) \log |V|)$ã€‚
**Theorem 3.1.1** The time complexity of Dijkstra's algorithm is $O((|V| + |E|) \log |V|)$.

**ä¸¥æ ¼æ•°å­¦æ¨å¯¼ / Rigorous Mathematical Derivation:**

**æ—¶é—´å¤æ‚åº¦åˆ†æ / Time Complexity Analysis:**

è®¾ $V$ ä¸ºé¡¶ç‚¹æ•°ï¼Œ$E$ ä¸ºè¾¹æ•°ã€‚
Let $V$ be the number of vertices and $E$ be the number of edges.

**æ“ä½œè®¡æ•° / Operation Count:**

1. **åˆå§‹åŒ– / Initialization**: $O(|V|)$
   - åˆå§‹åŒ–è·ç¦»æ•°ç»„å’Œè®¿é—®æ ‡è®°
   - Initialize distance array and visited marks

2. **ä¼˜å…ˆé˜Ÿåˆ—æ“ä½œ / Priority Queue Operations**:
   - **Extract-Min**: æ‰§è¡Œ $|V|$ æ¬¡ï¼Œæ¯æ¬¡ $O(\log |V|)$ï¼Œæ€»è®¡ $O(|V| \log |V|)$
   - **Decrease-Key**: æ‰§è¡Œ $|E|$ æ¬¡ï¼Œæ¯æ¬¡ $O(\log |V|)$ï¼Œæ€»è®¡ $O(|E| \log |V|)$
   - **Extract-Min**: Executed $|V|$ times, each $O(\log |V|)$, total $O(|V| \log |V|)$
   - **Decrease-Key**: Executed $|E|$ times, each $O(\log |V|)$, total $O(|E| \log |V|)$

3. **æ€»æ—¶é—´å¤æ‚åº¦ / Total Time Complexity**:
   $$T(|V|, |E|) = O(|V|) + O(|V| \log |V|) + O(|E| \log |V|) = O((|V| + |E|) \log |V|)$$

**ç©ºé—´å¤æ‚åº¦åˆ†æ / Space Complexity Analysis:**

- **è·ç¦»æ•°ç»„**: $O(|V|)$
- **è®¿é—®æ ‡è®°**: $O(|V|)$
- **ä¼˜å…ˆé˜Ÿåˆ—**: $O(|V|)$
- **æ€»ç©ºé—´å¤æ‚åº¦**: $O(|V|)$
- **Distance array**: $O(|V|)$
- **Visited marks**: $O(|V|)$
- **Priority queue**: $O(|V|)$
- **Total space complexity**: $O(|V|)$

**å®šç† 3.1.2** (Dijkstraç®—æ³•æ­£ç¡®æ€§å®šç†) å¯¹äºæ— è´Ÿæƒå›¾ï¼ŒDijkstraç®—æ³•èƒ½å¤Ÿæ‰¾åˆ°ä»æºç‚¹åˆ°æ‰€æœ‰å…¶ä»–é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ã€‚
**Theorem 3.1.2** (Dijkstra Algorithm Correctness Theorem) For graphs with non-negative weights, Dijkstra's algorithm finds shortest paths from source to all other vertices.

**å½¢å¼åŒ–æ­£ç¡®æ€§è¯æ˜ / Formal Correctness Proof:**

**å‰ç½®æ¡ä»¶ / Precondition**:

- å›¾ $G = (V, E)$ æœ‰éè´Ÿè¾¹æƒé‡
- æºé¡¶ç‚¹ $s \in V$
**Graph**: $G = (V, E)$ with non-negative edge weights
**Source vertex**: $s \in V$

**åç½®æ¡ä»¶ / Postcondition**:

- å¯¹äºæ‰€æœ‰ $v \in V$ï¼Œ$dist[v] = \delta(s, v)$ï¼ˆä» $s$ åˆ° $v$ çš„æœ€çŸ­è·¯å¾„è·ç¦»ï¼‰
**For all $v \in V$**, $dist[v] = \delta(s, v)$ (shortest path distance from $s$ to $v$)

**å…³é”®å¼•ç† / Key Lemma:**

**å¼•ç† 3.1.1** (ä¸‹ç•Œæ€§è´¨) åœ¨ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå¯¹äºæ‰€æœ‰é¡¶ç‚¹ $v$ï¼Œ$dist[v] \geq \delta(s, v)$ã€‚
**Lemma 3.1.1** (Lower Bound Property) During algorithm execution, for all vertices $v$, $dist[v] \geq \delta(s, v)$.

**è¯æ˜ / Proof:**
ä½¿ç”¨å½’çº³æ³•ã€‚åˆå§‹æ—¶ $dist[s] = 0 = \delta(s, s)$ï¼Œå…¶ä»–é¡¶ç‚¹ $dist[v] = \infty \geq \delta(s, v)$ã€‚
Use induction. Initially $dist[s] = 0 = \delta(s, s)$, other vertices $dist[v] = \infty \geq \delta(s, v)$.

åœ¨æ¾å¼›æ“ä½œä¸­ï¼Œå¦‚æœ $dist[u] + w(u,v) < dist[v]$ï¼Œåˆ™æ›´æ–° $dist[v] = dist[u] + w(u,v)$ã€‚
In relaxation, if $dist[u] + w(u,v) < dist[v]$, update $dist[v] = dist[u] + w(u,v)$.

ç”±äº $dist[u] \geq \delta(s, u)$ï¼ˆå½’çº³å‡è®¾ï¼‰ï¼Œä¸” $w(u,v) \geq 0$ï¼Œå› æ­¤ï¼š
Since $dist[u] \geq \delta(s, u)$ (inductive hypothesis) and $w(u,v) \geq 0$, therefore:

$$dist[v] = dist[u] + w(u,v) \geq \delta(s, u) + w(u,v) \geq \delta(s, v)$$

**å¼•ç† 3.1.2** (è´ªå¿ƒé€‰æ‹©æ€§è´¨) å½“é¡¶ç‚¹ $u$ ä»ä¼˜å…ˆé˜Ÿåˆ—ä¸­æå–æ—¶ï¼Œ$dist[u] = \delta(s, u)$ã€‚
**Lemma 3.1.2** (Greedy Choice Property) When vertex $u$ is extracted from the priority queue, $dist[u] = \delta(s, u)$.

**è¯æ˜ / Proof:**
ä½¿ç”¨åè¯æ³•ã€‚å‡è®¾å­˜åœ¨é¡¶ç‚¹ $u$ï¼Œå½“å®ƒè¢«æå–æ—¶ $dist[u] > \delta(s, u)$ã€‚
Use proof by contradiction. Assume there exists vertex $u$ such that when extracted, $dist[u] > \delta(s, u)$.

è®¾ $P$ ä¸ºä» $s$ åˆ° $u$ çš„æœ€çŸ­è·¯å¾„ï¼Œ$y$ ä¸º $P$ ä¸Šç¬¬ä¸€ä¸ªæœªè®¿é—®çš„é¡¶ç‚¹ã€‚
Let $P$ be the shortest path from $s$ to $u$, and $y$ be the first unvisited vertex on $P$.

è®¾ $x$ ä¸º $P$ ä¸Š $y$ çš„å‰é©±é¡¶ç‚¹ï¼ˆå·²è®¿é—®ï¼‰ã€‚
Let $x$ be the predecessor of $y$ on $P$ (visited).

ç”±äº $x$ å·²è®¿é—®ï¼Œ$dist[x] = \delta(s, x)$ã€‚
Since $x$ is visited, $dist[x] = \delta(s, x)$.

å½“ $x$ è¢«å¤„ç†æ—¶ï¼Œæˆ‘ä»¬æ¾å¼›äº†è¾¹ $(x, y)$ï¼Œå› æ­¤ï¼š
When $x$ is processed, we relaxed edge $(x, y)$, therefore:

$$dist[y] \leq dist[x] + w(x, y) = \delta(s, x) + w(x, y) = \delta(s, y)$$

ç”±äº $y$ åœ¨ $P$ ä¸Šä¸” $P$ æ˜¯ä» $s$ åˆ° $u$ çš„æœ€çŸ­è·¯å¾„ï¼š
Since $y$ is on $P$ and $P$ is the shortest path from $s$ to $u$:

$$\delta(s, y) + \delta(y, u) = \delta(s, u)$$

å› æ­¤ï¼š
Therefore:

$$dist[y] \leq \delta(s, y) \leq \delta(s, u) < dist[u]$$

è¿™ä¸ $u$ æ˜¯ä¼˜å…ˆé˜Ÿåˆ—ä¸­è·ç¦»æœ€å°çš„é¡¶ç‚¹çŸ›ç›¾ã€‚
This contradicts that $u$ is the vertex with minimum distance in the priority queue.

å› æ­¤ $dist[u] = \delta(s, u)$ã€‚
Therefore $dist[u] = \delta(s, u)$.

**ä¸»å®šç†è¯æ˜ / Main Theorem Proof:**

ç»“åˆå¼•ç†3.1.1å’Œ3.1.2ï¼š
Combining Lemmas 3.1.1 and 3.1.2:

- å½“é¡¶ç‚¹ $u$ è¢«æå–æ—¶ï¼Œ$dist[u] = \delta(s, u)$ï¼ˆå¼•ç†3.1.2ï¼‰
- å¯¹äºæ‰€æœ‰é¡¶ç‚¹ï¼Œ$dist[v] \geq \delta(s, v)$ï¼ˆå¼•ç†3.1.1ï¼‰
- When vertex $u$ is extracted, $dist[u] = \delta(s, u)$ (Lemma 3.1.2)
- For all vertices, $dist[v] \geq \delta(s, v)$ (Lemma 3.1.1)

ç”±äºç®—æ³•å¤„ç†æ‰€æœ‰é¡¶ç‚¹ï¼Œæœ€ç»ˆæ‰€æœ‰é¡¶ç‚¹çš„è·ç¦»éƒ½æ˜¯æœ€çŸ­è·¯å¾„è·ç¦»ã€‚
Since the algorithm processes all vertices, eventually all vertices have shortest path distances.

**å¾ªç¯ä¸å˜å¼è¯æ˜ / Loop Invariant Proof:**

**å¾ªç¯ä¸å˜å¼ / Loop Invariant**:
åœ¨æ¯æ¬¡è¿­ä»£å¼€å§‹æ—¶ï¼Œå¯¹äºæ‰€æœ‰å·²è®¿é—®çš„é¡¶ç‚¹ $v$ï¼Œ$dist[v] = \delta(s, v)$ã€‚
At the start of each iteration, for all visited vertices $v$, $dist[v] = \delta(s, v)$.

**åˆå§‹åŒ– / Initialization**:
åªæœ‰ $s$ è¢«è®¿é—®ï¼Œ$dist[s] = 0 = \delta(s, s)$ï¼Œä¸å˜å¼æˆç«‹ã€‚
Only $s$ is visited, $dist[s] = 0 = \delta(s, s)$, invariant holds.

**ä¿æŒ / Maintenance**:
å½“é¡¶ç‚¹ $u$ è¢«æå–å¹¶æ ‡è®°ä¸ºå·²è®¿é—®æ—¶ï¼Œæ ¹æ®å¼•ç†3.1.2ï¼Œ$dist[u] = \delta(s, u)$ã€‚
When vertex $u$ is extracted and marked as visited, by Lemma 3.1.2, $dist[u] = \delta(s, u)$.

æ¾å¼›æ“ä½œåªæ›´æ–°æœªè®¿é—®é¡¶ç‚¹çš„è·ç¦»ï¼Œä¸å½±å“å·²è®¿é—®é¡¶ç‚¹çš„è·ç¦»ã€‚
Relaxation only updates distances of unvisited vertices, not affecting visited vertices.

**ç»ˆæ­¢ / Termination**:
å½“æ‰€æœ‰é¡¶ç‚¹éƒ½è¢«è®¿é—®æ—¶ï¼Œæ‰€æœ‰é¡¶ç‚¹çš„è·ç¦»éƒ½æ˜¯æœ€çŸ­è·¯å¾„è·ç¦»ã€‚
When all vertices are visited, all vertices have shortest path distances.

**å­¦æœ¯å¼•ç”¨ / Academic Citations:**

- [Dijkstra 1959]: Dijkstra, E. W. (1959). "A note on two problems in connexion with graphs." *Numerische Mathematik*, 1(1), 269-271.
- [Cormen 2022]: Cormen, T. H., et al. (2022). *Introduction to Algorithms* (4th ed.). MIT Press.

**å½¢å¼åŒ–è¯æ˜ / Formal Proof:**

```lean
-- Dijkstraç®—æ³•å½¢å¼åŒ–å®šä¹‰ / Formal Definition of Dijkstra's Algorithm
structure DijkstraState where
  distances : Array â„ -- è·ç¦»æ•°ç»„ / Distance array
  visited : Array Bool -- è®¿é—®æ ‡è®° / Visited marks
  queue : PriorityQueue (â„ Ã— Nat) -- ä¼˜å…ˆé˜Ÿåˆ— / Priority queue

-- Dijkstraç®—æ³•æ­£ç¡®æ€§å®šç† / Correctness Theorem of Dijkstra's Algorithm
theorem dijkstra_correctness :
  âˆ€ G : Graph, âˆ€ s : Nat, s âˆˆ G.vertices,
  let result := dijkstra G s
  âˆ€ v âˆˆ G.vertices,
  result[v] = shortest_path_distance G s v := by
  intro G s h_s
  -- ä½¿ç”¨å¾ªç¯ä¸å˜é‡ / Use loop invariant
  have invariant : âˆ€ t : Nat, t â‰¤ G.vertices.length â†’
    let state := dijkstra_step G s t
    âˆ€ v âˆˆ G.vertices,
    if state.visited[v] then
      state.distances[v] = shortest_path_distance G s v
    else
      state.distances[v] â‰¥ shortest_path_distance G s v
  -- è¯æ˜å¾ªç¯ä¸å˜é‡ / Prove loop invariant
  induction t with
  | zero =>
    simp [dijkstra_step]
    intro v h_v
    simp [shortest_path_distance]
    cases h_v with
    | inl h => simp [h]
    | inr h => simp [h]
  | succ t ih =>
    intro h_t v h_v
    -- å¤„ç†ä¸‹ä¸€ä¸ªé¡¶ç‚¹ / Process next vertex
    have h_next := dijkstra_next_vertex G s t
    have h_update := dijkstra_update_distances G s t h_next
    -- æ›´æ–°è·ç¦» / Update distances
    have h_correct := dijkstra_distance_correct G s t h_next
    exact h_correct

-- Dijkstraç®—æ³•å¤æ‚åº¦åˆ†æ / Complexity Analysis of Dijkstra's Algorithm
theorem dijkstra_complexity :
  âˆ€ G : Graph, âˆ€ s : Nat,
  let operations := dijkstra_operations G s
  operations = O((G.vertices.length + G.edges.length) * log G.vertices.length) := by
  intro G s
  -- åˆ†æä¼˜å…ˆé˜Ÿåˆ—æ“ä½œ / Analyze priority queue operations
  have h1 : extract_min_operations = O(log n)
  have h2 : insert_operations = O(log n)
  have h3 : total_operations = O((V + E) * log V)
  exact h3

-- æœ€çŸ­è·¯å¾„è·ç¦»å½¢å¼åŒ–å®šä¹‰ / Formal Definition of Shortest Path Distance
def shortest_path_distance (G : Graph) (s v : Nat) : â„ :=
  if s = v then 0
  else if âˆƒ path : Path s v, path_valid G path then
    min { path_weight G path | path : Path s v, path_valid G path }
  else âˆ

-- è·¯å¾„æœ‰æ•ˆæ€§ / Path Validity
def path_valid (G : Graph) (path : Path) : Prop :=
  âˆ€ i : Nat, i < path.length - 1 â†’
  let edge := (path[i], path[i+1])
  edge âˆˆ G.edges

-- è·¯å¾„æƒé‡ / Path Weight
def path_weight (G : Graph) (path : Path) : â„ :=
  path.foldl (fun acc i =>
    if i < path.length - 1 then
      acc + G.weights (path[i], path[i+1])
    else acc) 0

-- Dijkstraç®—æ³•å®ç° / Dijkstra Algorithm Implementation
def dijkstra (G : Graph) (s : Nat) : Array â„ :=
  let initial_state := {
    distances := Array.mk G.vertices.length âˆ,
    visited := Array.mk G.vertices.length false,
    queue := PriorityQueue.empty
  }
  let final_state := dijkstra_loop G s initial_state
  final_state.distances

-- Dijkstraç®—æ³•ä¸»å¾ªç¯ / Dijkstra Main Loop
def dijkstra_loop (G : Graph) (s : Nat) (state : DijkstraState) : DijkstraState :=
  if state.queue.isEmpty then state
  else
    let (dist, u) := state.queue.extract_min
    let new_state := {
      state with
      visited := state.visited.set u true,
      distances := update_distances G u dist state.distances
    }
    let new_queue := add_neighbors_to_queue G u new_state.queue
    dijkstra_loop G s { new_state with queue := new_queue }

-- æ›´æ–°è·ç¦» / Update Distances
def update_distances (G : Graph) (u : Nat) (dist_u : â„) (distances : Array â„) : Array â„ :=
  distances.mapIdx (fun v dist_v =>
    let edge_weight := G.weights (u, v)
    if edge_weight < âˆ then min dist_v (dist_u + edge_weight) else dist_v)
```

### 3.2 Bellman-Fordç®—æ³• / Bellman-Ford Algorithm

**å®šä¹‰ 3.2.1** Bellman-Fordç®—æ³•å¯ä»¥å¤„ç†è´Ÿæƒè¾¹ã€‚
**Definition 3.2.1** Bellman-Ford algorithm can handle negative weight edges.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
BellmanFord(G, s):
    dist[s] = 0
    dist[v] = âˆ for all v â‰  s
    for i = 1 to |V|-1:
        for each edge (u,v) in E:
            if dist[u] + weight(u,v) < dist[v]:
                dist[v] = dist[u] + weight(u,v)
    // Check for negative cycles
    for each edge (u,v) in E:
        if dist[u] + weight(u,v) < dist[v]:
            return "Negative cycle detected"
```

**å®šç† 3.2.1** Bellman-Fordç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| \cdot |E|)$ã€‚
**Theorem 3.2.1** The time complexity of Bellman-Ford algorithm is $O(|V| \cdot |E|)$.

**å®šç† 3.2.2** (åŠ¨æ€è§„åˆ’æœ€ä¼˜å­ç»“æ„ - Bellman-Ford) (Theorem - Optimal Substructure of Dynamic Programming - Bellman-Ford):
è®¾ `dist_k(v)` ä¸ºåªä½¿ç”¨ **ä¸è¶…è¿‡ k æ¡è¾¹** çš„æœ€çŸ­è·¯å¾„é•¿åº¦ï¼Œåˆ™

Let `dist_k(v)` be the shortest path length using **at most k edges**, then

$$dist_{k+1}(v) = \min( dist_k(v), \min_{(u,v) \in E} [dist_k(u) + w(u,v)] )$$

ä¸” `dist_{|V|-1}(v)` ä¸º **çœŸå®æœ€çŸ­è·¯å¾„**ï¼ˆè‹¥æ— è´Ÿç¯ï¼‰ã€‚

And `dist_{|V|-1}(v)` is the **true shortest path** (if there is no negative cycle).

**è¯æ˜è¦ç‚¹** (Proof Outline):

- **å½’çº³åŸºç¡€** (Base Case): `k=0` æ—¶ `dist_0(s)=0`ï¼Œå…¶ä½™ä¸º âˆï¼Œæ˜¾ç„¶æ­£ç¡®ã€‚
  When `k=0`, `dist_0(s)=0`, others are âˆ, obviously correct.

- **å½’çº³æ­¥éª¤** (Inductive Step): å‡è®¾ `dist_k` æ­£ç¡®ï¼Œè€ƒè™‘è·¯å¾„ `P` é•¿åº¦ â‰¤ `k+1`ï¼š
  Assume `dist_k` is correct, consider path `P` with length â‰¤ `k+1`:

  - è‹¥ `P` ä½¿ç”¨ â‰¤ `k` æ¡è¾¹ï¼Œåˆ™ `dist_k` å·²è¦†ç›–ã€‚
    If `P` uses â‰¤ `k` edges, then `dist_k` already covers it.

  - å¦åˆ™ `P` å¯å†™æˆ `u â†’ v`ï¼ˆæœ€åä¸€æ¡è¾¹ï¼‰ï¼Œå…¶å‰ç¼€ â‰¤ `k` æ¡è¾¹ï¼Œä»£ä»·ä¸º `dist_k(u)+w(u,v)`ã€‚
    Otherwise `P` can be written as `u â†’ v` (last edge), its prefix â‰¤ `k` edges, cost is `dist_k(u)+w(u,v)`.

- **å–æœ€å°å€¼** (Take Minimum): å–ä¸¤è€…æœ€å°å³ä¸º `dist_{k+1}(v)`ã€‚
  Taking the minimum of both gives `dist_{k+1}(v)`.

- **ç»ˆæ­¢æ¡ä»¶** (Termination): å½“ `k = |V|-1` æ—¶ï¼Œä»»ä½•æ— è´Ÿç¯çš„æœ€çŸ­è·¯å¾„æœ€å¤šä½¿ç”¨ `|V|-1` æ¡è¾¹ï¼Œæ•…å¾—åˆ°å…¨å±€æœ€çŸ­è·¯å¾„ã€‚
  When `k = |V|-1`, any shortest path without negative cycles uses at most `|V|-1` edges, thus obtaining the global shortest path.

> **DP æ­£ç¡®æ€§** ä¾èµ–äº **æœ€ä¼˜å­ç»“æ„** ä¸ **æ— åæ•ˆæ€§**ï¼ˆå­é—®é¢˜è§£ä¸å—åç»­å†³ç­–å½±å“ï¼‰ã€‚
> **DP correctness** depends on **optimal substructure** and **no aftereffect** (subproblem solutions are not affected by subsequent decisions).

### 3.3 Floyd-Warshallç®—æ³• / Floyd-Warshall Algorithm

**å®šä¹‰ 3.3.1** Floyd-Warshallç®—æ³•è§£å†³æ‰€æœ‰ç‚¹å¯¹æœ€çŸ­è·¯å¾„é—®é¢˜ã€‚
**Definition 3.3.1** Floyd-Warshall algorithm solves the all-pairs shortest path problem.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
FloydWarshall(G):
    dist = adjacency matrix of G
    for k = 1 to |V|:
        for i = 1 to |V|:
            for j = 1 to |V|:
                dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])
```

**å®šç† 3.3.1** Floyd-Warshallç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V|^3)$ã€‚
**Theorem 3.3.1** The time complexity of Floyd-Warshall algorithm is $O(|V|^3)$.

---

## 4. æœ€å°ç”Ÿæˆæ ‘ / Minimum Spanning Tree

### 4.1 Kruskalç®—æ³• / Kruskal's Algorithm

**å®šä¹‰ 4.1.1** Kruskalç®—æ³•é€šè¿‡é€‰æ‹©æœ€å°æƒé‡è¾¹æ„å»ºæœ€å°ç”Ÿæˆæ ‘ã€‚
**Definition 4.1.1** Kruskal's algorithm builds MST by selecting minimum weight edges.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
Kruskal(G):
    sort edges by weight
    MST = empty set
    for each edge (u,v) in sorted order:
        if adding (u,v) doesn't create cycle:
            MST.add((u,v))
    return MST
```

**å®šç† 4.1.1** Kruskalç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|E| \log |E|)$ã€‚
**Theorem 4.1.1** The time complexity of Kruskal's algorithm is $O(|E| \log |E|)$.

### 4.2 Primç®—æ³• / Prim's Algorithm

**å®šä¹‰ 4.2.1** Primç®—æ³•ä»å•ä¸ªé¡¶ç‚¹å¼€å§‹æ„å»ºæœ€å°ç”Ÿæˆæ ‘ã€‚
**Definition 4.2.1** Prim's algorithm builds MST starting from a single vertex.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
Prim(G, s):
    MST = {s}
    Q = priority queue with edges from s
    while MST.size < |V|:
        (u,v) = Q.extract_min()
        if v not in MST:
            MST.add(v)
            for each neighbor w of v:
                if w not in MST:
                    Q.insert((v,w), weight(v,w))
```

**å®šç† 4.2.1** Primç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O((|V| + |E|) \log |V|)$ã€‚
**Theorem 4.2.1** The time complexity of Prim's algorithm is $O((|V| + |E|) \log |V|)$.

### 4.3 æœ€å°ç”Ÿæˆæ ‘æ€§è´¨ / MST Properties

**å®šç† 4.3.1** æœ€å°ç”Ÿæˆæ ‘åŒ…å« $|V| - 1$ æ¡è¾¹ã€‚
**Theorem 4.3.1** Minimum spanning tree contains $|V| - 1$ edges.

**å®šç† 4.3.2** æœ€å°ç”Ÿæˆæ ‘æ˜¯å”¯ä¸€çš„å½“ä¸”ä»…å½“æ‰€æœ‰è¾¹æƒé‡éƒ½ä¸åŒã€‚
**Theorem 4.3.2** MST is unique if and only if all edge weights are distinct.

**å®šç† 4.3.3** Kruskalç®—æ³•çš„æœ€ä¼˜æ€§ / Optimality of Kruskal's Algorithmï¼š
Kruskalç®—æ³•èƒ½å¤Ÿæ‰¾åˆ°å›¾çš„æœ€å°ç”Ÿæˆæ ‘ã€‚
Kruskal's algorithm finds the minimum spanning tree of a graph.

**è¯æ˜ / Proof:**
ä½¿ç”¨åè¯æ³•ã€‚å‡è®¾Kruskalç®—æ³•æ‰¾åˆ°çš„æ ‘ $T$ ä¸æ˜¯æœ€å°ç”Ÿæˆæ ‘ï¼Œå­˜åœ¨æ›´å°çš„ç”Ÿæˆæ ‘ $T'$ã€‚
Use proof by contradiction. Assume the tree $T$ found by Kruskal is not MST, there exists a smaller spanning tree $T'$.

**å½¢å¼åŒ–è¯æ˜ / Formal Proof:**

```lean
-- æœ€å°ç”Ÿæˆæ ‘å½¢å¼åŒ–å®šä¹‰ / Formal Definition of Minimum Spanning Tree
structure MST where
  edges : List (Nat Ã— Nat) -- ç”Ÿæˆæ ‘è¾¹é›† / MST edge set
  weight : â„ -- æ€»æƒé‡ / Total weight
  connected : Prop -- è¿é€šæ€§ / Connectivity
  acyclic : Prop -- æ— ç¯æ€§ / Acyclicity

-- Kruskalç®—æ³•æœ€ä¼˜æ€§å®šç† / Optimality Theorem of Kruskal's Algorithm
theorem kruskal_optimality :
  âˆ€ G : Graph,
  let mst := kruskal G
  âˆ€ other_mst : MST G,
  mst.weight â‰¤ other_mst.weight := by
  intro G
  -- ä½¿ç”¨åè¯æ³• / Use proof by contradiction
  intro h_contra
  -- å‡è®¾å­˜åœ¨æ›´å°çš„ç”Ÿæˆæ ‘ / Assume there exists a smaller spanning tree
  have h1 : âˆƒ other_mst : MST G, other_mst.weight < mst.weight
  -- æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸åŒçš„è¾¹ / Find the first different edge
  have h2 : âˆƒ e âˆˆ other_mst.edges, e âˆ‰ mst.edges
  -- ä½¿ç”¨å‰²æ€§è´¨ / Use cut property
  have h3 : âˆ€ cut : Cut G, e crosses cut â†’
            âˆƒ e' âˆˆ mst.edges, e' crosses cut âˆ§ e'.weight â‰¤ e.weight
  -- æ„é€ æ›´å°çš„ç”Ÿæˆæ ‘ / Construct smaller spanning tree
  have h4 : âˆƒ smaller_mst : MST G, smaller_mst.weight < mst.weight
  -- çŸ›ç›¾ / Contradiction
  contradiction

-- å‰²æ€§è´¨å½¢å¼åŒ–å®šä¹‰ / Formal Definition of Cut Property
structure Cut (G : Graph) where
  partition : Nat â†’ Bool -- é¡¶ç‚¹åˆ†å‰² / Vertex partition
  edges : List (Nat Ã— Nat) -- å‰²è¾¹ / Cut edges

def edge_crosses_cut (e : Nat Ã— Nat) (cut : Cut G) : Prop :=
  cut.partition e.1 â‰  cut.partition e.2

-- å‰²æ€§è´¨å®šç† / Cut Property Theorem
theorem cut_property :
  âˆ€ G : Graph, âˆ€ cut : Cut G, âˆ€ e : Nat Ã— Nat,
  e âˆˆ G.edges â†’ e crosses cut â†’
  let mst := kruskal G
  âˆƒ e' âˆˆ mst.edges, e' crosses cut âˆ§ e'.weight â‰¤ e.weight := by
  intro G cut e h_e h_cross
  -- ä½¿ç”¨Kruskalç®—æ³•çš„è´ªå¿ƒæ€§è´¨ / Use greedy property of Kruskal's algorithm
  have h1 : âˆ€ e' âˆˆ G.edges, e' crosses cut â†’ e'.weight â‰¥ e.weight
  have h2 : e âˆˆ mst.edges âˆ¨ âˆƒ e' âˆˆ mst.edges, e' crosses cut âˆ§ e'.weight â‰¤ e.weight
  cases h2 with
  | inl h => exact âŸ¨e, h, le_refl e.weightâŸ©
  | inr h => exact h

-- Kruskalç®—æ³•å®ç° / Kruskal Algorithm Implementation
def kruskal (G : Graph) : MST :=
  let sorted_edges := sort_by_weight G.edges
  let initial_mst := { edges := [], weight := 0, connected := true, acyclic := true }
  kruskal_loop G sorted_edges initial_mst

-- Kruskalç®—æ³•ä¸»å¾ªç¯ / Kruskal Main Loop
def kruskal_loop (G : Graph) (edges : List (Nat Ã— Nat)) (mst : MST) : MST :=
  match edges with
  | [] => mst
  | e :: rest =>
    if would_create_cycle G mst e then
      kruskal_loop G rest mst
    else
      let new_mst := add_edge_to_mst G mst e
      kruskal_loop G rest new_mst

-- æ£€æŸ¥æ˜¯å¦ä¼šäº§ç”Ÿç¯ / Check if adding edge would create cycle
def would_create_cycle (G : Graph) (mst : MST) (e : Nat Ã— Nat) : Bool :=
  let uf := union_find_from_mst G mst
  uf.find e.1 = uf.find e.2

-- æ·»åŠ è¾¹åˆ°ç”Ÿæˆæ ‘ / Add Edge to MST
def add_edge_to_mst (G : Graph) (mst : MST) (e : Nat Ã— Nat) : MST :=
  {
    edges := e :: mst.edges,
    weight := mst.weight + G.weights e,
    connected := mst_connected_after_add G mst e,
    acyclic := mst_acyclic_after_add G mst e
  }

-- ç”Ÿæˆæ ‘è¿é€šæ€§ä¿æŒ / MST Connectivity Preservation
theorem mst_connected_after_add :
  âˆ€ G : Graph, âˆ€ mst : MST G, âˆ€ e : Nat Ã— Nat,
  mst.connected â†’ Â¬ would_create_cycle G mst e â†’
  mst_connected_after_add G mst e := by
  intro G mst e h_conn h_no_cycle
  -- è¯æ˜æ·»åŠ è¾¹åä¿æŒè¿é€šæ€§ / Prove connectivity is preserved after adding edge
  have h1 : âˆ€ u v : Nat, u âˆˆ G.vertices â†’ v âˆˆ G.vertices â†’
            âˆƒ path : Path u v, path_uses_mst_edges path mst
  have h2 : âˆ€ u v : Nat, u âˆˆ G.vertices â†’ v âˆˆ G.vertices â†’
            âˆƒ path : Path u v, path_uses_mst_edges path (add_edge_to_mst G mst e)
  exact h2

-- ç”Ÿæˆæ ‘æ— ç¯æ€§ä¿æŒ / MST Acyclicity Preservation
theorem mst_acyclic_after_add :
  âˆ€ G : Graph, âˆ€ mst : MST G, âˆ€ e : Nat Ã— Nat,
  mst.acyclic â†’ Â¬ would_create_cycle G mst e â†’
  mst_acyclic_after_add G mst e := by
  intro G mst e h_acyclic h_no_cycle
  -- è¯æ˜æ·»åŠ è¾¹åä¿æŒæ— ç¯æ€§ / Prove acyclicity is preserved after adding edge
  have h1 : âˆ€ cycle : Cycle, Â¬ cycle_uses_mst_edges cycle mst
  have h2 : âˆ€ cycle : Cycle, Â¬ cycle_uses_mst_edges cycle (add_edge_to_mst G mst e)
  exact h2

-- å¹¶æŸ¥é›†å®ç° / Union-Find Implementation
structure UnionFind where
  parent : Array Nat -- çˆ¶èŠ‚ç‚¹æ•°ç»„ / Parent array
  rank : Array Nat -- ç§©æ•°ç»„ / Rank array

def union_find_from_mst (G : Graph) (mst : MST) : UnionFind :=
  let uf := UnionFind.new G.vertices.length
  mst.edges.foldl (fun uf e => uf.union e.1 e.2) uf

-- å¹¶æŸ¥é›†æ“ä½œ / Union-Find Operations
def UnionFind.find (uf : UnionFind) (x : Nat) : Nat :=
  if uf.parent[x] = x then x
  else
    let root := uf.find uf.parent[x]
    uf.parent.set x root
    root

def UnionFind.union (uf : UnionFind) (x y : Nat) : UnionFind :=
  let px := uf.find x
  let py := uf.find y
  if px = py then uf
  else if uf.rank[px] < uf.rank[py] then
    { uf with parent := uf.parent.set px py }
  else if uf.rank[px] > uf.rank[py] then
    { uf with parent := uf.parent.set py px }
  else
    { uf with
      parent := uf.parent.set py px,
      rank := uf.rank.set px (uf.rank[px] + 1)
    }
```

---

## 5. å¼ºè¿é€šåˆ†é‡ / Strongly Connected Components

### 5.1 Kosarajuç®—æ³• / Kosaraju's Algorithm

**å®šä¹‰ 5.1.1** Kosarajuç®—æ³•é€šè¿‡ä¸¤æ¬¡DFSæ‰¾åˆ°å¼ºè¿é€šåˆ†é‡ã€‚
**Definition 5.1.1** Kosaraju's algorithm finds SCCs using two DFS passes.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
Kosaraju(G):
    // First DFS to get finish times
    visited = [false] * |V|
    finish_times = []
    for v in V:
        if not visited[v]:
            DFS1(G, v, visited, finish_times)

    // Second DFS on transpose graph
    G_T = transpose(G)
    visited = [false] * |V|
    SCCs = []
    for v in reversed(finish_times):
        if not visited[v]:
            SCC = []
            DFS2(G_T, v, visited, SCC)
            SCCs.append(SCC)
    return SCCs
```

### 5.2 Tarjanç®—æ³• / Tarjan's Algorithm

**å®šä¹‰ 5.2.1** Tarjanç®—æ³•ä½¿ç”¨å•æ¬¡DFSæ‰¾åˆ°å¼ºè¿é€šåˆ†é‡ã€‚
**Definition 5.2.1** Tarjan's algorithm finds SCCs using a single DFS pass.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
Tarjan(G):
    index = 0
    stack = []
    indices = [-1] * |V|
    low_links = [-1] * |V|
    on_stack = [false] * |V|
    SCCs = []

    for v in V:
        if indices[v] == -1:
            strongconnect(v, index, stack, indices, low_links, on_stack, SCCs)
    return SCCs
```

---

## 6. ç½‘ç»œæµ / Network Flow

### 6.1 æœ€å¤§æµé—®é¢˜ / Maximum Flow Problem

**å®šä¹‰ 6.1.1** æœ€å¤§æµé—®é¢˜æ˜¯åœ¨å®¹é‡çº¦æŸä¸‹æ‰¾åˆ°ä»æºç‚¹åˆ°æ±‡ç‚¹çš„æœ€å¤§æµé‡ã€‚
**Definition 6.1.1** Maximum flow problem finds maximum flow from source to sink under capacity constraints.

**å½¢å¼åŒ–å®šä¹‰ / Formal Definition:**
ç»™å®šç½‘ç»œ $G = (V, E)$ å’Œå®¹é‡å‡½æ•° $c: E \rightarrow \mathbb{R}^+$ï¼Œæ‰¾åˆ°æœ€å¤§æµ $f: E \rightarrow \mathbb{R}^+$ã€‚
Given network $G = (V, E)$ and capacity function $c: E \rightarrow \mathbb{R}^+$, find maximum flow $f: E \rightarrow \mathbb{R}^+$.

### 6.2 Ford-Fulkersonç®—æ³• / Ford-Fulkerson Algorithm

**å®šä¹‰ 6.2.1** Ford-Fulkersonç®—æ³•é€šè¿‡å¯»æ‰¾å¢å¹¿è·¯å¾„è®¡ç®—æœ€å¤§æµã€‚
**Definition 6.2.1** Ford-Fulkerson algorithm computes maximum flow by finding augmenting paths.

**ç®—æ³•æè¿° / Algorithm Description:**

```text
FordFulkerson(G, s, t):
    f = zero flow
    while there exists augmenting path p from s to t:
        cf(p) = min{cf(e) : e in p}
        for each edge e in p:
            if e in E:
                f[e] += cf(p)
            else:
                f[reverse(e)] -= cf(p)
    return f
```

### 6.3 Dinicç®—æ³• / Dinic's Algorithm

**å®šä¹‰ 6.3.1** Dinicç®—æ³•ä½¿ç”¨åˆ†å±‚ç½‘ç»œä¼˜åŒ–æœ€å¤§æµè®¡ç®—ã€‚
**Definition 6.3.1** Dinic's algorithm optimizes maximum flow computation using layered networks.

**å®šç† 6.3.1** Dinicç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V|^2 |E|)$ã€‚
**Theorem 6.3.1** The time complexity of Dinic's algorithm is $O(|V|^2 |E|)$.

**å®šç† 6.3.2** Ford-Fulkersonç®—æ³•çš„æ­£ç¡®æ€§ / Correctness of Ford-Fulkerson Algorithmï¼š
Ford-Fulkersonç®—æ³•èƒ½å¤Ÿæ‰¾åˆ°ç½‘ç»œçš„æœ€å¤§æµã€‚
Ford-Fulkerson algorithm finds the maximum flow in a network.

**è¯æ˜ / Proof:**
ä½¿ç”¨æœ€å¤§æµæœ€å°å‰²å®šç†ã€‚ç®—æ³•ç»ˆæ­¢æ—¶ï¼Œæ®‹é‡ç½‘ç»œä¸­ä¸å­˜åœ¨ä»æºç‚¹åˆ°æ±‡ç‚¹çš„è·¯å¾„ï¼Œæ­¤æ—¶æµå€¼ç­‰äºæœ€å°å‰²å®¹é‡ã€‚
Use max-flow min-cut theorem. When algorithm terminates, no path exists from source to sink in residual network, flow value equals minimum cut capacity.

**å½¢å¼åŒ–è¯æ˜ / Formal Proof:**

```lean
-- ç½‘ç»œæµå½¢å¼åŒ–å®šä¹‰ / Formal Definition of Network Flow
structure Network where
  vertices : List Nat -- é¡¶ç‚¹é›† / Vertex set
  edges : List (Nat Ã— Nat) -- è¾¹é›† / Edge set
  capacities : Nat Ã— Nat â†’ â„ -- å®¹é‡å‡½æ•° / Capacity function
  source : Nat -- æºç‚¹ / Source
  sink : Nat -- æ±‡ç‚¹ / Sink

structure Flow where
  flow_values : Nat Ã— Nat â†’ â„ -- æµå€¼å‡½æ•° / Flow value function
  conservation : Prop -- æµé‡å®ˆæ’ / Flow conservation
  capacity_constraint : Prop -- å®¹é‡çº¦æŸ / Capacity constraint

-- Ford-Fulkersonç®—æ³•æ­£ç¡®æ€§å®šç† / Correctness Theorem of Ford-Fulkerson Algorithm
theorem ford_fulkerson_correctness :
  âˆ€ network : Network,
  let max_flow := ford_fulkerson network
  max_flow.value = min_cut_capacity network := by
  intro network
  -- ä½¿ç”¨æœ€å¤§æµæœ€å°å‰²å®šç† / Use max-flow min-cut theorem
  have h1 : max_flow.value â‰¤ min_cut_capacity network
  have h2 : max_flow.value â‰¥ min_cut_capacity network
  have h3 : max_flow.value = min_cut_capacity network
  exact h3

-- æœ€å¤§æµæœ€å°å‰²å®šç† / Max-Flow Min-Cut Theorem
theorem max_flow_min_cut :
  âˆ€ network : Network, âˆ€ flow : Flow network,
  flow.value = min_cut_capacity network â†”
  Â¬ âˆƒ augmenting_path network flow := by
  intro network flow
  constructor
  Â· -- æœ€å¤§æµ â‡’ æ— å¢å¹¿è·¯å¾„ / Max flow â‡’ No augmenting path
    intro h_max
    intro h_augment
    -- çŸ›ç›¾ï¼šå¯ä»¥å¢åŠ æµå€¼ / Contradiction: can increase flow value
    have h1 : âˆƒ flow' : Flow network, flow'.value > flow.value
    contradiction
  Â· -- æ— å¢å¹¿è·¯å¾„ â‡’ æœ€å¤§æµ / No augmenting path â‡’ Max flow
    intro h_no_augment
    -- æ„é€ æœ€å°å‰² / Construct minimum cut
    have h1 : âˆƒ cut : Cut network, cut.capacity = flow.value
    have h2 : flow.value = min_cut_capacity network
    exact h2

-- å¢å¹¿è·¯å¾„å½¢å¼åŒ–å®šä¹‰ / Formal Definition of Augmenting Path
def augmenting_path (network : Network) (flow : Flow network) : Prop :=
  âˆƒ path : Path network.source network.sink,
  path_valid_in_residual network flow path âˆ§
  path_has_positive_capacity network flow path

-- æ®‹é‡ç½‘ç»œ / Residual Network
def residual_network (network : Network) (flow : Flow network) : Network :=
  {
    vertices := network.vertices,
    edges := residual_edges network flow,
    capacities := residual_capacities network flow,
    source := network.source,
    sink := network.sink
  }

-- æ®‹é‡è¾¹ / Residual Edges
def residual_edges (network : Network) (flow : Flow network) : List (Nat Ã— Nat) :=
  network.edges.filter (fun e =>
    flow.flow_values e < network.capacities e) ++
  network.edges.filter (fun e =>
    flow.flow_values e > 0).map (fun e => (e.2, e.1))

-- æ®‹é‡å®¹é‡ / Residual Capacities
def residual_capacities (network : Network) (flow : Flow network) (e : Nat Ã— Nat) : â„ :=
  if e âˆˆ network.edges then
    network.capacities e - flow.flow_values e
  else if (e.2, e.1) âˆˆ network.edges then
    flow.flow_values (e.2, e.1)
  else 0

-- Ford-Fulkersonç®—æ³•å®ç° / Ford-Fulkerson Algorithm Implementation
def ford_fulkerson (network : Network) : Flow network :=
  let initial_flow := zero_flow network
  ford_fulkerson_loop network initial_flow

-- Ford-Fulkersonç®—æ³•ä¸»å¾ªç¯ / Ford-Fulkerson Main Loop
def ford_fulkerson_loop (network : Network) (flow : Flow network) : Flow network :=
  match find_augmenting_path network flow with
  | none => flow
  | some path =>
    let bottleneck := find_bottleneck network flow path
    let new_flow := augment_flow network flow path bottleneck
    ford_fulkerson_loop network new_flow

-- å¯»æ‰¾å¢å¹¿è·¯å¾„ / Find Augmenting Path
def find_augmenting_path (network : Network) (flow : Flow network) : Option (Path network.source network.sink) :=
  let residual := residual_network network flow
  bfs_path residual network.source network.sink

-- å¯»æ‰¾ç“¶é¢ˆå®¹é‡ / Find Bottleneck Capacity
def find_bottleneck (network : Network) (flow : Flow network) (path : Path) : â„ :=
  path.edges.foldl (fun min_cap e =>
    min min_cap (residual_capacities network flow e)) âˆ

-- å¢å¹¿æµ / Augment Flow
def augment_flow (network : Network) (flow : Flow network) (path : Path) (bottleneck : â„) : Flow network :=
  {
    flow_values := augment_flow_values network flow path bottleneck,
    conservation := flow_conservation_preserved network flow path bottleneck,
    capacity_constraint := capacity_constraint_preserved network flow path bottleneck
  }

-- å¢å¹¿æµå€¼ / Augment Flow Values
def augment_flow_values (network : Network) (flow : Flow network) (path : Path) (bottleneck : â„) (e : Nat Ã— Nat) : â„ :=
  if e âˆˆ path.edges then
    flow.flow_values e + bottleneck
  else if (e.2, e.1) âˆˆ path.edges then
    flow.flow_values e - bottleneck
  else
    flow.flow_values e

-- æµé‡å®ˆæ’ä¿æŒ / Flow Conservation Preservation
theorem flow_conservation_preserved :
  âˆ€ network : Network, âˆ€ flow : Flow network, âˆ€ path : Path, âˆ€ bottleneck : â„,
  flow.conservation â†’
  flow_conservation_preserved network flow path bottleneck := by
  intro network flow path bottleneck h_cons
  -- è¯æ˜å¢å¹¿åä¿æŒæµé‡å®ˆæ’ / Prove flow conservation is preserved after augmentation
  have h1 : âˆ€ v âˆˆ network.vertices, v â‰  network.source â†’ v â‰  network.sink â†’
            incoming_flow v = outgoing_flow v
  exact h1

-- å®¹é‡çº¦æŸä¿æŒ / Capacity Constraint Preservation
theorem capacity_constraint_preserved :
  âˆ€ network : Network, âˆ€ flow : Flow network, âˆ€ path : Path, âˆ€ bottleneck : â„,
  flow.capacity_constraint â†’
  capacity_constraint_preserved network flow path bottleneck := by
  intro network flow path bottleneck h_cap
  -- è¯æ˜å¢å¹¿åä¿æŒå®¹é‡çº¦æŸ / Prove capacity constraint is preserved after augmentation
  have h1 : âˆ€ e âˆˆ network.edges,
            new_flow_values e â‰¤ network.capacities e âˆ§ new_flow_values e â‰¥ 0
  exact h1

-- Dinicç®—æ³•å¤æ‚åº¦åˆ†æ / Dinic Algorithm Complexity Analysis
theorem dinic_complexity :
  âˆ€ network : Network,
  let operations := dinic_operations network
  operations = O(network.vertices.length^2 * network.edges.length) := by
  intro network
  -- åˆ†æåˆ†å±‚ç½‘ç»œæ„å»º / Analyze layered network construction
  have h1 : layered_network_construction = O(V + E)
  -- åˆ†æé˜»å¡æµè®¡ç®— / Analyze blocking flow computation
  have h2 : blocking_flow_computation = O(V * E)
  -- åˆ†æè¿­ä»£æ¬¡æ•° / Analyze number of iterations
  have h3 : max_iterations = O(V)
  -- æ€»å¤æ‚åº¦ / Total complexity
  have h4 : total_operations = O(V^2 * E)
  exact h4
```

---

## 7. å®ç°ç¤ºä¾‹ / Implementation Examples

### 7.1 å›¾çš„åŸºæœ¬ç»“æ„ / Basic Graph Structure

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
pub struct Graph {
    vertices: Vec<usize>,
    edges: HashMap<(usize, usize), f64>,
    directed: bool,
}

impl Graph {
    pub fn new(directed: bool) -> Self {
        Graph {
            vertices: Vec::new(),
            edges: HashMap::new(),
            directed,
        }
    }

    pub fn add_vertex(&mut self, v: usize) {
        if !self.vertices.contains(&v) {
            self.vertices.push(v);
        }
    }

    pub fn add_edge(&mut self, from: usize, to: usize, weight: f64) {
        self.edges.insert((from, to), weight);
        if !self.directed {
            self.edges.insert((to, from), weight);
        }
    }

    pub fn get_neighbors(&self, v: usize) -> Vec<usize> {
        self.edges
            .iter()
            .filter_map(|((from, to), _)| {
                if *from == v {
                    Some(*to)
                } else {
                    None
                }
            })
            .collect()
    }
}
```

### 7.2 DFSå®ç° / DFS Implementation

```rust
impl Graph {
    pub fn dfs(&self, start: usize) -> Vec<usize> {
        let mut visited = vec![false; self.vertices.len()];
        let mut result = Vec::new();
        self.dfs_recursive(start, &mut visited, &mut result);
        result
    }

    fn dfs_recursive(&self, v: usize, visited: &mut [bool], result: &mut Vec<usize>) {
        visited[v] = true;
        result.push(v);

        for neighbor in self.get_neighbors(v) {
            if !visited[neighbor] {
                self.dfs_recursive(neighbor, visited, result);
            }
        }
    }
}
```

### 7.3 BFSå®ç° / BFS Implementation

```rust
use std::collections::VecDeque;

impl Graph {
    pub fn bfs(&self, start: usize) -> Vec<usize> {
        let mut visited = vec![false; self.vertices.len()];
        let mut queue = VecDeque::new();
        let mut result = Vec::new();

        visited[start] = true;
        queue.push_back(start);

        while let Some(v) = queue.pop_front() {
            result.push(v);

            for neighbor in self.get_neighbors(v) {
                if !visited[neighbor] {
                    visited[neighbor] = true;
                    queue.push_back(neighbor);
                }
            }
        }

        result
    }
}
```

### 7.4 Dijkstraç®—æ³•å®ç° / Dijkstra Implementation

```rust
use std::collections::BinaryHeap;
use std::cmp::Ordering;

#[derive(PartialEq, Eq)]
struct State {
    cost: f64,
    position: usize,
}

impl Ord for State {
    fn cmp(&self, other: &Self) -> Ordering {
        other.cost.partial_cmp(&self.cost).unwrap()
    }
}

impl PartialOrd for State {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl Graph {
    pub fn dijkstra(&self, start: usize) -> Vec<f64> {
        let mut dist = vec![f64::INFINITY; self.vertices.len()];
        let mut heap = BinaryHeap::new();

        dist[start] = 0.0;
        heap.push(State { cost: 0.0, position: start });

        while let Some(State { cost, position }) = heap.pop() {
            if cost > dist[position] {
                continue;
            }

            for neighbor in self.get_neighbors(position) {
                let edge_weight = self.edges.get(&(position, neighbor)).unwrap_or(&f64::INFINITY);
                let next = State {
                    cost: cost + edge_weight,
                    position: neighbor,
                };

                if next.cost < dist[neighbor] {
                    heap.push(next);
                    dist[neighbor] = next.cost;
                }
            }
        }

        dist
    }
}
```

### 7.5 Kruskalç®—æ³•å®ç° / Kruskal Implementation

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
struct Edge {
    from: usize,
    to: usize,
    weight: f64,
}

impl Graph {
    pub fn kruskal(&self) -> Vec<(usize, usize)> {
        let mut edges: Vec<Edge> = self.edges
            .iter()
            .map(|((from, to), weight)| Edge {
                from: *from,
                to: *to,
                weight: *weight,
            })
            .collect();

        edges.sort_by(|a, b| a.weight.partial_cmp(&b.weight).unwrap());

        let mut uf = UnionFind::new(self.vertices.len());
        let mut mst = Vec::new();

        for edge in edges {
            if uf.union(edge.from, edge.to) {
                mst.push((edge.from, edge.to));
            }
        }

        mst
    }
}

struct UnionFind {
    parent: Vec<usize>,
    rank: Vec<usize>,
}

impl UnionFind {
    fn new(size: usize) -> Self {
        UnionFind {
            parent: (0..size).collect(),
            rank: vec![0; size],
        }
    }

    fn find(&mut self, x: usize) -> usize {
        if self.parent[x] != x {
            self.parent[x] = self.find(self.parent[x]);
        }
        self.parent[x]
    }

    fn union(&mut self, x: usize, y: usize) -> bool {
        let px = self.find(x);
        let py = self.find(y);

        if px == py {
            return false;
        }

        if self.rank[px] < self.rank[py] {
            self.parent[px] = py;
        } else if self.rank[px] > self.rank[py] {
            self.parent[py] = px;
        } else {
            self.parent[py] = px;
            self.rank[px] += 1;
        }

        true
    }
}
```

### 7.6 å¼ºè¿é€šåˆ†é‡å®ç° / SCC Implementation

```rust
impl Graph {
    pub fn kosaraju(&self) -> Vec<Vec<usize>> {
        let mut visited = vec![false; self.vertices.len()];
        let mut finish_times = Vec::new();

        // First DFS to get finish times
        for &v in &self.vertices {
            if !visited[v] {
                self.dfs_finish_times(v, &mut visited, &mut finish_times);
            }
        }

        // Second DFS on transpose graph
        let transpose = self.transpose();
        let mut visited = vec![false; self.vertices.len()];
        let mut sccs = Vec::new();

        for &v in finish_times.iter().rev() {
            if !visited[v] {
                let mut scc = Vec::new();
                transpose.dfs_scc(v, &mut visited, &mut scc);
                sccs.push(scc);
            }
        }

        sccs
    }

    fn dfs_finish_times(&self, v: usize, visited: &mut [bool], finish_times: &mut Vec<usize>) {
        visited[v] = true;

        for neighbor in self.get_neighbors(v) {
            if !visited[neighbor] {
                self.dfs_finish_times(neighbor, visited, finish_times);
            }
        }

        finish_times.push(v);
    }

    fn transpose(&self) -> Graph {
        let mut transpose = Graph::new(self.directed);

        for &v in &self.vertices {
            transpose.add_vertex(v);
        }

        for ((from, to), weight) in &self.edges {
            transpose.add_edge(*to, *from, *weight);
        }

        transpose
    }

    fn dfs_scc(&self, v: usize, visited: &mut [bool], scc: &mut Vec<usize>) {
        visited[v] = true;
        scc.push(v);

        for neighbor in self.get_neighbors(v) {
            if !visited[neighbor] {
                self.dfs_scc(neighbor, visited, scc);
            }
        }
    }
}
```

---

## 8. å‚è€ƒæ–‡çŒ® / References

> **è¯´æ˜ / Note**: æœ¬æ–‡æ¡£çš„å‚è€ƒæ–‡çŒ®é‡‡ç”¨ç»Ÿä¸€çš„å¼•ç”¨æ ‡å‡†ï¼Œæ‰€æœ‰æ–‡çŒ®æ¡ç›®å‡æ¥è‡ª `docs/references_database.yaml` æ•°æ®åº“ã€‚

### 8.1 ç»å…¸æ•™æ / Classic Textbooks

1. [Cormen2022] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2022). *Introduction to Algorithms* (4th ed.). MIT Press. ISBN: 978-0262046305
   - **Cormen-Leiserson-Rivest-Steinç®—æ³•å¯¼è®º**ï¼Œç®—æ³•è®¾è®¡ä¸åˆ†æçš„æƒå¨æ•™æã€‚æœ¬æ–‡æ¡£çš„å›¾ç®—æ³•ç†è®ºå‚è€ƒæ­¤ä¹¦ã€‚

2. [Kleinberg2005] Kleinberg, J., & Tardos, Ã‰. (2005). *Algorithm Design*. Pearson. ISBN: 978-0321295354
   - **Kleinberg-Tardosç®—æ³•è®¾è®¡æ•™æ**ï¼Œå¼ºè°ƒç®—æ³•è®¾è®¡æŠ€å·§ã€‚æœ¬æ–‡æ¡£çš„å›¾ç®—æ³•è®¾è®¡å‚è€ƒæ­¤ä¹¦ã€‚

3. [Tarjan1983] Tarjan, R. E. (1983). *Data Structures and Network Algorithms*. SIAM. ISBN: 978-0898711875
   - **Tarjanæ•°æ®ç»“æ„ä¸ç½‘ç»œç®—æ³•ç»å…¸è‘—ä½œ**ï¼Œå›¾ç®—æ³•çš„é‡è¦å‚è€ƒã€‚æœ¬æ–‡æ¡£çš„ç½‘ç»œæµç®—æ³•å‚è€ƒæ­¤ä¹¦ã€‚

4. **Bondy, J. A., & Murty, U. S. R.** (2008). *Graph Theory*. Springer.
   - Bondy-Murtyå›¾è®ºæ•™æï¼Œå›¾è®ºåŸºç¡€ç†è®ºã€‚

5. **Diestel, R.** (2017). *Graph Theory* (5th ed.). Springer.
   - Diestelå›¾è®ºæ•™æï¼Œç°ä»£å›¾è®ºç†è®ºã€‚

### 8.2 Wikiæ¦‚å¿µå‚è€ƒ / Wiki Concept References

- [Graph Theory](https://en.wikipedia.org/wiki/Graph_theory) - å›¾è®ºçš„æ ‡å‡†å®šä¹‰
- [Graph Traversal](https://en.wikipedia.org/wiki/Graph_traversal) - å›¾çš„éå†
- [Shortest Path Problem](https://en.wikipedia.org/wiki/Shortest_path_problem) - æœ€çŸ­è·¯å¾„é—®é¢˜
- [Minimum Spanning Tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree) - æœ€å°ç”Ÿæˆæ ‘
- [Dijkstra's Algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) - è¿ªæ°æ–¯ç‰¹æ‹‰ç®—æ³•
- [Bellman-Ford Algorithm](https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm) - è´å°”æ›¼-ç¦ç‰¹ç®—æ³•
- [Floyd-Warshall Algorithm](https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm) - å¼—æ´›ä¼Šå¾·-æ²ƒèˆå°”ç®—æ³•
- [Kruskal's Algorithm](https://en.wikipedia.org/wiki/Kruskal%27s_algorithm) - å…‹é²æ–¯å¡å°”ç®—æ³•
- [Prim's Algorithm](https://en.wikipedia.org/wiki/Prim%27s_algorithm) - æ™®é‡Œå§†ç®—æ³•
- [Strongly Connected Component](https://en.wikipedia.org/wiki/Strongly_connected_component) - å¼ºè¿é€šåˆ†é‡
- [Maximum Flow Problem](https://en.wikipedia.org/wiki/Maximum_flow_problem) - æœ€å¤§æµé—®é¢˜

### 8.3 å¤§å­¦è¯¾ç¨‹å‚è€ƒ / University Course References

- **MIT 6.006**: Introduction to Algorithms. MIT OpenCourseWare. URL: <https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/>
- **Stanford CS161**: Design and Analysis of Algorithms. Stanford University. URL: <https://web.stanford.edu/class/cs161/>
- **CMU 15-451**: Algorithm Design and Analysis. Carnegie Mellon University. URL: <https://www.cs.cmu.edu/~15451/>

### 8.4 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers

#### å›¾ç®—æ³•ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Graph Algorithm Theory

1. **Journal of the ACM (JACM)**
   - **Dijkstra, E.W.** (1959). "A Note on Two Problems in Connexion with Graphs". *Numerische Mathematik*, 1(1), 269-271.
   - **Kruskal, J.B.** (1956). "On the Shortest Spanning Subtree of a Graph and the Traveling Salesman Problem". *Proceedings of the American Mathematical Society*, 7(1), 48-50.
   - **Prim, R.C.** (1957). "Shortest Connection Networks and Some Generalizations". *Bell System Technical Journal*, 36(6), 1389-1401.
   - **Tarjan, R.E.** (1972). "Depth-First Search and Linear Graph Algorithms". *SIAM Journal on Computing*, 1(2), 146-160.

2. **SIAM Journal on Computing (SICOMP)**
   - **Fredman, M.L., & Tarjan, R.E.** (1987). "Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms". *Journal of the ACM*, 34(3), 596-615.
   - **Thorup, M.** (1999). "Undirected Single-Source Shortest Paths with Positive Integer Weights in Linear Time". *Journal of the ACM*, 46(3), 362-394.
   - **Gabow, H.N.** (1976). "An Efficient Implementation of Edmonds' Algorithm for Maximum Matching on Graphs". *Journal of the ACM*, 23(2), 221-234.

#### ç½‘ç»œæµç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Network Flow Theory

1. **Mathematical Programming**
   - **Ford, L.R., & Fulkerson, D.R.** (1956). "Maximal Flow Through a Network". *Canadian Journal of Mathematics*, 8(3), 399-404.
   - **Ahuja, R.K., et al.** (1993). *Network Flows: Theory, Algorithms, and Applications*. Prentice Hall.
   - **Goldberg, A.V., & Tarjan, R.E.** (1988). "A New Approach to the Maximum-Flow Problem". *Journal of the ACM*, 35(4), 921-940.
   - **Dinic, E.A.** (1970). "Algorithm for Solution of a Problem of Maximum Flow in Networks with Power Estimation". *Soviet Math. Doklady*, 11, 1277-1280.

2. **Operations Research**
   - **Edmonds, J., & Karp, R.M.** (1972). "Theoretical Improvements in Algorithmic Efficiency for Network Flow Problems". *Journal of the ACM*, 19(2), 248-264.
   - **Karzanov, A.V.** (1974). "Determining the Maximum Flow in a Network by the Method of Preflows". *Soviet Math. Doklady*, 15, 434-437.

#### å›¾è®ºåŸºç¡€é¡¶çº§æœŸåˆŠ / Top Journals in Graph Theory Foundations

1. **Journal of Graph Theory**
   - **Bondy, J.A., & Murty, U.S.R.** (2008). *Graph Theory*. Springer.
   - **West, D.B.** (2001). *Introduction to Graph Theory* (2nd ed.). Prentice Hall.
   - **LovÃ¡sz, L.** (1993). *Combinatorial Problems and Exercises* (2nd ed.). North-Holland.

2. **Combinatorica**
   - **Tutte, W.T.** (1984). *Graph Theory*. Addison-Wesley.
   - **Berge, C.** (1973). *Graphs and Hypergraphs*. North-Holland.

#### å¹¶è¡Œå›¾ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Parallel Graph Algorithms

1. **Journal of Parallel and Distributed Computing**
   - **Karp, R.M., & Ramachandran, V.** (1990). "A Survey of Parallel Algorithms for Shared-Memory Machines". *Handbook of Theoretical Computer Science*, 869-941.
   - **JaJa, J.** (1992). *An Introduction to Parallel Algorithms*. Addison-Wesley.
   - **Blelloch, G.E.** (1990). "Prefix Sums and Their Applications". *Synthesis of Parallel Algorithms*, 35-60.

2. **Parallel Computing**
   - **Akl, S.G.** (1989). *The Design and Analysis of Parallel Algorithms*. Prentice Hall.
   - **Leighton, T.** (1992). *Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes*. Morgan Kaufmann.

#### å›¾ç®—æ³•åº”ç”¨é¡¶çº§æœŸåˆŠ / Top Journals in Graph Algorithm Applications

1. **Journal of Computer and System Sciences**
   - **Hopcroft, J.E., & Tarjan, R.E.** (1973). "Algorithm 447: Efficient Algorithms for Graph Manipulation". *Communications of the ACM*, 16(6), 372-378.
   - **Even, S.** (1979). *Graph Algorithms*. Computer Science Press.
   - **Cormen, T.H., et al.** (2009). *Introduction to Algorithms* (3rd ed.). MIT Press.

2. **Theoretical Computer Science**
   - **Pettie, S.** (2004). "A New Approach to All-Pairs Shortest Paths on Real-Weighted Graphs". *Theoretical Computer Science*, 312(1), 47-74.
   - **Thorup, M.** (2007). "Equivalence Between Priority Queues and Sorting". *Journal of the ACM*, 54(6), 1-28.

---

## æ€»ç»“ / Summary

### æ ¸å¿ƒæ¦‚å¿µ / Core Concepts

- å›¾çš„åŸºæœ¬å®šä¹‰å’Œè¡¨ç¤ºæ–¹æ³• / Basic graph definitions and representations
- å›¾çš„éå†ç®—æ³•ï¼šDFSå’ŒBFS / Graph traversal algorithms: DFS and BFS
- æœ€çŸ­è·¯å¾„ç®—æ³•ï¼šDijkstraã€Bellman-Fordã€Floyd-Warshall / Shortest path algorithms: Dijkstra, Bellman-Ford, Floyd-Warshall
- æœ€å°ç”Ÿæˆæ ‘ç®—æ³•ï¼šKruskalã€Prim / Minimum spanning tree algorithms: Kruskal, Prim
- å¼ºè¿é€šåˆ†é‡ç®—æ³•ï¼šKosarajuã€Tarjan / Strongly connected component algorithms: Kosaraju, Tarjan
- ç½‘ç»œæµç®—æ³•ï¼šFord-Fulkersonã€Dinic / Network flow algorithms: Ford-Fulkerson, Dinic

### ç®—æ³•å¤æ‚åº¦ / Algorithm Complexity

- å›¾éå†ï¼š$O(|V| + |E|)$ / Graph traversal: $O(|V| + |E|)$
- æœ€çŸ­è·¯å¾„ï¼šDijkstra $O((|V| + |E|) \log |V|)$ï¼ŒBellman-Ford $O(|V| \cdot |E|)$ï¼ŒFloyd-Warshall $O(|V|^3)$ / Shortest path: Dijkstra $O((|V| + |E|) \log |V|)$, Bellman-Ford $O(|V| \cdot |E|)$, Floyd-Warshall $O(|V|^3)$
- æœ€å°ç”Ÿæˆæ ‘ï¼šKruskal $O(|E| \log |E|)$ï¼ŒPrim $O((|V| + |E|) \log |V|)$ / MST: Kruskal $O(|E| \log |E|)$, Prim $O((|V| + |E|) \log |V|)$
- å¼ºè¿é€šåˆ†é‡ï¼šKosaraju $O(|V| + |E|)$ï¼ŒTarjan $O(|V| + |E|)$ / SCC: Kosaraju $O(|V| + |E|)$, Tarjan $O(|V| + |E|)$
- ç½‘ç»œæµï¼šFord-Fulkerson $O(|E| \cdot f^*)$ï¼ŒDinic $O(|V|^2 |E|)$ / Network flow: Ford-Fulkerson $O(|E| \cdot f^*)$, Dinic $O(|V|^2 |E|)$

### å®è·µåº”ç”¨ / Practical Applications

**åœ¨çº¿èµ„æº / Online Resources**:

1. **Wikipedia - Graph Theory**: <https://en.wikipedia.org/wiki/Graph_theory>
   - å›¾è®ºçš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«åŸºæœ¬å®šä¹‰ã€å›¾çš„è¡¨ç¤ºå’Œåˆ†ç±»ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

2. **Wikipedia - Graph Traversal**: <https://en.wikipedia.org/wiki/Graph_traversal>
   - å›¾éå†çš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»BFSå’ŒDFSï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

3. **Wikipedia - Shortest Path Problem**: <https://en.wikipedia.org/wiki/Shortest_path_problem>
   - æœ€çŸ­è·¯å¾„é—®é¢˜çš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«Dijkstraã€Bellman-Fordç­‰ç®—æ³•ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

4. **Wikipedia - Minimum Spanning Tree**: <https://en.wikipedia.org/wiki/Minimum_spanning_tree>
   - æœ€å°ç”Ÿæˆæ ‘çš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»Kruskalå’ŒPrimç®—æ³•ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

5. **Wikipedia - Maximum Flow Problem**: <https://en.wikipedia.org/wiki/Maximum_flow_problem>
   - æœ€å¤§æµé—®é¢˜çš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«Ford-Fulkersonå’ŒDinicç®—æ³•ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰ã€‚

**å¼•ç”¨è§„èŒƒè¯´æ˜ / Citation Guidelines**:

æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®å¼•ç”¨è§„èŒƒï¼ˆè§ `docs/å¼•ç”¨è§„èŒƒä¸æ•°æ®åº“.md`ï¼‰ã€‚æ‰€æœ‰å¼•ç”¨æ¡ç›®åœ¨ `docs/references_database.yaml` ä¸­æœ‰å®Œæ•´è®°å½•ã€‚

æœ¬æ–‡æ¡£å†…å®¹å·²å¯¹ç…§Wikipediaç›¸å…³æ¡ç›®ï¼ˆæˆªè‡³2025å¹´1æœˆ11æ—¥ï¼‰è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æœ¯è¯­å®šä¹‰å’Œç†è®ºæ¡†æ¶ä¸å½“å‰å­¦æœ¯æ ‡å‡†ä¸€è‡´ã€‚

---

## 9. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure

### 9.1 ç›¸å…³æ–‡æ¡£ / Related Documents

- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/01-ç®—æ³•è®¾è®¡ç†è®º.md` - ç®—æ³•è®¾è®¡ç†è®ºï¼ˆè´ªå¿ƒã€åŠ¨æ€è§„åˆ’ç­‰è®¾è®¡èŒƒå¼ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/22-ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶.md` - ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶ï¼ˆé—®é¢˜ç±»å‹ç»´åº¦ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/04-æœç´¢ç®—æ³•ç†è®º.md` - æœç´¢ç®—æ³•ç†è®ºï¼ˆBFSã€DFSç­‰å›¾æœç´¢ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/02-æ•°æ®ç»“æ„ç†è®º.md` - æ•°æ®ç»“æ„ç†è®ºï¼ˆå›¾æ•°æ®ç»“æ„ï¼‰
- ç›¸å…³å†…å®¹å·²æ•´åˆåˆ°æœ¬æ–‡æ¡£ï¼ˆåŸ `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` Â§3.3, Â§3.4ï¼‰

### 9.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position

æœ¬æ–‡æ¡£å±äº **09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€** æ¨¡å—ï¼Œæ˜¯å›¾ç®—æ³•ç†è®ºçš„æ ¸å¿ƒæ–‡æ¡£ï¼Œä¸ºå›¾ç®—æ³•çš„è®¾è®¡å’Œåˆ†ææä¾›ç†è®ºåŸºç¡€ã€‚

### 9.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents

- ç›¸å…³å†…å®¹å·²æ•´åˆåˆ°æœ¬æ–‡æ¡£ Â§3.2ï¼ˆåŸ `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-01-11.md` Â§3.3, Â§3.4ï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.1
****æœ€åæ›´æ–° / Last Updated**: 2025-01-11
**çŠ¶æ€ / Status**: å·²å¯¹ç…§Wikipediaæ›´æ–° / Updated with Wikipedia references (as of 2025-01-11)

---

- ç¤¾äº¤ç½‘ç»œåˆ†æ / Social network analysis
- è·¯ç”±ç®—æ³• / Routing algorithms
- ç½‘ç»œè®¾è®¡ / Network design
- ç”Ÿç‰©ä¿¡æ¯å­¦ / Bioinformatics
- è®¡ç®—æœºè§†è§‰ / Computer vision
- æ¨èç³»ç»Ÿ / Recommendation systems
