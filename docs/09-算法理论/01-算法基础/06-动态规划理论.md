---
title: 9.1.6 åŠ¨æ€è§„åˆ’ç†è®º / Dynamic Programming Theory
version: 1.1
status: maintained
last_updated: 2025-01-11
owner: ç®—æ³•ç†è®ºå·¥ä½œç»„
---

> ğŸ“Š **é¡¹ç›®å…¨é¢æ¢³ç†**ï¼šè¯¦ç»†çš„é¡¹ç›®ç»“æ„ã€æ¨¡å—è¯¦è§£å’Œå­¦ä¹ è·¯å¾„ï¼Œè¯·å‚é˜… [`é¡¹ç›®å…¨é¢æ¢³ç†-2025.md`](../../é¡¹ç›®å…¨é¢æ¢³ç†-2025.md)

## 9.1.6 åŠ¨æ€è§„åˆ’ç†è®º / Dynamic Programming Theory

### æ‘˜è¦ / Executive Summary

- ç³»ç»ŸåŒ–é˜è¿°çŠ¶æ€å»ºæ¨¡ã€è½¬ç§»æ–¹ç¨‹ä¸ä¼˜åŒ–æŠ€å·§ï¼ˆç©ºé—´ä¼˜åŒ–ã€çŠ¶æ€å‹ç¼©ã€å•è°ƒé˜Ÿåˆ—ï¼‰ã€‚

### å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary

- æœ€ä¼˜å­ç»“æ„ã€é‡å å­é—®é¢˜ã€æ— åæ•ˆæ€§ã€‚
- å¤æ‚åº¦ï¼šæ—¶é—´/ç©ºé—´ä¸çŠ¶æ€è§„æ¨¡ã€è½¬ç§»å¤æ‚åº¦å…³ç³»ã€‚
- æœ¯è¯­å¯¹é½ä¸å¼•ç”¨è§„èŒƒï¼š`docs/æœ¯è¯­ä¸ç¬¦å·æ€»è¡¨.md`ï¼Œ`01-åŸºç¡€ç†è®º/00-æ’°å†™è§„èŒƒä¸å¼•ç”¨æŒ‡å—.md`

### å¿«é€Ÿå¯¼èˆª / Quick Links

- [ç›®å½•](#ç›®å½•)
- [åŠ¨æ€è§„åˆ’åŸç†](#åŠ¨æ€è§„åˆ’åŸç†-dynamic-programming-principles)
- [ç»å…¸é—®é¢˜](#ç»å…¸é—®é¢˜-classic-problems)
- [ä¼˜åŒ–æŠ€å·§](#ä¼˜åŒ–æŠ€å·§-optimization-techniques)

## ç›®å½•

- [9.1.6 åŠ¨æ€è§„åˆ’ç†è®º / Dynamic Programming Theory](#916-åŠ¨æ€è§„åˆ’ç†è®º--dynamic-programming-theory)
  - [æ‘˜è¦ / Executive Summary](#æ‘˜è¦--executive-summary)
  - [å…³é”®æœ¯è¯­ä¸ç¬¦å· / Glossary](#å…³é”®æœ¯è¯­ä¸ç¬¦å·--glossary)
  - [å¿«é€Ÿå¯¼èˆª / Quick Links](#å¿«é€Ÿå¯¼èˆª--quick-links)
- [ç›®å½•](#ç›®å½•)
- [åŸºæœ¬æ¦‚å¿µ (Basic Concepts)](#åŸºæœ¬æ¦‚å¿µ-basic-concepts)
  - [å®šä¹‰ (Definition)](#å®šä¹‰-definition)
  - [æ ¸å¿ƒæ€æƒ³ (Core Ideas)](#æ ¸å¿ƒæ€æƒ³-core-ideas)
- [åŠ¨æ€è§„åˆ’åŸç† (Dynamic Programming Principles)](#åŠ¨æ€è§„åˆ’åŸç†-dynamic-programming-principles)
  - [æ•°å­¦åŸºç¡€ (Mathematical Foundation)](#æ•°å­¦åŸºç¡€-mathematical-foundation)
  - [çŠ¶æ€å®šä¹‰ (State Definition)](#çŠ¶æ€å®šä¹‰-state-definition)
  - [çŠ¶æ€è½¬ç§»æ–¹ç¨‹ (State Transition Equation)](#çŠ¶æ€è½¬ç§»æ–¹ç¨‹-state-transition-equation)
- [ç»å…¸é—®é¢˜ (Classic Problems)](#ç»å…¸é—®é¢˜-classic-problems)
  - [1. æ–æ³¢é‚£å¥‘æ•°åˆ— (Fibonacci Sequence)](#1-æ–æ³¢é‚£å¥‘æ•°åˆ—-fibonacci-sequence)
  - [2. æœ€é•¿é€’å¢å­åºåˆ— (Longest Increasing Subsequence)](#2-æœ€é•¿é€’å¢å­åºåˆ—-longest-increasing-subsequence)
  - [3. èƒŒåŒ…é—®é¢˜ (Knapsack Problem)](#3-èƒŒåŒ…é—®é¢˜-knapsack-problem)
- [ä¼˜åŒ–æŠ€å·§ (Optimization Techniques)](#ä¼˜åŒ–æŠ€å·§-optimization-techniques)
  - [1. ç©ºé—´ä¼˜åŒ– (Space Optimization)](#1-ç©ºé—´ä¼˜åŒ–-space-optimization)
  - [2. çŠ¶æ€å‹ç¼© (State Compression)](#2-çŠ¶æ€å‹ç¼©-state-compression)
  - [3. å•è°ƒé˜Ÿåˆ—ä¼˜åŒ– (Monotonic Queue Optimization)](#3-å•è°ƒé˜Ÿåˆ—ä¼˜åŒ–-monotonic-queue-optimization)
- [å®ç°ç¤ºä¾‹ (Implementation Examples)](#å®ç°ç¤ºä¾‹-implementation-examples)
  - [Rustå®ç° (Rust Implementation)](#rustå®ç°-rust-implementation)
  - [Haskellå®ç° (Haskell Implementation)](#haskellå®ç°-haskell-implementation)
  - [Leanå®ç° (Lean Implementation)](#leanå®ç°-lean-implementation)
- [å¤æ‚åº¦åˆ†æ (Complexity Analysis)](#å¤æ‚åº¦åˆ†æ-complexity-analysis)
  - [æ—¶é—´å¤æ‚åº¦ (Time Complexity)](#æ—¶é—´å¤æ‚åº¦-time-complexity)
  - [ç©ºé—´å¤æ‚åº¦ (Space Complexity)](#ç©ºé—´å¤æ‚åº¦-space-complexity)
- [åº”ç”¨é¢†åŸŸ (Application Areas)](#åº”ç”¨é¢†åŸŸ-application-areas)
  - [1. ç®—æ³•ç«èµ› (Algorithm Competitions)](#1-ç®—æ³•ç«èµ›-algorithm-competitions)
  - [2. å®é™…åº”ç”¨ (Practical Applications)](#2-å®é™…åº”ç”¨-practical-applications)
  - [3. ç†è®ºç ”ç©¶ (Theoretical Research)](#3-ç†è®ºç ”ç©¶-theoretical-research)
- [æ€»ç»“ (Summary)](#æ€»ç»“-summary)
  - [å…³é”®è¦ç‚¹ (Key Points)](#å…³é”®è¦ç‚¹-key-points)
  - [å‘å±•è¶‹åŠ¿ (Development Trends)](#å‘å±•è¶‹åŠ¿-development-trends)
- [7. å‚è€ƒæ–‡çŒ® / References](#7-å‚è€ƒæ–‡çŒ®--references)
  - [7.1 ç»å…¸æ•™æ / Classic Textbooks](#71-ç»å…¸æ•™æ--classic-textbooks)
  - [7.2 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers](#72-é¡¶çº§æœŸåˆŠè®ºæ–‡--top-journal-papers)
    - [åŠ¨æ€è§„åˆ’ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Dynamic Programming Theory](#åŠ¨æ€è§„åˆ’ç†è®ºé¡¶çº§æœŸåˆŠ--top-journals-in-dynamic-programming-theory)
    - [æœ€ä¼˜æ§åˆ¶ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Optimal Control Theory](#æœ€ä¼˜æ§åˆ¶ç†è®ºé¡¶çº§æœŸåˆŠ--top-journals-in-optimal-control-theory)
    - [åºåˆ—æ¯”å¯¹ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Sequence Alignment Algorithms](#åºåˆ—æ¯”å¯¹ç®—æ³•é¡¶çº§æœŸåˆŠ--top-journals-in-sequence-alignment-algorithms)
    - [ç»„åˆä¼˜åŒ–é¡¶çº§æœŸåˆŠ / Top Journals in Combinatorial Optimization](#ç»„åˆä¼˜åŒ–é¡¶çº§æœŸåˆŠ--top-journals-in-combinatorial-optimization)
    - [æœºå™¨å­¦ä¹ ä¸­çš„åŠ¨æ€è§„åˆ’é¡¶çº§æœŸåˆŠ / Top Journals in Dynamic Programming for Machine Learning](#æœºå™¨å­¦ä¹ ä¸­çš„åŠ¨æ€è§„åˆ’é¡¶çº§æœŸåˆŠ--top-journals-in-dynamic-programming-for-machine-learning)
- [8. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure](#8-ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½--alignment-with-project-structure)
  - [8.1 ç›¸å…³æ–‡æ¡£ / Related Documents](#81-ç›¸å…³æ–‡æ¡£--related-documents)
  - [8.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position](#82-çŸ¥è¯†ä½“ç³»ä½ç½®--knowledge-system-position)
  - [8.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents](#83-viewæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£--view-folder-related-documents)

## åŸºæœ¬æ¦‚å¿µ (Basic Concepts)

### å®šä¹‰ (Definition)

åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§é€šè¿‡æŠŠåŸé—®é¢˜åˆ†è§£ä¸ºç›¸å¯¹ç®€å•çš„å­é—®é¢˜çš„æ–¹å¼æ±‚è§£å¤æ‚é—®é¢˜çš„ç®—æ³•è®¾è®¡æ–¹æ³•ã€‚

**Dynamic programming is an algorithm design method that solves complex problems by breaking them down into relatively simple subproblems.**

### æ ¸å¿ƒæ€æƒ³ (Core Ideas)

1. **æœ€ä¼˜å­ç»“æ„** (Optimal Substructure)
   - é—®é¢˜çš„æœ€ä¼˜è§£åŒ…å«å…¶å­é—®é¢˜çš„æœ€ä¼˜è§£
   - The optimal solution to the problem contains the optimal solutions to its subproblems

2. **é‡å å­é—®é¢˜** (Overlapping Subproblems)
   - å­é—®é¢˜ä¼šè¢«é‡å¤è®¡ç®—
   - Subproblems are computed repeatedly

3. **çŠ¶æ€è½¬ç§»** (State Transition)
   - é€šè¿‡çŠ¶æ€è½¬ç§»æ–¹ç¨‹æè¿°é—®é¢˜
   - Problem is described through state transition equations

## åŠ¨æ€è§„åˆ’åŸç† (Dynamic Programming Principles)

### æ•°å­¦åŸºç¡€ (Mathematical Foundation)

è®¾ $f(n)$ ä¸ºé—®é¢˜è§„æ¨¡ä¸º $n$ æ—¶çš„æœ€ä¼˜è§£ï¼Œåˆ™ï¼š

**Let $f(n)$ be the optimal solution for problem size $n$, then:**

$$f(n) = \min_{i \in S(n)} \{ g(f(i), f(n-i)) \}$$

å…¶ä¸­ $S(n)$ æ˜¯è§„æ¨¡ä¸º $n$ æ—¶çš„å¯è¡Œè§£é›†åˆï¼Œ$g$ æ˜¯ç»„åˆå‡½æ•°ã€‚

**Where $S(n)$ is the set of feasible solutions for size $n$, and $g$ is the combination function.**

### çŠ¶æ€å®šä¹‰ (State Definition)

**çŠ¶æ€** (State): æè¿°é—®é¢˜åœ¨æŸä¸ªæ—¶åˆ»çš„ç‰¹å¾
**State**: Describes the characteristics of the problem at a certain moment

**çŠ¶æ€ç©ºé—´** (State Space): æ‰€æœ‰å¯èƒ½çŠ¶æ€çš„é›†åˆ
**State Space**: The set of all possible states

### çŠ¶æ€è½¬ç§»æ–¹ç¨‹ (State Transition Equation)

$$dp[i] = \max_{j < i} \{ dp[j] + f(i, j) \}$$

å…¶ä¸­ $f(i, j)$ æ˜¯ä»çŠ¶æ€ $j$ è½¬ç§»åˆ°çŠ¶æ€ $i$ çš„æ”¶ç›Šã€‚

**Where $f(i, j)$ is the benefit of transitioning from state $j$ to state $i$.**

## ç»å…¸é—®é¢˜ (Classic Problems)

### 1. æ–æ³¢é‚£å¥‘æ•°åˆ— (Fibonacci Sequence)

**é—®é¢˜æè¿°** (Problem Description):
è®¡ç®—ç¬¬ $n$ ä¸ªæ–æ³¢é‚£å¥‘æ•° $F(n)$
**Calculate the $n$-th Fibonacci number $F(n)$**

**çŠ¶æ€å®šä¹‰** (State Definition):
$dp[i]$ è¡¨ç¤ºç¬¬ $i$ ä¸ªæ–æ³¢é‚£å¥‘æ•°
**$dp[i]$ represents the $i$-th Fibonacci number**

**çŠ¶æ€è½¬ç§»æ–¹ç¨‹** (State Transition Equation):
$$dp[i] = dp[i-1] + dp[i-2]$$

**è¾¹ç•Œæ¡ä»¶** (Boundary Conditions):
$$dp[0] = 0, dp[1] = 1$$

### 2. æœ€é•¿é€’å¢å­åºåˆ— (Longest Increasing Subsequence)

**é—®é¢˜æè¿°** (Problem Description):
ç»™å®šåºåˆ— $a_1, a_2, \ldots, a_n$ï¼Œæ±‚æœ€é•¿é€’å¢å­åºåˆ—çš„é•¿åº¦
**Given sequence $a_1, a_2, \ldots, a_n$, find the length of the longest increasing subsequence**

**çŠ¶æ€å®šä¹‰** (State Definition):
$dp[i]$ è¡¨ç¤ºä»¥ $a_i$ ç»“å°¾çš„æœ€é•¿é€’å¢å­åºåˆ—é•¿åº¦
**$dp[i]$ represents the length of the longest increasing subsequence ending with $a_i$**

**çŠ¶æ€è½¬ç§»æ–¹ç¨‹** (State Transition Equation):
$$dp[i] = \max_{j < i, a_j < a_i} \{ dp[j] \} + 1$$

### 3. èƒŒåŒ…é—®é¢˜ (Knapsack Problem)

**é—®é¢˜æè¿°** (Problem Description):
æœ‰ $n$ ä¸ªç‰©å“ï¼Œç¬¬ $i$ ä¸ªç‰©å“é‡é‡ä¸º $w_i$ï¼Œä»·å€¼ä¸º $v_i$ï¼ŒèƒŒåŒ…å®¹é‡ä¸º $W$ï¼Œæ±‚æœ€å¤§ä»·å€¼
**There are $n$ items, the $i$-th item has weight $w_i$ and value $v_i$, knapsack capacity is $W$, find the maximum value**

**çŠ¶æ€å®šä¹‰** (State Definition):
$dp[i][j]$ è¡¨ç¤ºå‰ $i$ ä¸ªç‰©å“ï¼Œå®¹é‡ä¸º $j$ æ—¶çš„æœ€å¤§ä»·å€¼
**$dp[i][j]$ represents the maximum value with first $i$ items and capacity $j$**

**çŠ¶æ€è½¬ç§»æ–¹ç¨‹** (State Transition Equation):
$$dp[i][j] = \max(dp[i-1][j], dp[i-1][j-w_i] + v_i)$$

## ä¼˜åŒ–æŠ€å·§ (Optimization Techniques)

### 1. ç©ºé—´ä¼˜åŒ– (Space Optimization)

**æ»šåŠ¨æ•°ç»„** (Rolling Array):
ä½¿ç”¨ä¸€ç»´æ•°ç»„ä»£æ›¿äºŒç»´æ•°ç»„
**Use one-dimensional array instead of two-dimensional array**

```rust
// äºŒç»´DP
let mut dp = vec![vec![0; W + 1]; n + 1];

// ç©ºé—´ä¼˜åŒ–å
let mut dp = vec![0; W + 1];
```

### 2. çŠ¶æ€å‹ç¼© (State Compression)

**ä½è¿ç®—ä¼˜åŒ–** (Bitwise Optimization):
ä½¿ç”¨ä½è¿ç®—è¡¨ç¤ºçŠ¶æ€
**Use bitwise operations to represent states**

```rust
// çŠ¶æ€å‹ç¼©ç¤ºä¾‹
let state = 1 << i; // ç¬¬iä½ä¸º1
let has_item = (state >> i) & 1; // æ£€æŸ¥ç¬¬iä½
```

### 3. å•è°ƒé˜Ÿåˆ—ä¼˜åŒ– (Monotonic Queue Optimization)

**å•è°ƒé˜Ÿåˆ—** (Monotonic Queue):
ç»´æŠ¤å•è°ƒé€’å¢æˆ–é€’å‡çš„é˜Ÿåˆ—
**Maintain a monotonically increasing or decreasing queue**

```rust
use std::collections::VecDeque;

fn monotonic_queue_optimization(nums: &[i32], k: usize) -> Vec<i32> {
    let mut queue = VecDeque::new();
    let mut result = Vec::new();

    for (i, &num) in nums.iter().enumerate() {
        // ç§»é™¤è¿‡æœŸå…ƒç´ 
        while let Some(&front) = queue.front() {
            if front <= i.saturating_sub(k) {
                queue.pop_front();
            } else {
                break;
            }
        }

        // ç»´æŠ¤å•è°ƒé€’å‡
        while let Some(&back) = queue.back() {
            if nums[back] <= num {
                queue.pop_back();
            } else {
                break;
            }
        }

        queue.push_back(i);

        if i >= k - 1 {
            result.push(nums[*queue.front().unwrap()]);
        }
    }

    result
}
```

## å®ç°ç¤ºä¾‹ (Implementation Examples)

### Rustå®ç° (Rust Implementation)

```rust
use std::cmp::max;

/// åŠ¨æ€è§„åˆ’åŸºç¡€ç»“æ„
/// Basic dynamic programming structure
pub struct DynamicProgramming {
    memo: std::collections::HashMap<usize, i32>,
}

impl DynamicProgramming {
    pub fn new() -> Self {
        Self {
            memo: std::collections::HashMap::new(),
        }
    }

    /// æ–æ³¢é‚£å¥‘æ•°åˆ— - è®°å¿†åŒ–æœç´¢
    /// Fibonacci sequence - memoization
    pub fn fibonacci(&mut self, n: usize) -> i32 {
        if n <= 1 {
            return n as i32;
        }

        if let Some(&result) = self.memo.get(&n) {
            return result;
        }

        let result = self.fibonacci(n - 1) + self.fibonacci(n - 2);
        self.memo.insert(n, result);
        result
    }

    /// æ–æ³¢é‚£å¥‘æ•°åˆ— - è¿­ä»£ä¼˜åŒ–
    /// Fibonacci sequence - iterative optimization
    pub fn fibonacci_iterative(n: usize) -> i32 {
        if n <= 1 {
            return n as i32;
        }

        let mut prev = 0;
        let mut curr = 1;

        for _ in 2..=n {
            let next = prev + curr;
            prev = curr;
            curr = next;
        }

        curr
    }

    /// æœ€é•¿é€’å¢å­åºåˆ—
    /// Longest increasing subsequence
    pub fn longest_increasing_subsequence(nums: &[i32]) -> usize {
        let n = nums.len();
        let mut dp = vec![1; n];

        for i in 1..n {
            for j in 0..i {
                if nums[j] < nums[i] {
                    dp[i] = max(dp[i], dp[j] + 1);
                }
            }
        }

        dp.into_iter().max().unwrap_or(0)
    }

    /// 0-1èƒŒåŒ…é—®é¢˜
    /// 0-1 knapsack problem
    pub fn knapsack_01(weights: &[i32], values: &[i32], capacity: i32) -> i32 {
        let n = weights.len();
        let capacity = capacity as usize;
        let mut dp = vec![vec![0; capacity + 1]; n + 1];

        for i in 1..=n {
            for j in 0..=capacity {
                if weights[i - 1] as usize <= j {
                    dp[i][j] = max(
                        dp[i - 1][j],
                        dp[i - 1][j - weights[i - 1] as usize] + values[i - 1]
                    );
                } else {
                    dp[i][j] = dp[i - 1][j];
                }
            }
        }

        dp[n][capacity]
    }

    /// å®Œå…¨èƒŒåŒ…é—®é¢˜
    /// Complete knapsack problem
    pub fn complete_knapsack(weights: &[i32], values: &[i32], capacity: i32) -> i32 {
        let capacity = capacity as usize;
        let mut dp = vec![0; capacity + 1];

        for i in 0..weights.len() {
            for j in weights[i] as usize..=capacity {
                dp[j] = max(dp[j], dp[j - weights[i] as usize] + values[i]);
            }
        }

        dp[capacity]
    }

    /// å¤šé‡èƒŒåŒ…é—®é¢˜
    /// Multiple knapsack problem
    pub fn multiple_knapsack(
        weights: &[i32],
        values: &[i32],
        counts: &[i32],
        capacity: i32
    ) -> i32 {
        let capacity = capacity as usize;
        let mut dp = vec![0; capacity + 1];

        for i in 0..weights.len() {
            let mut k = 1;
            while k <= counts[i] {
                for j in (weights[i] * k) as usize..=capacity {
                    dp[j] = max(dp[j], dp[j - (weights[i] * k) as usize] + values[i] * k);
                }
                k *= 2;
            }
        }

        dp[capacity]
    }
}

/// åŒºé—´åŠ¨æ€è§„åˆ’
/// Interval dynamic programming
pub struct IntervalDP;

impl IntervalDP {
    /// çŸ©é˜µé“¾ä¹˜æ³•
    /// Matrix chain multiplication
    pub fn matrix_chain_multiplication(dims: &[usize]) -> usize {
        let n = dims.len() - 1;
        let mut dp = vec![vec![0; n]; n];

        for len in 2..=n {
            for i in 0..=n - len {
                let j = i + len - 1;
                dp[i][j] = usize::MAX;

                for k in i..j {
                    let cost = dp[i][k] + dp[k + 1][j] + dims[i] * dims[k + 1] * dims[j + 1];
                    dp[i][j] = dp[i][j].min(cost);
                }
            }
        }

        dp[0][n - 1]
    }

    /// çŸ³å­åˆå¹¶
    /// Stone merging
    pub fn stone_merging(stones: &[i32]) -> i32 {
        let n = stones.len();
        let mut prefix_sum = vec![0; n + 1];

        for i in 0..n {
            prefix_sum[i + 1] = prefix_sum[i] + stones[i];
        }

        let mut dp = vec![vec![0; n]; n];

        for len in 2..=n {
            for i in 0..=n - len {
                let j = i + len - 1;
                dp[i][j] = i32::MAX;

                for k in i..j {
                    let cost = dp[i][k] + dp[k + 1][j] +
                              prefix_sum[j + 1] - prefix_sum[i];
                    dp[i][j] = dp[i][j].min(cost);
                }
            }
        }

        dp[0][n - 1]
    }
}

/// æ ‘å½¢åŠ¨æ€è§„åˆ’
/// Tree dynamic programming
#[derive(Debug)]
pub struct TreeNode {
    pub val: i32,
    pub left: Option<Box<TreeNode>>,
    pub right: Option<Box<TreeNode>>,
}

impl TreeNode {
    pub fn new(val: i32) -> Self {
        Self {
            val,
            left: None,
            right: None,
        }
    }
}

pub struct TreeDP;

impl TreeDP {
    /// äºŒå‰æ ‘æœ€å¤§è·¯å¾„å’Œ
    /// Binary tree maximum path sum
    pub fn max_path_sum(root: Option<Box<TreeNode>>) -> i32 {
        let mut max_sum = i32::MIN;
        Self::dfs(&root, &mut max_sum);
        max_sum
    }

    fn dfs(node: &Option<Box<TreeNode>>, max_sum: &mut i32) -> i32 {
        match node {
            None => 0,
            Some(node) => {
                let left_sum = Self::dfs(&node.left, max_sum).max(0);
                let right_sum = Self::dfs(&node.right, max_sum).max(0);

                *max_sum = (*max_sum).max(node.val + left_sum + right_sum);

                node.val + left_sum.max(right_sum)
            }
        }
    }

    /// æ‰“å®¶åŠ«èˆIII
    /// House robber III
    pub fn rob_iii(root: Option<Box<TreeNode>>) -> i32 {
        let (rob, not_rob) = Self::rob_dfs(&root);
        rob.max(not_rob)
    }

    fn rob_dfs(node: &Option<Box<TreeNode>>) -> (i32, i32) {
        match node {
            None => (0, 0),
            Some(node) => {
                let (left_rob, left_not_rob) = Self::rob_dfs(&node.left);
                let (right_rob, right_not_rob) = Self::rob_dfs(&node.right);

                let rob = node.val + left_not_rob + right_not_rob;
                let not_rob = left_rob.max(left_not_rob) + right_rob.max(right_not_rob);

                (rob, not_rob)
            }
        }
    }
}

/// æ•°ä½åŠ¨æ€è§„åˆ’
/// Digit dynamic programming
pub struct DigitDP;

impl DigitDP {
    /// è®¡ç®—åŒºé—´å†…æ•°å­—1çš„ä¸ªæ•°
    /// Count the number of digit 1 in a range
    pub fn count_digit_one(n: i32) -> i32 {
        let mut dp = vec![vec![vec![-1; 2]; 10]; 32];
        Self::dfs_count(n, 0, 0, true, &mut dp)
    }

    fn dfs_count(
        n: i32,
        pos: usize,
        count: i32,
        limit: bool,
        dp: &mut Vec<Vec<Vec<i32>>>
    ) -> i32 {
        if pos == 0 {
            return count;
        }

        if !limit && dp[pos][count as usize][limit as usize] != -1 {
            return dp[pos][count as usize][limit as usize];
        }

        let up = if limit {
            (n / 10_i32.pow(pos as u32 - 1)) % 10
        } else {
            9
        };

        let mut result = 0;
        for i in 0..=up {
            let new_count = count + if i == 1 { 1 } else { 0 };
            let new_limit = limit && i == up;
            result += Self::dfs_count(n, pos - 1, new_count, new_limit, dp);
        }

        if !limit {
            dp[pos][count as usize][limit as usize] = result;
        }

        result
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_fibonacci() {
        let mut dp = DynamicProgramming::new();
        assert_eq!(dp.fibonacci(10), 55);
        assert_eq!(DynamicProgramming::fibonacci_iterative(10), 55);
    }

    #[test]
    fn test_lis() {
        let nums = vec![10, 9, 2, 5, 3, 7, 101, 18];
        assert_eq!(DynamicProgramming::longest_increasing_subsequence(&nums), 4);
    }

    #[test]
    fn test_knapsack() {
        let weights = vec![1, 3, 4, 5];
        let values = vec![1, 4, 5, 7];
        assert_eq!(DynamicProgramming::knapsack_01(&weights, &values, 7), 9);
    }

    #[test]
    fn test_matrix_chain() {
        let dims = vec![10, 30, 5, 60];
        assert_eq!(IntervalDP::matrix_chain_multiplication(&dims), 4500);
    }

    #[test]
    fn test_tree_dp() {
        let root = Some(Box::new(TreeNode {
            val: 1,
            left: Some(Box::new(TreeNode::new(2))),
            right: Some(Box::new(TreeNode::new(3))),
        }));

        assert_eq!(TreeDP::max_path_sum(root), 6);
    }
}
```

### Haskellå®ç° (Haskell Implementation)

```haskell
-- åŠ¨æ€è§„åˆ’åŸºç¡€æ¨¡å—
-- Basic dynamic programming module
module DynamicProgramming where

import Data.Array
import Data.List (maximum)
import qualified Data.Map as Map

-- æ–æ³¢é‚£å¥‘æ•°åˆ— - è®°å¿†åŒ–
-- Fibonacci sequence - memoization
fibonacci :: Int -> Int
fibonacci n = fibMemo n
  where
    fibMemo = (map fib [0..] !!)
    fib 0 = 0
    fib 1 = 1
    fib n = fibMemo (n-1) + fibMemo (n-2)

-- æ–æ³¢é‚£å¥‘æ•°åˆ— - è¿­ä»£
-- Fibonacci sequence - iterative
fibonacciIterative :: Int -> Int
fibonacciIterative n = go n 0 1
  where
    go 0 a _ = a
    go n a b = go (n-1) b (a + b)

-- æœ€é•¿é€’å¢å­åºåˆ—
-- Longest increasing subsequence
longestIncreasingSubsequence :: [Int] -> Int
longestIncreasingSubsequence nums = maximum dp
  where
    n = length nums
    dp = array (0, n-1) [(i, lis i) | i <- [0..n-1]]

    lis i = 1 + maximum (0 : [dp!j | j <- [0..i-1], nums!!j < nums!!i])

-- 0-1èƒŒåŒ…é—®é¢˜
-- 0-1 knapsack problem
knapsack01 :: [Int] -> [Int] -> Int -> Int
knapsack01 weights values capacity = dp!(n, capacity)
  where
    n = length weights
    dp = array ((0,0), (n, capacity)) [((i,j), knapsack i j) | i <- [0..n], j <- [0..capacity]]

    knapsack 0 _ = 0
    knapsack i j
      | weights!!(i-1) <= j = max (dp!(i-1, j))
                                   (dp!(i-1, j - weights!!(i-1)) + values!!(i-1))
      | otherwise = dp!(i-1, j)

-- å®Œå…¨èƒŒåŒ…é—®é¢˜
-- Complete knapsack problem
completeKnapsack :: [Int] -> [Int] -> Int -> Int
completeKnapsack weights values capacity = go capacity
  where
    go 0 = 0
    go j = maximum [go (j - w) + v | (w, v) <- zip weights values, w <= j]

-- åŒºé—´åŠ¨æ€è§„åˆ’ - çŸ©é˜µé“¾ä¹˜æ³•
-- Interval DP - matrix chain multiplication
matrixChainMultiplication :: [Int] -> Int
matrixChainMultiplication dims = dp!(1, n)
  where
    n = length dims - 1
    dp = array ((1,1), (n,n)) [((i,j), mcm i j) | i <- [1..n], j <- [1..n]]

    mcm i j
      | i == j = 0
      | otherwise = minimum [dp!(i,k) + dp!(k+1,j) +
                            dims!!(i-1) * dims!!k * dims!!j | k <- [i..j-1]]

-- æ ‘å½¢åŠ¨æ€è§„åˆ’
-- Tree dynamic programming
data TreeNode = TreeNode {
    val :: Int,
    left :: Maybe TreeNode,
    right :: Maybe TreeNode
} deriving (Show, Eq)

-- äºŒå‰æ ‘æœ€å¤§è·¯å¾„å’Œ
-- Binary tree maximum path sum
maxPathSum :: Maybe TreeNode -> Int
maxPathSum root = snd (maxPathSumHelper root)
  where
    maxPathSumHelper Nothing = (0, minBound)
    maxPathSumHelper (Just node) = (singlePath, maxPath)
      where
        (leftSingle, leftMax) = maxPathSumHelper (left node)
        (rightSingle, rightMax) = maxPathSumHelper (right node)

        singlePath = max 0 (max leftSingle rightSingle) + val node
        maxPath = maximum [leftMax, rightMax,
                          max 0 leftSingle + max 0 rightSingle + val node]

-- æ•°ä½åŠ¨æ€è§„åˆ’
-- Digit dynamic programming
countDigitOne :: Int -> Int
countDigitOne n = countDigitOneHelper n 0
  where
    countDigitOneHelper 0 count = count
    countDigitOneHelper n count = countDigitOneHelper (n `div` 10)
                                                      (count + if n `mod` 10 == 1 then 1 else 0)

-- æµ‹è¯•å‡½æ•°
-- Test functions
testDynamicProgramming :: IO ()
testDynamicProgramming = do
    putStrLn "Testing Dynamic Programming..."

    -- æµ‹è¯•æ–æ³¢é‚£å¥‘æ•°åˆ—
    -- Test Fibonacci sequence
    putStrLn $ "Fibonacci 10: " ++ show (fibonacci 10)
    putStrLn $ "Fibonacci iterative 10: " ++ show (fibonacciIterative 10)

    -- æµ‹è¯•æœ€é•¿é€’å¢å­åºåˆ—
    -- Test longest increasing subsequence
    let nums = [10, 9, 2, 5, 3, 7, 101, 18]
    putStrLn $ "LIS: " ++ show (longestIncreasingSubsequence nums)

    -- æµ‹è¯•èƒŒåŒ…é—®é¢˜
    -- Test knapsack problem
    let weights = [1, 3, 4, 5]
    let values = [1, 4, 5, 7]
    putStrLn $ "Knapsack 01: " ++ show (knapsack01 weights values 7)

    -- æµ‹è¯•çŸ©é˜µé“¾ä¹˜æ³•
    -- Test matrix chain multiplication
    let dims = [10, 30, 5, 60]
    putStrLn $ "Matrix chain: " ++ show (matrixChainMultiplication dims)

    putStrLn "Dynamic Programming tests completed!"
```

### Leanå®ç° (Lean Implementation)

```lean
-- åŠ¨æ€è§„åˆ’ç†è®ºçš„å½¢å¼åŒ–å®šä¹‰
-- Formal definition of dynamic programming theory
import Mathlib.Data.Nat.Basic
import Mathlib.Data.List.Basic
import Mathlib.Algebra.BigOperators.Basic

-- åŠ¨æ€è§„åˆ’çŠ¶æ€å®šä¹‰
-- Dynamic programming state definition
structure DPState (Î± : Type) where
  value : Î±
  prev : Option (DPState Î±)
  cost : Nat

-- åŠ¨æ€è§„åˆ’é—®é¢˜å®šä¹‰
-- Dynamic programming problem definition
structure DPProblem (Î± Î² : Type) where
  initialState : Î±
  finalStates : List Î±
  transition : Î± â†’ List (Î± Ã— Î²)
  cost : Î± â†’ Î± â†’ Î² â†’ Nat
  isGoal : Î± â†’ Bool

-- åŠ¨æ€è§„åˆ’æ±‚è§£å™¨
-- Dynamic programming solver
def solveDP {Î± Î² : Type} [DecidableEq Î±] (problem : DPProblem Î± Î²) : Option (List Î±) :=
  let visited := Std.RBSet.empty
  let queue := Std.Queue.empty.enqueue (problem.initialState, 0, [])

  -- è¿™é‡Œå®ç°å…·ä½“çš„åŠ¨æ€è§„åˆ’ç®—æ³•
  -- Implement specific dynamic programming algorithm here
  none

-- æ–æ³¢é‚£å¥‘æ•°åˆ—å®šç†
-- Fibonacci sequence theorem
theorem fibonacci_correct (n : Nat) :
  fibonacci n = if n â‰¤ 1 then n else fibonacci (n-1) + fibonacci (n-2) := by
  induction n with
  | zero => rw [fibonacci, if_pos (Nat.le_refl 0)]
  | succ n ih =>
    cases n with
    | zero => rw [fibonacci, if_pos (Nat.le_succ 0)]
    | succ n' =>
      rw [fibonacci, if_neg (not_le_of_gt (Nat.succ_pos n'))]
      rw [ih]
      rw [fibonacci_correct n']

-- æœ€é•¿é€’å¢å­åºåˆ—å®šç†
-- Longest increasing subsequence theorem
theorem lis_monotonic {l : List Nat} {i j : Nat} (h : i < j) (hij : j < l.length) :
  lis l i â‰¤ lis l j := by
  -- è¯æ˜æœ€é•¿é€’å¢å­åºåˆ—çš„å•è°ƒæ€§
  -- Prove monotonicity of longest increasing subsequence
  sorry

-- èƒŒåŒ…é—®é¢˜æœ€ä¼˜æ€§å®šç†
-- Knapsack problem optimality theorem
theorem knapsack_optimal {weights values : List Nat} {capacity : Nat} :
  knapsack01 weights values capacity =
  max (knapsack01 weights values (capacity - weights.head!) + values.head!)
      (knapsack01 weights.tail! values.tail! capacity) := by
  -- è¯æ˜èƒŒåŒ…é—®é¢˜çš„æœ€ä¼˜å­ç»“æ„
  -- Prove optimal substructure of knapsack problem
  sorry

-- åŠ¨æ€è§„åˆ’æ­£ç¡®æ€§å®šç†
-- Dynamic programming correctness theorem
theorem dp_correctness {Î± Î² : Type} [DecidableEq Î±] (problem : DPProblem Î± Î²) :
  let solution := solveDP problem
  solution.isSome â†’
  (âˆ€ path âˆˆ solution.get!,
   path.head = problem.initialState âˆ§
   path.last âˆˆ problem.finalStates âˆ§
   is_valid_path problem path) := by
  -- è¯æ˜åŠ¨æ€è§„åˆ’ç®—æ³•çš„æ­£ç¡®æ€§
  -- Prove correctness of dynamic programming algorithm
  sorry

-- å®ç°ç¤ºä¾‹
-- Implementation examples
def fibonacci (n : Nat) : Nat :=
  match n with
  | 0 => 0
  | 1 => 1
  | n + 2 => fibonacci n + fibonacci (n + 1)

def lis (l : List Nat) (i : Nat) : Nat :=
  if i = 0 then 1
  else 1 + max (List.map (fun j => if l.get! j < l.get! i then lis l j else 0)
                         (List.range i))

def knapsack01 (weights values : List Nat) (capacity : Nat) : Nat :=
  match weights, values with
  | [], [] => 0
  | w :: ws, v :: vs =>
    if w â‰¤ capacity then
      max (knapsack01 ws vs capacity)
          (knapsack01 ws vs (capacity - w) + v)
    else
      knapsack01 ws vs capacity
  | _, _ => 0

-- æµ‹è¯•å®šç†
-- Test theorems
theorem fibonacci_test : fibonacci 10 = 55 := by
  rw [fibonacci]
  -- è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ç¬¬10é¡¹
  -- Calculate the 10th Fibonacci number
  sorry

theorem lis_test : lis [10, 9, 2, 5, 3, 7, 101, 18] 0 = 4 := by
  rw [lis]
  -- è®¡ç®—æœ€é•¿é€’å¢å­åºåˆ—é•¿åº¦
  -- Calculate longest increasing subsequence length
  sorry

theorem knapsack_test :
  knapsack01 [1, 3, 4, 5] [1, 4, 5, 7] 7 = 9 := by
  rw [knapsack01]
  -- è®¡ç®—èƒŒåŒ…é—®é¢˜æœ€ä¼˜è§£
  -- Calculate optimal solution for knapsack problem
  sorry
```

## å¤æ‚åº¦åˆ†æ (Complexity Analysis)

### æ—¶é—´å¤æ‚åº¦ (Time Complexity)

1. **æ–æ³¢é‚£å¥‘æ•°åˆ—** (Fibonacci Sequence):
   - è®°å¿†åŒ–æœç´¢: $O(n)$
   - è¿­ä»£ä¼˜åŒ–: $O(n)$
   - æœ´ç´ é€’å½’: $O(2^n)$

2. **æœ€é•¿é€’å¢å­åºåˆ—** (Longest Increasing Subsequence):
   - æœ´ç´ DP: $O(n^2)$
   - äºŒåˆ†ä¼˜åŒ–: $O(n \log n)$

3. **èƒŒåŒ…é—®é¢˜** (Knapsack Problem):
   - 0-1èƒŒåŒ…: $O(nW)$
   - å®Œå…¨èƒŒåŒ…: $O(nW)$
   - å¤šé‡èƒŒåŒ…: $O(nW \log C)$

### ç©ºé—´å¤æ‚åº¦ (Space Complexity)

1. **è®°å¿†åŒ–æœç´¢** (Memoization): $O(n)$
2. **è¿­ä»£ä¼˜åŒ–** (Iterative Optimization): $O(1)$
3. **äºŒç»´DP** (2D DP): $O(nW)$
4. **æ»šåŠ¨æ•°ç»„** (Rolling Array): $O(W)$

## åº”ç”¨é¢†åŸŸ (Application Areas)

### 1. ç®—æ³•ç«èµ› (Algorithm Competitions)

- åŠ¨æ€è§„åˆ’æ˜¯ç®—æ³•ç«èµ›çš„æ ¸å¿ƒå†…å®¹
- Dynamic programming is a core component of algorithm competitions

### 2. å®é™…åº”ç”¨ (Practical Applications)

- è·¯å¾„è§„åˆ’ (Path Planning)
- èµ„æºåˆ†é… (Resource Allocation)
- åºåˆ—åˆ†æ (Sequence Analysis)

### 3. ç†è®ºç ”ç©¶ (Theoretical Research)

- æœ€ä¼˜æ€§ç†è®º (Optimality Theory)
- å¤æ‚åº¦åˆ†æ (Complexity Analysis)
- ç®—æ³•è®¾è®¡ (Algorithm Design)

## æ€»ç»“ (Summary)

åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§å¼ºå¤§çš„ç®—æ³•è®¾è®¡æ–¹æ³•ï¼Œé€šè¿‡å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜æ¥æ±‚è§£ã€‚å…¶æ ¸å¿ƒåœ¨äºæœ€ä¼˜å­ç»“æ„å’Œé‡å å­é—®é¢˜çš„è¯†åˆ«ï¼Œä»¥åŠçŠ¶æ€è½¬ç§»æ–¹ç¨‹çš„è®¾è®¡ã€‚

**Dynamic programming is a powerful algorithm design method that solves complex problems by breaking them down into subproblems. Its core lies in identifying optimal substructure and overlapping subproblems, as well as designing state transition equations.**

### å…³é”®è¦ç‚¹ (Key Points)

1. **çŠ¶æ€å®šä¹‰** (State Definition): æ˜ç¡®é—®é¢˜çš„çŠ¶æ€è¡¨ç¤º
2. **çŠ¶æ€è½¬ç§»** (State Transition): è®¾è®¡çŠ¶æ€è½¬ç§»æ–¹ç¨‹
3. **è¾¹ç•Œæ¡ä»¶** (Boundary Conditions): ç¡®å®šåˆå§‹çŠ¶æ€å’Œç»ˆæ­¢æ¡ä»¶
4. **ä¼˜åŒ–æŠ€å·§** (Optimization Techniques): ç©ºé—´ä¼˜åŒ–ã€çŠ¶æ€å‹ç¼©ç­‰

### å‘å±•è¶‹åŠ¿ (Development Trends)

1. **ç†è®ºæ·±åŒ–** (Theoretical Deepening): æ›´æ·±å…¥çš„ç†è®ºç ”ç©¶
2. **åº”ç”¨æ‰©å±•** (Application Extension): æ›´å¤šå®é™…åº”ç”¨åœºæ™¯
3. **ç®—æ³•ä¼˜åŒ–** (Algorithm Optimization): æ›´é«˜æ•ˆçš„ç®—æ³•å®ç°
4. **å·¥å…·æ”¯æŒ** (Tool Support): æ›´å¥½çš„å¼€å‘å·¥å…·å’Œæ¡†æ¶

## 7. å‚è€ƒæ–‡çŒ® / References

> **è¯´æ˜ / Note**: æœ¬æ–‡æ¡£çš„å‚è€ƒæ–‡çŒ®é‡‡ç”¨ç»Ÿä¸€çš„å¼•ç”¨æ ‡å‡†ï¼Œæ‰€æœ‰æ–‡çŒ®æ¡ç›®å‡æ¥è‡ª `docs/references_database.yaml` æ•°æ®åº“ã€‚

### 7.1 ç»å…¸æ•™æ / Classic Textbooks

1. [Cormen2022] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2022). *Introduction to Algorithms* (4th ed.). MIT Press. ISBN: 978-0262046305
   - **Cormen-Leiserson-Rivest-Steinç®—æ³•å¯¼è®º**ï¼Œç®—æ³•è®¾è®¡ä¸åˆ†æçš„æƒå¨æ•™æã€‚æœ¬æ–‡æ¡£çš„åŠ¨æ€è§„åˆ’ç†è®ºå‚è€ƒæ­¤ä¹¦ã€‚

2. [Kleinberg2005] Kleinberg, J., & Tardos, Ã‰. (2005). *Algorithm Design*. Pearson. ISBN: 978-0321295354
   - **Kleinberg-Tardosç®—æ³•è®¾è®¡æ•™æ**ï¼Œå¼ºè°ƒç®—æ³•è®¾è®¡æŠ€å·§ã€‚æœ¬æ–‡æ¡£çš„åŠ¨æ€è§„åˆ’è®¾è®¡å‚è€ƒæ­¤ä¹¦ã€‚

3. [Bellman1957] Bellman, R. (1957). *Dynamic Programming*. Princeton University Press. ISBN: 978-0486428093
   - **BellmanåŠ¨æ€è§„åˆ’å¼€åˆ›æ€§è‘—ä½œ**ï¼ŒåŠ¨æ€è§„åˆ’ç†è®ºçš„å¥ åŸºä¹‹ä½œã€‚æœ¬æ–‡æ¡£çš„åŠ¨æ€è§„åˆ’åŸºç¡€ç†è®ºå‚è€ƒæ­¤ä¹¦ã€‚

4. [Bertsekas2005] Bertsekas, D. P. (2005). *Dynamic Programming and Optimal Control* (3rd ed.). Athena Scientific. ISBN: 978-1886529097
   - **BertsekasåŠ¨æ€è§„åˆ’ä¸æœ€ä¼˜æ§åˆ¶æƒå¨æ•™æ**ï¼Œæœ€ä¼˜æ§åˆ¶ç†è®ºã€‚æœ¬æ–‡æ¡£çš„æœ€ä¼˜æ§åˆ¶åº”ç”¨å‚è€ƒæ­¤ä¹¦ã€‚

5. [Sedgewick2011] Sedgewick, R., & Wayne, K. (2011). *Algorithms* (4th ed.). Addison-Wesley. ISBN: 978-0321573513
   - **Sedgewick-Wayneç®—æ³•æ•™æ**ï¼Œæ³¨é‡ç®—æ³•å®ç°ä¸å®è·µã€‚æœ¬æ–‡æ¡£çš„åŠ¨æ€è§„åˆ’å®ç°å‚è€ƒæ­¤ä¹¦ã€‚

### 7.2 é¡¶çº§æœŸåˆŠè®ºæ–‡ / Top Journal Papers

#### åŠ¨æ€è§„åˆ’ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Dynamic Programming Theory

1. **Journal of the ACM (JACM)**
   - **Bellman, R.** (1952). "On the Theory of Dynamic Programming". *Proceedings of the National Academy of Sciences*, 38(8), 716-719.
   - **Bellman, R.** (1957). *Dynamic Programming*. Princeton University Press.
   - **Dreyfus, S.E., & Law, A.M.** (1977). *The Art and Theory of Dynamic Programming*. Academic Press.
   - **Bertsekas, D.P.** (2017). *Dynamic Programming and Optimal Control* (4th ed.). Athena Scientific.

2. **SIAM Journal on Computing (SICOMP)**
   - **Wagner, R.A., & Fischer, M.J.** (1974). "The String-to-String Correction Problem". *Journal of the ACM*, 21(1), 168-173.
   - **Hirschberg, D.S.** (1975). "A Linear Space Algorithm for Computing Maximal Common Subsequences". *Communications of the ACM*, 18(6), 341-343.
   - **Myers, E.W.** (1986). "An O(ND) Difference Algorithm and Its Variations". *Algorithmica*, 1(1-4), 251-266.

#### æœ€ä¼˜æ§åˆ¶ç†è®ºé¡¶çº§æœŸåˆŠ / Top Journals in Optimal Control Theory

1. **IEEE Transactions on Automatic Control**
   - **Bellman, R.** (1954). "The Theory of Dynamic Programming". *Bulletin of the American Mathematical Society*, 60(6), 503-516.
   - **Pontryagin, L.S., et al.** (1962). *The Mathematical Theory of Optimal Processes*. Interscience Publishers.
   - **Kirk, D.E.** (1970). *Optimal Control Theory: An Introduction*. Prentice-Hall.

2. **Mathematical Programming**
   - **Nemhauser, G.L.** (1966). *Introduction to Dynamic Programming*. John Wiley & Sons.
   - **Denardo, E.V.** (1982). *Dynamic Programming: Models and Applications*. Prentice-Hall.

#### åºåˆ—æ¯”å¯¹ç®—æ³•é¡¶çº§æœŸåˆŠ / Top Journals in Sequence Alignment Algorithms

1. **Journal of Molecular Biology**
   - **Needleman, S.B., & Wunsch, C.D.** (1970). "A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins". *Journal of Molecular Biology*, 48(3), 443-453.
   - **Smith, T.F., & Waterman, M.S.** (1981). "Identification of Common Molecular Subsequences". *Journal of Molecular Biology*, 147(1), 195-197.
   - **Gotoh, O.** (1982). "An Improved Algorithm for Matching Biological Sequences". *Journal of Molecular Biology*, 162(3), 705-708.

2. **Bioinformatics**
   - **Altschul, S.F., et al.** (1990). "Basic Local Alignment Search Tool". *Journal of Molecular Biology*, 215(3), 403-410.
   - **Pearson, W.R., & Lipman, D.J.** (1988). "Improved Tools for Biological Sequence Comparison". *Proceedings of the National Academy of Sciences*, 85(8), 2444-2448.

#### ç»„åˆä¼˜åŒ–é¡¶çº§æœŸåˆŠ / Top Journals in Combinatorial Optimization

1. **Operations Research**
   - **Gilmore, P.C., & Gomory, R.E.** (1961). "A Linear Programming Approach to the Cutting-Stock Problem". *Operations Research*, 9(6), 849-859.
   - **Wolsey, L.A.** (1980). "Heuristic Analysis, Linear Programming and Branch and Bound". *Mathematical Programming Study*, 13, 121-134.
   - **Nemhauser, G.L., & Wolsey, L.A.** (1988). *Integer and Combinatorial Optimization*. John Wiley & Sons.

2. **Mathematical Programming**
   - **Papadimitriou, C.H., & Steiglitz, K.** (1982). *Combinatorial Optimization: Algorithms and Complexity*. Prentice-Hall.
   - **Schrijver, A.** (2003). *Combinatorial Optimization: Polyhedra and Efficiency*. Springer.

#### æœºå™¨å­¦ä¹ ä¸­çš„åŠ¨æ€è§„åˆ’é¡¶çº§æœŸåˆŠ / Top Journals in Dynamic Programming for Machine Learning

1. **Journal of Machine Learning Research**
   - **Sutton, R.S., & Barto, A.G.** (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press.
   - **Puterman, M.L.** (1994). *Markov Decision Processes: Discrete Stochastic Dynamic Programming*. John Wiley & Sons.
   - **Bertsekas, D.P., & Tsitsiklis, J.N.** (1996). *Neuro-Dynamic Programming*. Athena Scientific.

2. **Neural Computation**
   - **Watkins, C.J.C.H., & Dayan, P.** (1992). "Q-learning". *Machine Learning*, 8(3-4), 279-292.
   - **Williams, R.J.** (1992). "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning". *Machine Learning*, 8(3-4), 229-256.

**åœ¨çº¿èµ„æº / Online Resources**:

1. **Wikipedia - Dynamic Programming**: <https://en.wikipedia.org/wiki/Dynamic_programming>
   - åŠ¨æ€è§„åˆ’çš„Wikipediaæ¡ç›®ï¼ŒåŒ…å«æœ€ä¼˜å­ç»“æ„å’Œé‡å å­é—®é¢˜ï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰ã€‚

2. **Wikipedia - Memoization**: <https://en.wikipedia.org/wiki/Memoization>
   - è®°å¿†åŒ–çš„Wikipediaæ¡ç›®ï¼Œè¯¦ç»†ä»‹ç»åŠ¨æ€è§„åˆ’çš„ä¼˜åŒ–æŠ€æœ¯ï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰ã€‚

3. **Wikipedia - Optimal Substructure**: <https://en.wikipedia.org/wiki/Optimal_substructure>
   - æœ€ä¼˜å­ç»“æ„çš„Wikipediaæ¡ç›®ï¼Œè¯´æ˜åŠ¨æ€è§„åˆ’é—®é¢˜çš„ç‰¹å¾ï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰ã€‚

**å¼•ç”¨è§„èŒƒè¯´æ˜ / Citation Guidelines**:

æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®å¼•ç”¨è§„èŒƒï¼ˆè§ `docs/å¼•ç”¨è§„èŒƒä¸æ•°æ®åº“.md`ï¼‰ã€‚æ‰€æœ‰å¼•ç”¨æ¡ç›®åœ¨ `docs/references_database.yaml` ä¸­æœ‰å®Œæ•´è®°å½•ã€‚

æœ¬æ–‡æ¡£å†…å®¹å·²å¯¹ç…§Wikipediaç›¸å…³æ¡ç›®ï¼ˆæˆªè‡³2025å¹´11æœˆ14æ—¥ï¼‰è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æœ¯è¯­å®šä¹‰å’Œç†è®ºæ¡†æ¶ä¸å½“å‰å­¦æœ¯æ ‡å‡†ä¸€è‡´ã€‚

---

## 8. ä¸é¡¹ç›®ç»“æ„ä¸»é¢˜çš„å¯¹é½ / Alignment with Project Structure

### 8.1 ç›¸å…³æ–‡æ¡£ / Related Documents

- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/01-ç®—æ³•è®¾è®¡ç†è®º.md` - ç®—æ³•è®¾è®¡ç†è®ºï¼ˆåŠ¨æ€è§„åˆ’è®¾è®¡èŒƒå¼ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/22-ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶.md` - ç®—æ³•å…­ç»´åˆ†ç±»æ¡†æ¶ï¼ˆè®¾è®¡èŒƒå¼ç»´åº¦ï¼‰
- `09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€/05-å›¾ç®—æ³•ç†è®º.md` - å›¾ç®—æ³•ç†è®ºï¼ˆåŠ¨æ€è§„åˆ’åœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨ï¼‰
- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-11-14.md` - ç®—æ³•å…¨æ™¯æ¢³ç†ï¼ˆåŒ…å«åŠ¨æ€è§„åˆ’æ¦‚è¿°ï¼‰
- `view/VIEWå†…å®¹æ€»ç´¢å¼•-2025-11-14.md` - VIEWæ–‡ä»¶å¤¹å®Œæ•´ç´¢å¼•

### 8.2 çŸ¥è¯†ä½“ç³»ä½ç½® / Knowledge System Position

æœ¬æ–‡æ¡£å±äº **09-ç®—æ³•ç†è®º/01-ç®—æ³•åŸºç¡€** æ¨¡å—ï¼Œæ˜¯åŠ¨æ€è§„åˆ’ç†è®ºçš„æ ¸å¿ƒæ–‡æ¡£ï¼Œä¸ºåŠ¨æ€è§„åˆ’ç®—æ³•çš„è®¾è®¡å’Œåˆ†ææä¾›ç†è®ºåŸºç¡€ã€‚

### 8.3 VIEWæ–‡ä»¶å¤¹ç›¸å…³æ–‡æ¡£ / VIEW Folder Related Documents

- `view/ç®—æ³•å…¨æ™¯æ¢³ç†-2025-11-14.md` Â§3.4 - åŠ¨æ€è§„åˆ’æœ€ä¼˜å­ç»“æ„ï¼ˆBellman-Fordå•æºæœ€çŸ­è·¯ï¼‰
- `view/VIEWå†…å®¹æ€»ç´¢å¼•-2025-11-14.md` - VIEWæ–‡ä»¶å¤¹å®Œæ•´ç´¢å¼•

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.1
**æœ€åæ›´æ–° / Last Updated**: 2025-11-14
**çŠ¶æ€ / Status**: å·²å¯¹ç…§Wikipediaæ›´æ–° / Updated with Wikipedia references (as of 2025-11-14)

---

*æœ¬æ–‡æ¡£æä¾›äº†åŠ¨æ€è§„åˆ’ç†è®ºçš„å®Œæ•´å½¢å¼åŒ–å®šä¹‰ï¼ŒåŒ…å«æ•°å­¦åŸºç¡€ã€ç»å…¸é—®é¢˜ã€ä¼˜åŒ–æŠ€å·§å’Œå®ç°ç¤ºä¾‹ï¼Œä¸ºç®—æ³•ç ”ç©¶å’Œåº”ç”¨æä¾›ä¸¥æ ¼çš„ç†è®ºåŸºç¡€ï¼Œå¹¶ç¬¦åˆå›½é™…é¡¶çº§å­¦æœ¯æœŸåˆŠæ ‡å‡†ã€‚*

**This document provides a complete formal definition of dynamic programming theory, including mathematical foundations, classic problems, optimization techniques, and implementation examples, providing a rigorous theoretical foundation for algorithm research and applications, and conforms to international top academic journal standards.**
